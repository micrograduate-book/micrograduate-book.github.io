<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>7. picoGPT: implementing a tiny GPT from scratch - microgra∇uate</title><meta property="og:title" content="7. picoGPT: implementing a tiny GPT from scratch - microgra∇uate"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/heading-5136875723662cf20389e350ea1e81d6.png"/><meta property="og:image" content="/build/heading-5136875723662cf20389e350ea1e81d6.png"/><link rel="stylesheet" href="/build/_assets/app-OIHP3NGU.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100vw;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="myst-home-link-logo mr-3 flex items-center dark:bg-white dark:rounded px-1"><img src="/build/logo-0c799f4fa809820562f5343e2dfd511f.png" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="microgra∇uate" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">microgra∇uate</a><a title="1. micrograd: implementing an autograd engine" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/micrograd">1. micrograd: implementing an autograd engine</a><a title="2. makemore (part 1): implementing a bigram character-level language model" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore1">2. makemore (part 1): implementing a bigram character-level language model</a><a title="3. makemore (part 2): mlp" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore2">3. makemore (part 2): mlp</a><a title="4. makemore (part 3): activations &amp; gradients, batchnorm" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore3">4. makemore (part 3): activations &amp; gradients, batchnorm</a><a title="5. makemore (part 4): becoming a backprop ninja" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore4">5. makemore (part 4): becoming a backprop ninja</a><a title="6. makemore (part 5): building a WaveNet" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore5">6. makemore (part 5): building a WaveNet</a><a title="7. picoGPT: implementing a tiny GPT from scratch" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg myst-toc-item-exact bg-blue-300/30 active" href="/micrograduate/picogpt">7. picoGPT: implementing a tiny GPT from scratch</a></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="myst-made-with-myst flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"><a href="https://github.com/ckaraneen/micrograduate" title="GitHub Repository: ckaraneen/micrograduate" target="_blank" rel="noopener noreferrer" class="myst-fm-github-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-github-icon inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div><a href="https://github.com/ckaraneen/micrograduate/edit/main/micrograduate/picogpt.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="myst-fm-edit-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-edit-icon inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">7. picoGPT: implementing a tiny GPT from scratch</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="IMsyE1e2gs" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import sys

IN_COLAB = &quot;google.colab&quot; in sys.modules
if IN_COLAB:
    print(&quot;Cloning repo...&quot;)
    !git clone --quiet https://github.com/ckaraneen/micrograduate.git &gt; /dev/null
    %cd micrograduate
    print(&quot;Installing requirements...&quot;)
    !pip install --quiet uv
    !uv pip install --system --quiet -r requirements.txt</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="NFZDLkr12ElDx8u-sKkiv" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="sDgmZPrpVd" class="myst-jp-nb-block relative group/block"><h2 id="intro" class="relative group"><span class="heading-text">Intro</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#intro" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="da96wI87wJ" class="myst-jp-nb-block relative group/block"><p>In this lesson, we’ll implement a tiny <strong>GPT</strong> from scratch in just a few lines of NumPy. To keep things simple, we’ll then load the trained <strong>GPT</strong>-2 model weights released by OpenAI into our implementation and generate some text. Sounds straightforward, right? Well, that’s because it is! Let’s get started.</p></div><div id="mteC4DWxuP" class="myst-jp-nb-block relative group/block"><h2 id="what-is-a-gpt" class="relative group"><span class="heading-text">What is a <strong>GPT</strong>?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#what-is-a-gpt" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="GdMiIiCj7J" class="myst-jp-nb-block relative group/block"><p><strong>GPT</strong> stands for <em>Generative Pre-trained Transformer</em>. It’s a type of <strong>nn</strong> architecture based on the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1706.03762.pdf" class="link">Transformer<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. <a target="_blank" rel="noreferrer" href="https://jalammar.github.io/how-gpt3-works-visualizations-animations/" class="link">Jay Alammar’s How <strong>GPT</strong>3 Works<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> is an excellent introduction to <strong>GPT</strong>s at a high level, but here’s the tl;dr:</p><ul><li><p>Generative: A <strong>GPT</strong> generates text.</p></li><li><p>Pre-trained: A <strong>GPT</strong> is trained on lots of text from books, the internet, etc ...</p></li><li><p>Transformer: A <strong>GPT</strong> is a decoder-only transformer <strong>nn</strong>.</p></li></ul><p>Large Language Models (LLMs), like <a href="https://en.wikipedia.org/wiki/GPT-3" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">OpenAI’s <strong>GPT</strong>-3</a>, are just <strong>GPT</strong>s under the hood. What makes them special is they happen to be:</p><ol start="1"><li><p>very big (billions of parameters) and</p></li><li><p>trained on lots of data (hundreds of gigabytes of text).</p></li></ol><p>Fundamentally, a <strong>GPT</strong> generates text given a prompt. Even with this very simple API (input = text, output = text), a well-trained <strong>GPT</strong> can do some pretty awesome stuff like <a target="_blank" rel="noreferrer" href="https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Demo-of-Drafting-an-Email.png?lossy=0&amp;strip=1&amp;webp=1&amp;ezimgfmt=ng:webp/ngcb1" class="link">write your emails<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Example-Book-Summarization.png?lossy=0&amp;strip=1&amp;webp=1&amp;ezimgfmt=ng:webp/ngcb1" class="link">summarize a book<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://khrisdigital.com/wp-content/uploads/2022/12/image-1.png" class="link">give you instagram caption ideas<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Examples-Explaining-Black-Holes.png?lossy=0&amp;strip=1&amp;webp=1&amp;ezimgfmt=ng:webp/ngcb1" class="link">explain black holes to a 5 year old<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Demo-of-Writing-SQL-Queries.png?lossy=0&amp;strip=1&amp;webp=1&amp;ezimgfmt=ng:webp/ngcb1" class="link">code in SQL<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, and even <a target="_blank" rel="noreferrer" href="https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/Chat-GPT-Example-Writing-a-Will.png?lossy=0&amp;strip=1&amp;webp=1&amp;ezimgfmt=ng:webp/ngcb1" class="link">write your will<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. So that’s a high-level overview of <strong>GPT</strong>s and their capabilities. Let’s dig into some more specifics.</p></div><div id="sDcfXVtyyZ" class="myst-jp-nb-block relative group/block"><h3 id="input-output" class="relative group"><span class="heading-text">Input / Output</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#input-output" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="YSOAxLEaL9" class="myst-jp-nb-block relative group/block"><p>The function signature for a <strong>GPT</strong> looks roughly like this:</p></div><div id="EpwDJgC0qV" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def gpt(inputs: list[int]) -&gt; list[list[float]]:
    # inputs has shape [n_seq]
    # output has shape [n_seq, n_vocab]
    output = # beep boop neural network magic
    return output</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="xKmVsE0OEM" class="myst-jp-nb-block relative group/block"><h4 id="input" class="relative group"><span class="heading-text">Input</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#input" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="agHTjhblM4" class="myst-jp-nb-block relative group/block"><p>The input is some text represented by a sequence of integers that map to tokens in the text:</p></div><div id="AfsaMc8Mm2" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># integers represent tokens in our text, for example:
# text   = &quot;not all heroes wear capes&quot;:
# tokens = &quot;not&quot;  &quot;all&quot; &quot;heroes&quot; &quot;wear&quot; &quot;capes&quot;
inputs =   [1,     0,    2,      4,     6]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="r1ocBtXYJK" class="myst-jp-nb-block relative group/block"><p>Tokens are sub-pieces of the text, which are produced using some kind of tokenizer. We can map tokens to integers using a vocabulary:</p></div><div id="dvf0wPRqZf" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># the index of a token in the vocab represents the integer id for that token
# i.e. the integer id for &quot;heroes&quot; would be 2, since vocab[2] = &quot;heroes&quot;
vocab = [&quot;all&quot;, &quot;not&quot;, &quot;heroes&quot;, &quot;the&quot;, &quot;wear&quot;, &quot;.&quot;, &quot;capes&quot;]

# a pretend tokenizer that tokenizes on whitespace
tokenizer = WhitespaceTokenizer(vocab)

# the encode() method converts a str -&gt; list[int]
ids = tokenizer.encode(&quot;not all heroes wear&quot;) # ids = [1, 0, 2, 4]

# we can see what the actual tokens are via our vocab mapping
tokens = [tokenizer.vocab[i] for i in ids] # tokens = [&quot;not&quot;, &quot;all&quot;, &quot;heroes&quot;, &quot;wear&quot;]

# the decode() method converts back a list[int] -&gt; str
text = tokenizer.decode(ids) # text = &quot;not all heroes wear&quot;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="PNaBDWGQGF" class="myst-jp-nb-block relative group/block"><p>In short:</p><ul><li><p>We have a string.</p></li><li><p>We use a tokenizer to break it down into smaller pieces called tokens.</p></li><li><p>We use a vocabulary to map those tokens to integers.</p></li></ul><p>In practice, we use more advanced methods of tokenization than simply splitting by whitespace, such as <a target="_blank" rel="noreferrer" href="https://huggingface.co/course/chapter6/5?fw=pt" class="link">Byte-Pair Encoding<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> or <a target="_blank" rel="noreferrer" href="https://huggingface.co/course/chapter6/6?fw=pt" class="link">WordPiece<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, but the principle is the same:</p><ul><li><p>There is a <code>vocab</code> that maps string tokens to integer indices</p></li><li><p>There is an <code>encode</code> method that converts <code>str -&gt; list[int]</code></p></li><li><p>There is a <code>decode</code> method that converts <code>list[int] -&gt; str</code></p></li></ul><p><em>Note</em>: For certain applications, the tokenizer doesn’t require a decode method. For example, if you want to classify if a movie review is saying the movie was good or bad, you only need to be able to encode the text and do a forward pass of the model, there is no need for decode. For generating text however, decode is a requirement. ↩︎</p></div><div id="F3QbFfgSW9" class="myst-jp-nb-block relative group/block"><h4 id="output" class="relative group"><span class="heading-text">Output</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#output" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="kr1xXMRGas" class="myst-jp-nb-block relative group/block"><p>The output is a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span> array, where <code>output[i][j]</code> is the model’s predicted probability that the token at <code>vocab[j]</code> is the next token <code>inputs[i+1]</code>. For example:</p></div><div id="JMm9uikZzE" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">vocab = [&quot;all&quot;, &quot;not&quot;, &quot;heroes&quot;, &quot;the&quot;, &quot;wear&quot;, &quot;.&quot;, &quot;capes&quot;]
inputs = [1, 0, 2, 4] # &quot;not&quot; &quot;all&quot; &quot;heroes&quot; &quot;wear&quot;
output = gpt(inputs)
#              [&quot;all&quot;, &quot;not&quot;, &quot;heroes&quot;, &quot;the&quot;, &quot;wear&quot;, &quot;.&quot;, &quot;capes&quot;]
# output[0] =  [0.75    0.1     0.0       0.15    0.0   0.0    0.0  ]
# given just &quot;not&quot;, the model predicts the word &quot;all&quot; with the highest probability

#              [&quot;all&quot;, &quot;not&quot;, &quot;heroes&quot;, &quot;the&quot;, &quot;wear&quot;, &quot;.&quot;, &quot;capes&quot;]
# output[1] =  [0.0     0.0      0.8     0.1    0.0    0.0   0.1  ]
# given the sequence [&quot;not&quot;, &quot;all&quot;], the model predicts the word &quot;heroes&quot; with the highest probability

#              [&quot;all&quot;, &quot;not&quot;, &quot;heroes&quot;, &quot;the&quot;, &quot;wear&quot;, &quot;.&quot;, &quot;capes&quot;]
# output[-1] = [0.0     0.0     0.0     0.1     0.0    0.05  0.85  ]
# given the whole sequence [&quot;not&quot;, &quot;all&quot;, &quot;heroes&quot;, &quot;wear&quot;], the model predicts the word &quot;capes&quot; with the highest probability</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="h1hQpmMzCP" class="myst-jp-nb-block relative group/block"><p>To get a next token prediction for the whole sequence, we simply take the token with the highest probability in <code>output[-1]</code>:</p></div><div id="kyHcJsqR6f" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">vocab = [&quot;all&quot;, &quot;not&quot;, &quot;heroes&quot;, &quot;the&quot;, &quot;wear&quot;, &quot;.&quot;, &quot;capes&quot;]
inputs = [1, 0, 2, 4] # &quot;not&quot; &quot;all&quot; &quot;heroes&quot; &quot;wear&quot;
output = gpt(inputs)
next_token_id = np.argmax(output[-1]) # next_token_id = 6
next_token = vocab[next_token_id] # next_token = &quot;capes&quot;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="Vh9KJmjoWc" class="myst-jp-nb-block relative group/block"><p>Taking the token with the highest probability as our prediction is known as <a target="_blank" rel="noreferrer" href="https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#1-pick-the-top-token-greedy-decoding" class="link">greedy decoding<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> or greedy sampling. The task of predicting the next logical word in a sequence is called language modeling. As such, we can call a <strong>GPT</strong> a language model. Generating a single word is cool and all, but what about entire sentences, paragraphs, etc ...?</p></div><div id="F6SVH0ddkV" class="myst-jp-nb-block relative group/block"><h3 id="generating-text" class="relative group"><span class="heading-text">Generating text</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#generating-text" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="hDyXZVFJ79" class="myst-jp-nb-block relative group/block"><h4 id="autoregressive" class="relative group"><span class="heading-text">Autoregressive</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#autoregressive" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="NZnyXhDS1Z" class="myst-jp-nb-block relative group/block"><p>We can generate full sentences by iteratively getting the next token prediction from our model. At each iteration, we append the predicted token back into the input:</p></div><div id="gd1RERM1Is" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def generate(inputs, n_tokens_to_generate):
    for _ in range(n_tokens_to_generate): # auto-regressive decode loop
        output = gpt(inputs) # model forward pass
        next_id = np.argmax(output[-1]) # greedy sampling
        inputs.append(int(next_id)) # append prediction to input
    return inputs[len(inputs) - n_tokens_to_generate :]  # only return generated ids

input_ids = [1, 0] # &quot;not&quot; &quot;all&quot;
output_ids = generate(input_ids, 3) # output_ids = [2, 4, 6]
output_tokens = [vocab[i] for i in output_ids] # &quot;heroes&quot; &quot;wear&quot; &quot;capes&quot;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="aW5IEQy9oJ" class="myst-jp-nb-block relative group/block"><p>This process of predicting a future value (regression), and adding it back into the input (auto), is why you might see a <strong>GPT</strong> described as autoregressive.</p></div><div id="f9u2DOxFl6" class="myst-jp-nb-block relative group/block"><h4 id="sampling" class="relative group"><span class="heading-text">Sampling</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#sampling" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="zRhRJChI3H" class="myst-jp-nb-block relative group/block"><p>We can introduce some stochasticity (randomness) to our generations by sampling from the probability distribution instead of being greedy:</p></div><div id="GJIa3cRTvP" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">inputs = [1, 0, 2, 4] # &quot;not&quot; &quot;all&quot; &quot;heroes&quot; &quot;wear&quot;
output = gpt(inputs)
np.random.choice(np.arange(vocab_size), p=output[-1]) # capes
np.random.choice(np.arange(vocab_size), p=output[-1]) # hats
np.random.choice(np.arange(vocab_size), p=output[-1]) # capes
np.random.choice(np.arange(vocab_size), p=output[-1]) # capes
np.random.choice(np.arange(vocab_size), p=output[-1]) # pants</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="W37x6F7112" class="myst-jp-nb-block relative group/block"><p>This allows us to generate different sentences given the same input. When combined with techniques like <a target="_blank" rel="noreferrer" href="https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#2-pick-from-amongst-the-top-tokens-top-k" class="link">top-k<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#3-pick-from-amongst-the-top-tokens-whose-probabilities-add-up-to-15-top-p" class="link">top-p<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, and <a target="_blank" rel="noreferrer" href="https://docs.cohere.ai/docs/temperature" class="link">temperature<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, which modify the distribution prior to sampling, the quality of our outputs is greatly increased. These techniques also introduce some hyperparameters that we can play around with to get different generation behaviors (for example, increasing temperature makes our model take more risks and thus be more “creative”.</p></div><div id="TliegPATfP" class="myst-jp-nb-block relative group/block"><h3 id="training" class="relative group"><span class="heading-text">Training</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#training" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="WBC6Tn4bNL" class="myst-jp-nb-block relative group/block"><p>We train a <strong>GPT</strong> like any other <strong>nn</strong>, using gradient descent <strong>w.r.t.</strong> some <strong>loss</strong> function. In the case of a <strong>GPT</strong>, we take the cross entropy <strong>loss</strong> over the language modeling task:</p></div><div id="eZxssZhGgE" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def lm_loss(inputs: list[int], params) -&gt; float:
    # the labels y are just the input shifted 1 to the left
    #
    # inputs = [not,     all,   heros,   wear,   capes]
    #      x = [not,     all,   heroes,  wear]
    #      y = [all,  heroes,     wear,  capes]
    #
    # of course, we don&#x27;t have a label for inputs[-1], so we exclude it from x
    #
    # as such, for N inputs, we have N - 1 language modeling example pairs
    x, y = inputs[:-1], inputs[1:] # both have shape [num_tokens_in_seq - 1]

    # forward pass
    # all the predicted next token probability distributions at each position
    output = gpt(x, params) # has shape [num_tokens_in_seq - 1, num_tokens_in_vocab]

    # cross entropy loss
    # we take the average over all N-1 examples
    loss = np.mean(-np.log(output[np.arange(len(output)), y]))

    return loss

def train(texts: list[list[str]], params) -&gt; float:
    for text in texts:
        inputs = tokenizer.encode(text)
        loss = lm_loss(inputs, params)
        gradients = compute_gradients_via_backpropagation(loss, params)
        params = gradient_descent_update_step(gradients, params)
    return params</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="sewWS7dCgr" class="myst-jp-nb-block relative group/block"><p>This is a heavily simplified training setup, but it illustrates the point. Notice the addition of <code>params</code> to our <code>gpt</code> function signature (we left this out in the previous sections for simplicity). During each iteration of the training loop:</p><ol start="1"><li><p>We compute the language modeling <strong>loss</strong> for the given input text example</p></li><li><p>The <strong>loss</strong> determines our gradients, which we compute via <strong>backprop</strong></p></li><li><p>We use the gradients to update our model parameters such that the <strong>loss</strong> is minimized (gradient descent)</p></li></ol><p>Notice, we don’t use explicitly labelled data. Instead, we are able to produce the input/label pairs from just the raw text itself. This is referred to as <a href="https://en.wikipedia.org/wiki/Self-supervised_learning" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">self-supervised learning</a>. Self-supervision enables us to massively scale training data. Just get our hands on as much raw text as possible and throw it at the model. For example, <strong>GPT</strong>-3 was trained on 300 billion tokens of text from the internet and books:</p></div><div id="t9m8KtjWbL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;table_2.2_gpt3_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="DB6F8jllVQw4ViYsvNDbI" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/a76b56e9630ed69223a51aa05e32ed05.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="r8nZczrn8R" class="myst-jp-nb-block relative group/block"><p>Of course, you need a sufficiently large model to be able to learn from all this data, which is why <strong>GPT</strong>-3 has 175 billion parameters and probably cost between <a target="_blank" rel="noreferrer" href="https://twitter.com/eturner303/status/1266264358771757057" class="link">$1m-10m in compute cost to train<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. This self-supervised training step is called pre-training, since we can reuse the “pre-trained” models weights to further train the model on downstream tasks, such as classifying if a tweet is toxic or not. Pre-trained models are also sometimes called foundation models. Training the model on downstream tasks is called fine-tuning, since the model weights have already been pre-trained to understand language, it’s just being fine-tuned to the specific task at hand. The “pre-training on a general task + fine-tuning on a specific task” strategy is called <a href="https://en.wikipedia.org/wiki/Transfer_learning" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">transfer learning</a>.</p><p><em>Note</em>: Although, with the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2210.11416.pdf" class="link">InstructGPT<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2203.15556.pdf" class="link">Chinchilla<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> papers, we’ve realized that we don’t actually need to train models that big. An optimally trained and instruction fine-tuned <strong>GPT</strong> at 1.3B parameters can outperform <strong>GPT</strong>-3 at 175B parameters.</p></div><div id="OqplaXLSJI" class="myst-jp-nb-block relative group/block"><h3 id="prompting" class="relative group"><span class="heading-text">Prompting</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#prompting" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="PHDXf3r3eH" class="myst-jp-nb-block relative group/block"><p>In principle, the original <a target="_blank" rel="noreferrer" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" class="link"><strong>GPT</strong><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> paper was only about the benefits of pre-training a transformer model for transfer learning. The paper showed that pre-training a 117M <strong>GPT</strong> achieved state-of-the-art performance on various NLP (natural language processing) tasks when fine-tuned on labelled datasets. It wasn’t until the <a target="_blank" rel="noreferrer" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" class="link"><strong>GPT</strong>-2<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/2005.14165" class="link"><strong>GPT</strong>-3<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> papers that we realized a <strong>GPT</strong> model pre-trained on enough data with enough parameters was capable of performing any arbitrary task by itself, no fine-tuning needed. Just prompt the model, perform autoregressive language modeling, and voila, the model magically gives us an appropriate response. This is referred to as in-context learning, because the model is using just the context of the prompt to perform the task. In-context learning can be zero shot, one shot, or few shot:</p></div><div id="ZNmdNyEPQO" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;fig_2.1_gpt3_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="q9eu4G4YwzjFGb10CjXwV" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/601e5b77d2987b0a7552484cf5cc5925.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="oSDe4KRmxn" class="myst-jp-nb-block relative group/block"><p>Generating text given a prompt is also sometimes referred to as conditional generation, since our model is generating some output conditioned on some input. <strong>GPT</strong>s are not limited to NLP tasks. You can condition the model on anything you want. For example, you can turn a <strong>GPT</strong> into a chatbot (i.e. <a target="_blank" rel="noreferrer" href="https://openai.com/index/chatgpt/" class="link">Chat<strong>GPT</strong><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>) by conditioning it on the conversation history. You can also further condition the chatbot to behave a certain way by prepending the prompt with some kind of description (i.e. “You are a chatbot. Be polite, speak in full sentences, don’t say harmful things, etc ...”). Conditioning the model like this can even give your <a target="_blank" rel="noreferrer" href="https://imgur.com/a/AbDFcgk" class="link">chatbot a persona<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. This is often referred to as a system prompt. However, this is not robust, you can still <a target="_blank" rel="noreferrer" href="https://twitter.com/zswitten/status/1598380220943593472" class="link">“jailbreak” the model and make it misbehave<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. With that out of the way, let’s finally get to the actual implementation.</p></div><div id="UEw57GKpei" class="myst-jp-nb-block relative group/block"><h2 id="setup" class="relative group"><span class="heading-text">Setup</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#setup" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="w71u2InFid" class="myst-jp-nb-block relative group/block"><p>Let’s dive right into the <strong>GPT</strong> implementation. First though, let’s define the necessary functions for downloading the model of our choice and the tokenizer files for  loading <code>encoder</code>, <code>hparams</code>, and <code>params</code> into our code:</p></div><div id="OSMZBFc3dT" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">&quot;&quot;&quot;Byte pair encoding utilities.

Contains the code for OpenAI&#x27;s BPE Tokenizer, taken straight from their gpt-2 repo: https://github.com/openai/gpt-2/blob/master/src/encoder.py.
&quot;&quot;&quot;

import json
import os
from functools import lru_cache
import regex as re


@lru_cache()
def bytes_to_unicode():
    &quot;&quot;&quot;
    Returns list of utf-8 byte and a corresponding list of unicode strings.
    The reversible bpe codes work on unicode strings.
    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.
    When you&#x27;re at something like a 10B token dataset you end up needing around 5K for decent coverage.
    This is a significant percentage of your normal, say, 32K bpe vocab.
    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.
    And avoids mapping to whitespace/control characters the bpe code barfs on.
    &quot;&quot;&quot;
    bs = (
        list(range(ord(&quot;!&quot;), ord(&quot;~&quot;) + 1))
        + list(range(ord(&quot;¡&quot;), ord(&quot;¬&quot;) + 1))
        + list(range(ord(&quot;®&quot;), ord(&quot;ÿ&quot;) + 1))
    )
    cs = bs[:]
    n = 0
    for b in range(2**8):
        if b not in bs:
            bs.append(b)
            cs.append(2**8 + n)
            n += 1
    cs = [chr(n) for n in cs]
    return dict(zip(bs, cs))


def get_pairs(word):
    &quot;&quot;&quot;Return set of symbol pairs in a word.
    Word is represented as tuple of symbols (symbols being variable-length strings).
    &quot;&quot;&quot;
    pairs = set()
    prev_char = word[0]
    for char in word[1:]:
        pairs.add((prev_char, char))
        prev_char = char
    return pairs


class Encoder:
    def __init__(self, encoder, bpe_merges, errors=&quot;replace&quot;):
        self.encoder = encoder
        self.decoder = {v: k for k, v in self.encoder.items()}
        self.errors = errors  # how to handle errors in decoding
        self.byte_encoder = bytes_to_unicode()
        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}
        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))
        self.cache = {}

        # Should have added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions
        self.pat = re.compile(
            r&quot;&quot;&quot;&#x27;s|&#x27;t|&#x27;re|&#x27;ve|&#x27;m|&#x27;ll|&#x27;d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+&quot;&quot;&quot;
        )

    def bpe(self, token):
        if token in self.cache:
            return self.cache[token]
        word = tuple(token)
        pairs = get_pairs(word)

        if not pairs:
            return token

        while True:
            bigram = min(pairs, key=lambda pair: self.bpe_ranks.get(pair, float(&quot;inf&quot;)))
            if bigram not in self.bpe_ranks:
                break
            first, second = bigram
            new_word = []
            i = 0
            while i &lt; len(word):
                try:
                    j = word.index(first, i)
                    new_word.extend(word[i:j])
                    i = j
                except:
                    new_word.extend(word[i:])
                    break

                if word[i] == first and i &lt; len(word) - 1 and word[i + 1] == second:
                    new_word.append(first + second)
                    i += 2
                else:
                    new_word.append(word[i])
                    i += 1
            new_word = tuple(new_word)
            word = new_word
            if len(word) == 1:
                break
            else:
                pairs = get_pairs(word)
        word = &quot; &quot;.join(word)
        self.cache[token] = word
        return word

    def encode(self, text):
        bpe_tokens = []
        for token in re.findall(self.pat, text):
            token = &quot;&quot;.join(self.byte_encoder[b] for b in token.encode(&quot;utf-8&quot;))
            bpe_tokens.extend(
                self.encoder[bpe_token] for bpe_token in self.bpe(token).split(&quot; &quot;)
            )
        return bpe_tokens

    def decode(self, tokens):
        text = &quot;&quot;.join([self.decoder[token] for token in tokens])
        text = bytearray([self.byte_decoder[c] for c in text]).decode(
            &quot;utf-8&quot;, errors=self.errors
        )
        return text


def get_encoder(model_name, models_dir):
    with open(os.path.join(models_dir, model_name, &quot;encoder.json&quot;), &quot;r&quot;) as f:
        encoder = json.load(f)
    with open(
        os.path.join(models_dir, model_name, &quot;vocab.bpe&quot;), &quot;r&quot;, encoding=&quot;utf-8&quot;
    ) as f:
        bpe_data = f.read()
    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split(&quot;\n&quot;)[1:-1]]
    return Encoder(encoder=encoder, bpe_merges=bpe_merges)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="5y7haKoAEkwkZtl4ELx4h" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="dCCRB3nfne" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">&quot;&quot;&quot;GPT-2 utilities.

Contains the code to download and load the GPT-2 model weights, tokenizer, and hyperparameters.
&quot;&quot;&quot;

import json
import os
import requests
import tensorflow as tf
from tqdm import tqdm


def download_gpt2_files(model_size, model_dir):
    assert model_size in [&quot;124M&quot;, &quot;355M&quot;, &quot;774M&quot;, &quot;1558M&quot;]
    for filename in [
        &quot;checkpoint&quot;,
        &quot;encoder.json&quot;,
        &quot;hparams.json&quot;,
        &quot;model.ckpt.data-00000-of-00001&quot;,
        &quot;model.ckpt.index&quot;,
        &quot;model.ckpt.meta&quot;,
        &quot;vocab.bpe&quot;,
    ]:
        url = &quot;https://openaipublic.blob.core.windows.net/gpt-2/models&quot;
        r = requests.get(f&quot;{url}/{model_size}/{filename}&quot;, stream=True)
        r.raise_for_status()

        with open(os.path.join(model_dir, filename), &quot;wb&quot;) as f:
            file_size = int(r.headers[&quot;content-length&quot;])
            chunk_size = 1000
            with tqdm(
                ncols=100,
                desc=&quot;Fetching &quot; + filename,
                total=file_size,
                unit_scale=True,
            ) as pbar:
                # 1k for chunk_size, since Ethernet packet size is around 1500 bytes
                for chunk in r.iter_content(chunk_size=chunk_size):
                    f.write(chunk)
                    pbar.update(chunk_size)


def load_gpt2_params_from_tf_ckpt(tf_ckpt_path, hparams):
    import re
    import numpy as np

    def set_in_nested_dict(d, keys, val):
        if not keys:
            return val
        if keys[0] not in d:
            d[keys[0]] = {}
        d[keys[0]] = set_in_nested_dict(d[keys[0]], keys[1:], val)
        return d

    init_vars = tf.train.list_variables(tf_ckpt_path)
    params = {&quot;blocks&quot;: [{} for _ in range(hparams[&quot;n_layer&quot;])]}
    for name, _ in init_vars:
        array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))
        name = name.removeprefix(&quot;model/&quot;)
        if name.startswith(&quot;h&quot;):
            m = re.match(r&quot;h([0-9]+)/(.*)&quot;, name)
            n = int(m[1])
            sub_name = m[2]
            set_in_nested_dict(params[&quot;blocks&quot;][n], sub_name.split(&quot;/&quot;), array)
        else:
            set_in_nested_dict(params, name.split(&quot;/&quot;), array)

    return params


def load_encoder_hparams_and_params(model_size, models_dir):
    assert model_size in [&quot;124M&quot;, &quot;355M&quot;, &quot;774M&quot;, &quot;1558M&quot;]

    model_dir = os.path.join(models_dir, model_size)
    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)
    if not tf_ckpt_path:  # download files if necessary
        os.makedirs(model_dir, exist_ok=True)
        download_gpt2_files(model_size, model_dir)
        tf_ckpt_path = tf.train.latest_checkpoint(model_dir)

    encoder = get_encoder(model_size, models_dir)
    hparams = json.load(open(os.path.join(model_dir, &quot;hparams.json&quot;)))
    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, hparams)

    return encoder, hparams, params</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="xArouRSHotEcSwLbQKeqU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>2025-02-18 12:27:24.663897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739899644.722397 1472589 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739899644.738680 1472589 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-18 12:27:24.870881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</span></code></pre></div></div></div></div><div id="lgsB1O4bjA" class="myst-jp-nb-block relative group/block"><p>Cool. Having defined the necessary utilities, we will now define the prompt and generation functions:</p></div><div id="Mp0z10ZcnK" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import numpy as np


def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):
    pass  # TODO: implement this


def generate(inputs, params, n_head, n_tokens_to_generate):
    for _ in tqdm(
        range(n_tokens_to_generate), &quot;generating&quot;
    ):  # auto-regressive decode loop
        logits = gpt2(inputs, **params, n_head=n_head)  # model forward pass
        next_id = np.argmax(logits[-1])  # greedy sampling
        inputs.append(int(next_id))  # append prediction to input

    return inputs[len(inputs) - n_tokens_to_generate :]  # only return generated ids


def prompt_gpt(
    prompt: str,
    n_tokens_to_generate: int = 40,
    model_size: str = &quot;124M&quot;,
    models_dir: str = &quot;models&quot;,
):
    # load encoder, hparams, and params from the released open-ai gpt-2 files
    encoder, hparams, params = load_encoder_hparams_and_params(model_size, models_dir)
    # map numpy arrays to jax arrays if jax is installed (in case saved params contain numpy arrays)
    if np.__name__ == &quot;jax.numpy&quot;:
        import jax.tree_util as jtu

        params = jtu.tree_map(
            lambda x: np.array(x) if isinstance(x, np.ndarray) else x, params
        )
    # encode the input string using the BPE tokenizer
    input_ids = encoder.encode(prompt)
    # make sure we are not surpassing the max sequence length of our model
    assert len(input_ids) + n_tokens_to_generate &lt; hparams[&quot;n_ctx&quot;]
    # generate output ids
    output_ids = generate(input_ids, params, hparams[&quot;n_head&quot;], n_tokens_to_generate)
    # decode the ids back into a string
    output_text = encoder.decode(output_ids)
    return output_text</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="q9msgVBBZUcaxMcedwY-M" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="OXT34dG4KB" class="myst-jp-nb-block relative group/block"><p>Breaking down each of the <!-- -->4<!-- --> sections:</p><ol start="1"><li><p>The <code>gpt2</code> function is the actual <strong>GPT</strong> code we’ll be implementing. You’ll notice that the function signature includes some extra stuff in addition to <code>inputs</code>:</p><ul><li><p><code>wte</code>, <code>wpe</code>, <code>blocks</code>, and <code>ln_f</code> are the parameters of our model.</p></li><li><p><code>n_head</code> is a hyperparameter that is needed during the forward pass.</p></li></ul></li><li><p>The <code>generate</code> function is the autoregressive decoding algorithm we saw earlier. We use greedy sampling for simplicity. <code>tqdm</code> is a progress bar to help us visualize the decoding process as it generates tokens one at a time.</p></li><li><p>The <code>prompt_gpt</code> function handles:</p><ul><li><p>Loading the tokenizer (<code>encoder</code>), model weights (<code>params</code>), and hyperparameters (<code>hparams</code>)</p></li><li><p>Encoding the input prompt into token IDs using the tokenizer</p></li><li><p>Calling the <code>generate</code> function</p></li><li><p>Decoding the output IDs into a string</p></li></ul></li></ol></div><div id="VeK3zY8UjK" class="myst-jp-nb-block relative group/block"><h3 id="encoder" class="relative group"><span class="heading-text">Encoder</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#encoder" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="ARuYxWflrW" class="myst-jp-nb-block relative group/block"><p>Take a closer look at the following call:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">encoder, hparams, params = load_encoder_hparams_and_params(&quot;124M&quot;, &quot;models&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>This will download the necessary model and tokenizer files into <code>models/124M</code> and load <code>encoder</code>, <code>hparams</code>, and <code>params</code> into our code. Let’s give it a try (may take some minutes, depending on your connection speed):</p></div><div id="QGAFoH1jXX" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">encoder, hparams, params = load_encoder_hparams_and_params(&quot;124M&quot;, &quot;models&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="H0t3twmbaRDulHd23R1hy" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>2025-02-18 12:27:28.665923: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.
</span></code></pre></div></div></div></div><div id="zDsNS6vcjb" class="myst-jp-nb-block relative group/block"><p>Now, let’s encode a prompt and see the <code>ids</code> it returns. Let’s then decode and verify that we get the same prompt back:</p></div><div id="dLPxZMVQ86" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">prompt = &quot;Not all heroes wear capes.&quot;
ids = encoder.encode(prompt)
print(ids)
prompt_decoded = encoder.decode(ids)
print(prompt_decoded)
assert prompt == prompt_decoded</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="dsXug_mA1NNvth2B4wA7n" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>[3673, 477, 10281, 5806, 1451, 274, 13]
Not all heroes wear capes.
</span></code></pre></div></div></div></div><div id="WlYjjz9oly" class="myst-jp-nb-block relative group/block"><p>We do, indeed. Cool! Using the vocabulary of the tokenizer (stored in <code>encoder.decoder</code>), we can take a peek at what the actual tokens look like:</p></div><div id="ahRly4JLRn" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">[encoder.decoder[i] for i in ids]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="j-h_eWZqsxdqi4a_uuN8r" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>[&#x27;Not&#x27;, &#x27;Ġall&#x27;, &#x27;Ġheroes&#x27;, &#x27;Ġwear&#x27;, &#x27;Ġcap&#x27;, &#x27;es&#x27;, &#x27;.&#x27;]</span></code></div></div></div><div id="XE061E2LoC" class="myst-jp-nb-block relative group/block"><p>Interesting. Notice how sometimes our tokens are words (e.g. <code>Not</code>), sometimes they are words but with a space in front of them (e.g. <code>Ġall</code>, the <a href="https://github.com/karpathy/minGPT/blob/37baab71b9abea1b76ab957409a1cc2fbfba8a26/mingpt/bpe.py#L22-L33" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">Ġ represents a space</a>), sometimes there are part of a word (e.g. capes is split into <code>Ġcap</code> and <code>es</code>), and sometimes they are punctuation (e.g. <code>.</code>). One nice thing about BPE is that it can encode any arbitrary string. If it encounters something that is not present in the vocabulary, it just breaks it down into substrings it does understand:</p></div><div id="yHP0VQYyTC" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">[encoder.decoder[i] for i in encoder.encode(&quot;zjqfl&quot;)]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="137fLfwHpASPm-OZysXWC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>[&#x27;z&#x27;, &#x27;j&#x27;, &#x27;q&#x27;, &#x27;fl&#x27;]</span></code></div></div></div><div id="ok3xEWVNqZ" class="myst-jp-nb-block relative group/block"><p>We can also check the size of the vocabulary:</p></div><div id="UtdKFC8aII" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">len(encoder.decoder)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="AF3F38wK2oVzEXaYmt0Xo" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>50257</span></code></div></div></div><div id="tm020GrP53" class="myst-jp-nb-block relative group/block"><p>The vocabulary, as well as the byte-pair merges which determines how strings are broken down, is obtained by <em>training</em> the tokenizer. When we load the tokenizer, we’re loading the already trained vocab and byte-pair merges from some files, which were downloaded alongside the model files when we ran <code>load_encoder_hparams_and_params</code>. See the files <code>models/124M/encoder.json</code> (the vocabulary) and <code>models/124M/vocab.bpe</code> (byte-pair merges).</p></div><div id="WNtHfDfrO9" class="myst-jp-nb-block relative group/block"><h3 id="hyperparameters" class="relative group"><span class="heading-text">Hyperparameters</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#hyperparameters" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="QKy9HBk7A0" class="myst-jp-nb-block relative group/block"><p><code>hparams</code> is a dictionary that contains the hyper-parameters of our model:</p></div><div id="HGRAVb7fWZ" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">hparams</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="UmS4NrTobuY5G1oqxkHDg" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>{&#x27;n_vocab&#x27;: 50257, &#x27;n_ctx&#x27;: 1024, &#x27;n_embd&#x27;: 768, &#x27;n_head&#x27;: 12, &#x27;n_layer&#x27;: 12}</span></code></div></div></div><div id="uArdlUFNa1" class="myst-jp-nb-block relative group/block"><p>Here’s what each key refers to:</p><ul><li><p><code>n_vocab</code>: number of tokens in our vocabulary</p></li><li><p><code>n_ctx</code>: maximum possible sequence length of the input</p></li><li><p><code>n_embd</code>: embedding dimension (determines the “width” of the network)</p></li><li><p><code>n_head</code>: number of attention heads (n_embd must be divisible by n_head)</p></li><li><p><code>n_layer</code>: number of layers (determines the “depth” of the network)</p></li></ul><p>We’ll use these symbols in our code’s comments to show the underlying shape of things. We’ll also use <code>n_seq</code> to denote the length of our input sequence (i.e. <code>n_seq = len(inputs)</code>).</p></div><div id="kbWgAAzvYR" class="myst-jp-nb-block relative group/block"><h3 id="parameters" class="relative group"><span class="heading-text">Parameters</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#parameters" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="JZc8daiZte" class="myst-jp-nb-block relative group/block"><p><code>params</code> is a nested json dictionary that hold the trained weights of our model. The leaf nodes of the json are NumPy arrays. If we print <code>params</code>, replacing the arrays with their shapes, we get:</p></div><div id="IOR3rxWAJp" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import numpy as np


def shape_tree(d):
    if isinstance(d, np.ndarray):
        return list(d.shape)
    elif isinstance(d, list):
        return [shape_tree(v) for v in d]
    elif isinstance(d, dict):
        return {k: shape_tree(v) for k, v in d.items()}
    else:
        ValueError(&quot;uh oh&quot;)


shape_tree(params)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="7zCS_egkZ_V5oAGYFNCni" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>{&#x27;blocks&#x27;: [{&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}},
  {&#x27;attn&#x27;: {&#x27;c_attn&#x27;: {&#x27;b&#x27;: [2304], &#x27;w&#x27;: [768, 2304]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [768, 768]}},
   &#x27;ln_1&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;ln_2&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
   &#x27;mlp&#x27;: {&#x27;c_fc&#x27;: {&#x27;b&#x27;: [3072], &#x27;w&#x27;: [768, 3072]},
    &#x27;c_proj&#x27;: {&#x27;b&#x27;: [768], &#x27;w&#x27;: [3072, 768]}}}],
 &#x27;ln_f&#x27;: {&#x27;b&#x27;: [768], &#x27;g&#x27;: [768]},
 &#x27;wpe&#x27;: [1024, 768],
 &#x27;wte&#x27;: [50257, 768]}</span></code></div></div></div><div id="vT76NMdAit" class="myst-jp-nb-block relative group/block"><p>where each dictionary inside the <code>&#x27;blocks&#x27;</code> list contains the weights information for each layer (<code>n_layers</code> total). These weights are loaded from the original OpenAI tensorflow checkpoint:</p></div><div id="yQCTneGUSv" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import tensorflow as tf

tf_ckpt_path = tf.train.latest_checkpoint(&quot;models/124M&quot;)
for name, _ in tf.train.list_variables(tf_ckpt_path):
    arr = tf.train.load_variable(tf_ckpt_path, name).squeeze()
    print(f&quot;{name}: {arr.shape}&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="L73r1sPdszehmGYfnTxDp" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>model/h0/attn/c_attn/b: (2304,)
model/h0/attn/c_attn/w: (768, 2304)
model/h0/attn/c_proj/b: (768,)
model/h0/attn/c_proj/w: (768, 768)
model/h0/ln_1/b: (768,)
model/h0/ln_1/g: (768,)
model/h0/ln_2/b: (768,)
model/h0/ln_2/g: (768,)
model/h0/mlp/c_fc/b: (3072,)
model/h0/mlp/c_fc/w: (768, 3072)
model/h0/mlp/c_proj/b: (768,)
model/h0/mlp/c_proj/w: (3072, 768)
model/h1/attn/c_attn/b: (2304,)
model/h1/attn/c_attn/w: (768, 2304)
model/h1/attn/c_proj/b: (768,)
model/h1/attn/c_proj/w: (768, 768)
model/h1/ln_1/b: (768,)
model/h1/ln_1/g: (768,)
model/h1/ln_2/b: (768,)
model/h1/ln_2/g: (768,)
model/h1/mlp/c_fc/b: (3072,)
model/h1/mlp/c_fc/w: (768, 3072)
model/h1/mlp/c_proj/b: (768,)
model/h1/mlp/c_proj/w: (3072, 768)
model/h10/attn/c_attn/b: (2304,)
model/h10/attn/c_attn/w: (768, 2304)
model/h10/attn/c_proj/b: (768,)
model/h10/attn/c_proj/w: (768, 768)
model/h10/ln_1/b: (768,)
model/h10/ln_1/g: (768,)
model/h10/ln_2/b: (768,)
model/h10/ln_2/g: (768,)
model/h10/mlp/c_fc/b: (3072,)
model/h10/mlp/c_fc/w: (768, 3072)
model/h10/mlp/c_proj/b: (768,)
model/h10/mlp/c_proj/w: (3072, 768)
model/h11/attn/c_attn/b: (2304,)
model/h11/attn/c_attn/w: (768, 2304)
model/h11/attn/c_proj/b: (768,)
model/h11/attn/c_proj/w: (768, 768)
model/h11/ln_1/b: (768,)
model/h11/ln_1/g: (768,)
model/h11/ln_2/b: (768,)
model/h11/ln_2/g: (768,)
model/h11/mlp/c_fc/b: (3072,)
model/h11/mlp/c_fc/w: (768, 3072)
model/h11/mlp/c_proj/b: (768,)
model/h11/mlp/c_proj/w: (3072, 768)
model/h2/attn/c_attn/b: (2304,)
model/h2/attn/c_attn/w: (768, 2304)
model/h2/attn/c_proj/b: (768,)
model/h2/attn/c_proj/w: (768, 768)
model/h2/ln_1/b: (768,)
model/h2/ln_1/g: (768,)
model/h2/ln_2/b: (768,)
model/h2/ln_2/g: (768,)
model/h2/mlp/c_fc/b: (3072,)
model/h2/mlp/c_fc/w: (768, 3072)
model/h2/mlp/c_proj/b: (768,)
model/h2/mlp/c_proj/w: (3072, 768)
model/h3/attn/c_attn/b: (2304,)
model/h3/attn/c_attn/w: (768, 2304)
model/h3/attn/c_proj/b: (768,)
model/h3/attn/c_proj/w: (768, 768)
model/h3/ln_1/b: (768,)
model/h3/ln_1/g: (768,)
model/h3/ln_2/b: (768,)
model/h3/ln_2/g: (768,)
model/h3/mlp/c_fc/b: (3072,)
model/h3/mlp/c_fc/w: (768, 3072)
model/h3/mlp/c_proj/b: (768,)
model/h3/mlp/c_proj/w: (3072, 768)
model/h4/attn/c_attn/b: (2304,)
model/h4/attn/c_attn/w: (768, 2304)
model/h4/attn/c_proj/b: (768,)
model/h4/attn/c_proj/w: (768, 768)
model/h4/ln_1/b: (768,)
model/h4/ln_1/g: (768,)
model/h4/ln_2/b: (768,)
model/h4/ln_2/g: (768,)
model/h4/mlp/c_fc/b: (3072,)
model/h4/mlp/c_fc/w: (768, 3072)
model/h4/mlp/c_proj/b: (768,)
model/h4/mlp/c_proj/w: (3072, 768)
model/h5/attn/c_attn/b: (2304,)
model/h5/attn/c_attn/w: (768, 2304)
model/h5/attn/c_proj/b: (768,)
model/h5/attn/c_proj/w: (768, 768)
model/h5/ln_1/b: (768,)
model/h5/ln_1/g: (768,)
model/h5/ln_2/b: (768,)
model/h5/ln_2/g: (768,)
model/h5/mlp/c_fc/b: (3072,)
model/h5/mlp/c_fc/w: (768, 3072)
model/h5/mlp/c_proj/b: (768,)
model/h5/mlp/c_proj/w: (3072, 768)
model/h6/attn/c_attn/b: (2304,)
model/h6/attn/c_attn/w: (768, 2304)
model/h6/attn/c_proj/b: (768,)
model/h6/attn/c_proj/w: (768, 768)
model/h6/ln_1/b: (768,)
model/h6/ln_1/g: (768,)
model/h6/ln_2/b: (768,)
model/h6/ln_2/g: (768,)
model/h6/mlp/c_fc/b: (3072,)
model/h6/mlp/c_fc/w: (768, 3072)
model/h6/mlp/c_proj/b: (768,)
model/h6/mlp/c_proj/w: (3072, 768)
model/h7/attn/c_attn/b: (2304,)
model/h7/attn/c_attn/w: (768, 2304)
model/h7/attn/c_proj/b: (768,)
model/h7/attn/c_proj/w: (768, 768)
model/h7/ln_1/b: (768,)
model/h7/ln_1/g: (768,)
model/h7/ln_2/b: (768,)
model/h7/ln_2/g: (768,)
model/h7/mlp/c_fc/b: (3072,)
model/h7/mlp/c_fc/w: (768, 3072)
model/h7/mlp/c_proj/b: (768,)
model/h7/mlp/c_proj/w: (3072, 768)
model/h8/attn/c_attn/b: (2304,)
model/h8/attn/c_attn/w: (768, 2304)
model/h8/attn/c_proj/b: (768,)
model/h8/attn/c_proj/w: (768, 768)
model/h8/ln_1/b: (768,)
model/h8/ln_1/g: (768,)
model/h8/ln_2/b: (768,)
model/h8/ln_2/g: (768,)
model/h8/mlp/c_fc/b: (3072,)
model/h8/mlp/c_fc/w: (768, 3072)
model/h8/mlp/c_proj/b: (768,)
model/h8/mlp/c_proj/w: (3072, 768)
model/h9/attn/c_attn/b: (2304,)
model/h9/attn/c_attn/w: (768, 2304)
model/h9/attn/c_proj/b: (768,)
model/h9/attn/c_proj/w: (768, 768)
model/h9/ln_1/b: (768,)
model/h9/ln_1/g: (768,)
model/h9/ln_2/b: (768,)
model/h9/ln_2/g: (768,)
model/h9/mlp/c_fc/b: (3072,)
model/h9/mlp/c_fc/w: (768, 3072)
model/h9/mlp/c_proj/b: (768,)
model/h9/mlp/c_proj/w: (3072, 768)
model/ln_f/b: (768,)
model/ln_f/g: (768,)
model/wpe: (1024, 768)
model/wte: (50257, 768)
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>2025-02-18 12:27:29.143545: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.
</span></code></pre></div></div></div></div><div id="zZSlFizTkV" class="myst-jp-nb-block relative group/block"><p>The <code>load_gpt2_params_from_tf_ckpt</code> function converts the above tensorflow variables into our <code>params</code> dictionary. For reference, here’s the shapes of <code>params</code> but with the numbers replaced by the <code>hparams</code> they represent:</p></div><div id="OEI7n02rTH" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">{
    &quot;wpe&quot;: [n_ctx, n_embd],
    &quot;wte&quot;: [n_vocab, n_embd],
    &quot;ln_f&quot;: {&quot;b&quot;: [n_embd], &quot;g&quot;: [n_embd]},
    &quot;blocks&quot;: [
        {
            &quot;attn&quot;: {
                &quot;c_attn&quot;: {&quot;b&quot;: [3*n_embd], &quot;w&quot;: [n_embd, 3*n_embd]},
                &quot;c_proj&quot;: {&quot;b&quot;: [n_embd], &quot;w&quot;: [n_embd, n_embd]},
            },
            &quot;ln_1&quot;: {&quot;b&quot;: [n_embd], &quot;g&quot;: [n_embd]},
            &quot;ln_2&quot;: {&quot;b&quot;: [n_embd], &quot;g&quot;: [n_embd]},
            &quot;mlp&quot;: {
                &quot;c_fc&quot;: {&quot;b&quot;: [4*n_embd], &quot;w&quot;: [n_embd, 4*n_embd]},
                &quot;c_proj&quot;: {&quot;b&quot;: [n_embd], &quot;w&quot;: [4*n_embd, n_embd]},
            },
        },
        ... # repeat for n_layers
    ]
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="q4suYhi8bH" class="myst-jp-nb-block relative group/block"><p>You’ll probably want to come back to reference this dictionary to check the shape of the weights as we implement our <strong>GPT</strong>. We’ll match the variable names in our code with the keys of this dictionary for consistency.</p></div><div id="j8Eyc0HF6e" class="myst-jp-nb-block relative group/block"><h2 id="basic-layers" class="relative group"><span class="heading-text">Basic Layers</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#basic-layers" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="SCuDnmv95D" class="myst-jp-nb-block relative group/block"><p>Last thing before we get into the actual <strong>GPT</strong> architecture itself, let’s implement some of the more basic <strong>nn</strong> layers that are non-specific to <strong>GPT</strong>s.</p></div><div id="GSauKBxgDm" class="myst-jp-nb-block relative group/block"><h3 id="gelu" class="relative group"><span class="heading-text">GELU</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gelu" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="yyRPlvMdSU" class="myst-jp-nb-block relative group/block"><p>The non-linearity (activation function) of choice for <strong>GPT</strong>-2 is GELU (Gaussian Error Linear Units), an alternative for ReLU:</p></div><div id="O5g9RBOibL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;fig_1_from_gelu_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="qIRWi90DNdpksrVyyMpFO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/bf801b993f69576d9a242672d2ba329c.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="CyuWWHCgIZ" class="myst-jp-nb-block relative group/block"><p>It is approximated by the following function:</p></div><div id="Zu8WFYVsyD" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def gelu(x):
    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="623Ewu_RYKkI_IEVZZa53" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="idubH7qdSL" class="myst-jp-nb-block relative group/block"><p>Like ReLU, GELU operates element-wise on the input:</p></div><div id="Tk3HGJGoeE" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">gelu(np.array([[1, 2], [-2, 0.5]]))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="kkQIFHXrLEzSFumTehJ6F" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>array([[ 0.84119199,  1.95459769],
       [-0.04540231,  0.34571401]])</span></code></div></div></div><div id="Qs2CEzH6Lh" class="myst-jp-nb-block relative group/block"><h3 id="softmax" class="relative group"><span class="heading-text">Softmax</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#softmax" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="iq6Yk9RStg" class="myst-jp-nb-block relative group/block"><p>Good ole <a href="https://en.wikipedia.org/wiki/Softmax_function" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">softmax</a>:</p></div><div id="HiXLvPxtlA" class="myst-jp-nb-block relative group/block"><div id="mr7RjoMvrS" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>softmax</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><msub><mi>x</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4632em;vertical-align:-1.1218em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#mr7RjoMvrS" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->1<!-- -->)</a></div></div></div><div id="FeWaxoMbgR" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def softmax(x):
    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="RS4KbTLNEwLAp-Jdyq1uE" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="skyYwut1PP" class="myst-jp-nb-block relative group/block"><p>We use the <a target="_blank" rel="noreferrer" href="https://jaykmody.com/blog/stable-softmax/" class="link">max(x) trick for numerical stability<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. Softmax is used to a convert set of real numbers (between <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">-\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">∞</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord">∞</span></span></span></span></span>) to probabilities (between <!-- -->0<!-- --> and <!-- -->1<!-- -->, with the numbers all summing to <!-- -->1<!-- -->). We apply <code>softmax</code> over the last axis of the input.</p></div><div id="Algc1jWEsc" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">x = softmax(np.array([[2, 100], [-5, 0]]))
x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Cd_DDa_Jw2CfeWRugv6n-" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>array([[2.74878501e-43, 1.00000000e+00],
       [6.69285092e-03, 9.93307149e-01]])</span></code></div></div></div><div id="PnnqSCRZbA" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">x.sum(axis=-1)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="VoT1GQ7TevpFem1HgkqHP" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>array([1., 1.])</span></code></div></div></div><div id="R5t4UpZYfI" class="myst-jp-nb-block relative group/block"><h3 id="layer-normalization" class="relative group"><span class="heading-text">Layer Normalization</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#layer-normalization" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="mLpL7efPbt" class="myst-jp-nb-block relative group/block"><p><a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1607.06450.pdf" class="link">Layer normalization<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> standardizes values to have a mean of <code>0</code> and a variance of <code>1</code>:</p><div id="H0zh15DXSa" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>LayerNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>γ</mi><mo>⋅</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\text{LayerNorm}(x) = \gamma\cdot\frac{x - \mu}{\sigma} + \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">LayerNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.9463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#H0zh15DXSa" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->2<!-- -->)</a></div></div><p>where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span></span> is the mean of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span> is the variance of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>, and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span> are learnable parameters.</p></div><div id="mYtZESF8we" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def layer_norm(x, g, b, eps: float = 1e-5):
    mean = np.mean(x, axis=-1, keepdims=True)
    variance = np.var(x, axis=-1, keepdims=True)
    x = (x - mean) / np.sqrt(
        variance + eps
    )  # normalize x to have mean=0 and var=1 over last axis
    return g * x + b  # scale and offset with gamma/beta params</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="7QQIYH84rLwqPyV4VnyEW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Wov8ywV6Mh" class="myst-jp-nb-block relative group/block"><p>Layer normalization ensures that the inputs for each layer are always within a consistent range, which is supposed to speed up and stabilize the training process. Like <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1502.03167.pdf" class="link"><strong>batchnorm</strong><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, the normalized output is then scaled and offset with two learnable vectors <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span>. The small epsilon term in the denominator (<code>eps</code>) is used to avoid a division by zero error. Layer norm is used instead of batch norm in the transformer for <a target="_blank" rel="noreferrer" href="https://stats.stackexchange.com/questions/474440/why-do-transformers-use-layer-norm-instead-of-batch-norm" class="link">various reasons<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. The differences between various normalization techniques is outlined in <a target="_blank" rel="noreferrer" href="https://tungmphung.com/deep-learning-normalization-methods/" class="link">this excellent blog post<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. We apply layer normalization over the last axis of the input:</p></div><div id="o3vUbU9A6w" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">x = np.array([[2, 2, 3], [-5, 0, 1]])
x = layer_norm(x, g=np.ones(x.shape[-1]), b=np.zeros(x.shape[-1]))
print(x)
print(&quot;var:&quot;, x.var(axis=-1))  # yields floating point shenanigans
print(&quot;mean:&quot;, x.mean(axis=-1))  # same here</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="6AHkZTNT48Yf2G7wXNI6Q" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>[[-0.70709087 -0.70709087  1.41418174]
 [-1.39700038  0.50800014  0.88900024]]
var: [0.999955   0.99999855]
mean: [-2.96059473e-16 -3.70074342e-17]
</span></code></pre></div></div></div></div><div id="xtt4i3h7SM" class="myst-jp-nb-block relative group/block"><h3 id="linear" class="relative group"><span class="heading-text">Linear</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#linear" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="NdHHJyiDBM" class="myst-jp-nb-block relative group/block"><p>Your standard matrix multiplication + bias:</p></div><div id="EHVSKdhPFS" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def linear(x, w, b):  # [m, in], [in, out], [out] -&gt; [m, out]
    return x @ w + b</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="7mW6n148IoE_Q7-mJFMZs" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="F97kikw9hP" class="myst-jp-nb-block relative group/block"><p>Linear layers are often referred to as projections (since they are projecting from one vector space to another vector space):</p></div><div id="mgAIj2FxaH" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">x = np.random.normal(size=(64, 784))  # input dim = 784, batch/sequence dim = 64
w = np.random.normal(size=(784, 10))  # output dim = 10
b = np.random.normal(size=(10,))
print(x.shape)  # shape before linear projection
print(linear(x, w, b).shape)  # shape after linear projection</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="U0HmQo3MPu1Dd9JSrSBsW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>(64, 784)
(64, 10)
</span></code></pre></div></div></div></div><div id="GXH4cbF8et" class="myst-jp-nb-block relative group/block"><h2 id="gpt-architecture" class="relative group"><span class="heading-text"><strong>GPT</strong> Architecture</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gpt-architecture" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="UTMACc3y2b" class="myst-jp-nb-block relative group/block"><p>The <strong>GPT</strong> architecture follows that of the transformer:</p></div><div id="snvnQgZYdT" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;fig_1_from_attention_is_all_you_need_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Cs7KLlIE4tKiPy6B_yRwf" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/95a2359853165c9eef927e4a752c43f9.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="WKZZIbWdp2" class="myst-jp-nb-block relative group/block"><p>But uses only the decoder stack (the right part of the diagram):</p></div><div id="xg7pdoLVTf" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;transformer_decoder_stack.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YWyMY4OiYLvthDCC7XTCe" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/1b391e61efa306561ab221327072a6f1.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="PZ1nM5KHuY" class="myst-jp-nb-block relative group/block"><p>Note, the middle “cross-attention” layer is also removed since we got rid of the encoder. At a high level, the <strong>GPT</strong> architecture has three sections:</p><ul><li><p>Text + positional embeddings</p></li><li><p>A transformer decoder stack</p></li><li><p>A projection to vocab step</p></li></ul><p>In code, it looks like this:</p></div><div id="oG9iP8jR8T" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):  # [n_seq] -&gt; [n_seq, n_vocab]
    # token + positional embeddings
    x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -&gt; [n_seq, n_embd]

    # forward pass through n_layer transformer blocks
    for block in blocks:
        x = transformer_block(
            x, **block, n_head=n_head
        )  # [n_seq, n_embd] -&gt; [n_seq, n_embd]

    # projection to vocab
    x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    return x @ wte.T  # [n_seq, n_embd] -&gt; [n_seq, n_vocab]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="RyKaeR5frl3nhgnO3cVzg" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="piyKbCtaS2" class="myst-jp-nb-block relative group/block"><p>Let’s break down each of these three sections into more detail.</p></div><div id="hDq8WWcw8y" class="myst-jp-nb-block relative group/block"><h3 id="embeddings" class="relative group"><span class="heading-text">Embeddings</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#embeddings" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="Dvzepm8QL2" class="myst-jp-nb-block relative group/block"><h4 id="token-embeddings" class="relative group"><span class="heading-text">Token Embeddings</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#token-embeddings" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="bRVThg558k" class="myst-jp-nb-block relative group/block"><p>Token IDs by themselves are not very good representations for a <strong>nn</strong>. For one, the relative magnitudes of the token IDs falsely communicate information (for example, if <code>Apple = 5</code> and <code>Table = 10</code> in our vocab, then we are implying that <code>2 * Apple = Table</code>). Secondly, a single number is not a lot of dimensionality for a <strong>nn</strong> to work with. To address these limitations, we’ll take advantage of <a target="_blank" rel="noreferrer" href="https://jaykmody.com/blog/attention-intuition/#word-vectors-and-similarity" class="link">word vectors<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, specifically via a learned embedding matrix:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">wte[inputs]  # [n_seq] -&gt; [n_seq, n_embd]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Recall, <code>wte</code> is a <code>[n_vocab, n_embd]</code> matrix. It acts as a lookup table, where the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> row in the matrix corresponds to the learned vector for the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> token in our vocabulary. <code>wte[inputs]</code> uses <a target="_blank" rel="noreferrer" href="https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing" class="link">integer array indexing<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> to retrieve the vectors corresponding to each token in our input. Like any other parameter in our network, <code>wte</code> is learned. That is, it is randomly initialized at the start of training and then updated via gradient descent.</p></div><div id="GoYZeTKgt0" class="myst-jp-nb-block relative group/block"><h4 id="positional-embeddings" class="relative group"><span class="heading-text">Positional Embeddings</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#positional-embeddings" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="v7aMwbaBnC" class="myst-jp-nb-block relative group/block"><p>One quirk of the transformer architecture is that it doesn’t take into account position. That is, if we randomly shuffled our input and then accordingly unshuffled the output, the output would be the same as if we never shuffled the input in the first place (the ordering of inputs doesn’t have any effect on the output). Of course, the ordering of words is a crucial part of language (duh), so we need some way to encode positional information into our inputs. For this, we can just use another learned embedding matrix:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">wpe[range(len(inputs))]  # [n_seq] -&gt; [n_seq, n_embd]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Recall, <code>wpe</code> is a <code>[n_ctx, n_embd]</code> matrix. The <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> row of the matrix contains a vector that encodes information about the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> position in the input. Similar to <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">wte</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">wt</span><span class="mord mathnormal">e</span></span></span></span></span>, this matrix is learned during gradient descent. Notice, this restricts our model to a maximum sequence length of <code>n_ctx</code>. That is, <code>len(inputs) &lt;= n_ctx</code> must hold.</p><p><em>Note</em>: The original transformer paper used a <a target="_blank" rel="noreferrer" href="https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding" class="link">calculated positional embedding<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> which they found performed just as well as learned positional embeddings, but has the distinct advantage that you can input any arbitrarily long sequence (you are not restricted by a maximum sequence length). However, in practice, your model is only going to be as the good sequence lengths that it was trained on. You can’t just train a <strong>GPT</strong> on sequences that are <!-- -->1024<!-- --> long and then expect it to perform well at 16k tokens long. Recently however, there has been some success with relative positional embeddings, such as <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2108.12409.pdf" class="link">Alibi<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2104.09864v4.pdf" class="link">RoPE<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></div><div id="tU9zdDg1JR" class="myst-jp-nb-block relative group/block"><h4 id="combined" class="relative group"><span class="heading-text">Combined</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#combined" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="UPqdlOq358" class="myst-jp-nb-block relative group/block"><p>We can add our token and positional embeddings to get a combined embedding that encodes both token and positional information:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># token + positional embeddings
x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -&gt; [n_seq, n_embd]

# x[i] represents the word embedding for the ith word + the positional
# embedding for the ith position</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="lfExYkMHGp" class="myst-jp-nb-block relative group/block"><h3 id="decoder-stack" class="relative group"><span class="heading-text">Decoder Stack</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#decoder-stack" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="aejACvZfve" class="myst-jp-nb-block relative group/block"><p>This is where all the magic happens and the “deep” in deep learning comes in. We pass our embedding through a stack of <code>n_layer</code> transformer decoder blocks:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># forward pass through n_layer transformer blocks
for block in blocks:
    x = transformer_block(
        x, **block, n_head=n_head
    )  # [n_seq, n_embd] -&gt; [n_seq, n_embd]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Stacking more layers is what allows us to control how deep our network is. <strong>GPT</strong>-3 for example, has a whopping <!-- -->96<!-- --> layers. On the other hand, choosing a larger <code>n_embd</code> value allows us to control how <em>wide</em> our network is (for example, <strong>GPT</strong>-3 uses an embedding size of <!-- -->12288<!-- -->).</p></div><div id="R1mK5gQcpm" class="myst-jp-nb-block relative group/block"><h3 id="projection-to-vocab" class="relative group"><span class="heading-text">Projection to Vocab</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#projection-to-vocab" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="XTgKhCfHxh" class="myst-jp-nb-block relative group/block"><p>In our final step, we project the output of the final transformer block to a probability distribution over our vocab:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># projection to vocab
x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
return x @ wte.T  # [n_seq, n_embd] -&gt; [n_seq, n_vocab]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Couple things to note here:</p><ol start="1"><li><p>We first pass <code>x</code> through a final layer normalization layer before doing the projection to vocab. This is specific to the <strong>GPT</strong>-2 architecture (this is not present in the original <strong>GPT</strong> and Transformer papers).</p></li><li><p>We are reusing the embedding matrix <code>wte</code> for the projection.  Other <strong>GPT</strong> implementations may choose to use a separate learned weight matrix for the projection, however sharing the embedding matrix has a couple of advantages:</p><ul><li><p>You save some parameters (although at <strong>GPT</strong>-3 scale, this is negligible).</p></li><li><p>Since the matrix is both responsible for mapping both <em>to</em> words and <em>from</em> words, in theory, it <em>may</em> learn a richer representation compared to having two separate matrixes.</p></li></ul></li><li><p>We don’t apply <code>softmax</code> at the end, so our outputs will be logits instead of probabilities between <!-- -->0<!-- --> and <!-- -->1<!-- -->. This is done for several reasons:</p><ul><li><p><code>softmax</code> is <a href="https://en.wikipedia.org/wiki/Monotonic_function" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">monotonic</a>, so for greedy sampling <code>np.argmax(logits)</code> is equivalent to <code>np.argmax(softmax(logits))</code> making <code>softmax</code> redundant</p></li><li><p><code>softmax</code> is irreversible, meaning we can always go from logits to probabilities by applying <code>softmax</code>, but we can’t go back to logits from probabilities, so for maximum flexibility, we output the logits</p></li><li><p>Numerically stability (for example, to compute cross entropy <strong>loss</strong>, taking <code>log(softmax(logits))</code> is numerically unstable compared to <code>log_softmax(logits)</code></p></li></ul></li></ol><p>The projection to vocab step is also sometimes called the language modeling head. What does “head” mean? Once your <strong>GPT</strong> is pre-trained, you can swap out the language modeling head with some other kind of projection, like a classification head for fine-tuning the model on some classification task. So your model can have multiple heads, kind of like a <a href="https://en.wikipedia.org/wiki/Lernaean_Hydra" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">hydra</a>. So that’s the <strong>GPT</strong> architecture at a high level, let’s actually dig a bit deeper into what the decoder blocks are doing.</p></div><div id="nz382V4Lor" class="myst-jp-nb-block relative group/block"><h3 id="decoder-block" class="relative group"><span class="heading-text">Decoder Block</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#decoder-block" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="XWJvmlrIjR" class="myst-jp-nb-block relative group/block"><p>The transformer decoder block consists of two sublayers:</p><ol start="1"><li><p>Multi-head causal self attention</p></li><li><p>Position-wise feed forward <strong>nn</strong></p></li></ol></div><div id="fzFyZBtTlG" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def transformer_block(
    x, mlp, attn, ln_1, ln_2, n_head
):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # multi-head causal self attention
    x = x + mha(
        layer_norm(x, **ln_1), **attn, n_head=n_head
    )  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # position-wise feed forward network
    x = x + ffn(layer_norm(x, **ln_2), **mlp)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="TandimmC9ZWvACigbrVq2" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="zc9kAvuI9u" class="myst-jp-nb-block relative group/block"><p>Each sublayer utilizes layer normalization on their inputs as well as a residual connection (i.e. add the input of the sublayer to the output of the sublayer). Some things to note:</p><ol start="1"><li><p>Multi-head causal self attention is what facilitates the communication between the inputs. Nowhere else in the network does the model allow inputs to “see” each other. The embeddings, position-wise feed forward network, layer norms, and projection to vocab all operate on our inputs position-wise. Modeling relationships between inputs is tasked solely to attention.</p></li><li><p>The Position-wise feed forward <strong>nn</strong> is just a regular 2 layer fully connected <strong>nn</strong>. This just adds a bunch of learnable parameters for our model to work with to facilitate learning.</p></li><li><p>In the original transformer paper, layer norm is placed on the output <code>layer_norm(x + sublayer(x))</code> while we place layer norm on the input <code>x + sublayer(layer_norm(x))</code> to match <strong>GPT</strong>-2. This is referred to as pre-norm and has been shown to be <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2002.04745.pdf" class="link">important in improving the performance of the transformer<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></li><li><p>Residual connections (popularized by ResNet) serve a couple of different purposes:</p><ul><li><p>Makes it easier to optimize <strong>nn</strong>s that are deep (i.e. networks that have lots of layers). The idea here is that we are providing “shortcuts” for the gradients to flow back through the network, making it easier to optimize the earlier layers in the network.</p></li><li><p>Without residual connections, deeper models see a degradation in performance when adding more layers (possibly because it’s hard for the gradients to flow all the way back through a deep network without losing information). Residual connections seem to give a bit of an accuracy boost for deeper networks.</p></li><li><p>Can help with the <a target="_blank" rel="noreferrer" href="https://programmathically.com/understanding-the-exploding-and-vanishing-gradients-problem/" class="link">vanishing/exploding gradients problem<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></li></ul></li></ol><p>Let’s dig a little deeper into the 2 sublayers.</p></div><div id="tXxRj1cUYM" class="myst-jp-nb-block relative group/block"><h3 id="position-wise-feed-forward-network" class="relative group"><span class="heading-text">Position-wise Feed Forward Network</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#position-wise-feed-forward-network" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="Q0tGOzYCik" class="myst-jp-nb-block relative group/block"><p>This is just a simple multi-layer perceptron with 2 layers:</p></div><div id="VFeWgOkhvi" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def ffn(x, c_fc, c_proj):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # project up
    a = gelu(linear(x, **c_fc))  # [n_seq, n_embd] -&gt; [n_seq, 4*n_embd]

    # project back down
    x = linear(a, **c_proj)  # [n_seq, 4*n_embd] -&gt; [n_seq, n_embd]

    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="8mo9PDot-Yt3XQ3HqGjsW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="ZRe1GNwi8P" class="myst-jp-nb-block relative group/block"><p>Nothing super fancy here, we just project from <code>n_embd</code> up to a higher dimension <code>4*n_embd</code> and then back down to <code>n_embd[4]</code>.</p><p><em>Note</em>: Different <strong>GPT</strong> models may choose a different hidden width that is not <code>4*n_embd</code>, however this is the common practice for <strong>GPT</strong> models. Also, we give the multi-head attention layer a lot of <em>attention</em> (pun intended) for driving the success of the transformer, but at the scale of <strong>GPT</strong>-3, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>80</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">80\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">80%</span></span></span></span></span> of the model parameters are contained in the feed forward layer. Just something to think about.</p><p>Recall, from our params dictionary, that our mlp params look like this:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">&quot;mlp&quot;: {
    &quot;c_fc&quot;: {&quot;b&quot;: [4*n_embd], &quot;w&quot;: [n_embd, 4*n_embd]},
    &quot;c_proj&quot;: {&quot;b&quot;: [n_embd], &quot;w&quot;: [4*n_embd, n_embd]},
},</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="ZTLtdZxkz3" class="myst-jp-nb-block relative group/block"><h3 id="multi-head-causal-self-attention" class="relative group"><span class="heading-text">Multi-Head Causal Self Attention</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#multi-head-causal-self-attention" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="oDpiNyuXSa" class="myst-jp-nb-block relative group/block"><p>This layer is probably the most difficult part of the transformer to understand. So let’s work our way up to “Multi-Head Causal Self Attention” by breaking each word down into its own section:</p><ol start="1"><li><p>Attention</p></li><li><p>Self</p></li><li><p>Causal</p></li><li><p>Multi-Head</p></li></ol></div><div id="Paue8rgW0Q" class="myst-jp-nb-block relative group/block"><h4 id="attention" class="relative group"><span class="heading-text">Attention</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#attention" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="PZk5j0oNmL" class="myst-jp-nb-block relative group/block"><p>ChatGPT and other large language models use a special type of <strong>nn</strong> called the transformer. The transformer defining feature is the attention mechanism. Attention is defined by the equation:</p><div id="NoWRY3Utwa" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#NoWRY3Utwa" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->3<!-- -->)</a></div></div><p>Attention can come in different forms, but this version of attention (known as scaled dot product attention) was first proposed in the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1706.03762.pdf" class="link">original transformer paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. In this post, we’ll build an intuition for the above equation by deriving it from the ground up.</p></div><div id="yMwBkt4Qwu" class="myst-jp-nb-block relative group/block"><h5 id="key-value-lookups" class="relative group"><span class="heading-text">Key-Value Lookups</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#key-value-lookups" title="Link to this Section" aria-label="Link to this Section">¶</a></h5></div><div id="jFyiHOBL4p" class="myst-jp-nb-block relative group/block"><p>A key-value (kv) lookup involves three components:</p><ol start="1"><li><p>A list of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> <strong>keys</strong></p></li><li><p>A list of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> <strong>values</strong> (that map 1-to-1 with the keys, forming key-value pairs)</p></li><li><p>A <strong>query</strong>, for which we want to <em>match</em> with the keys and get some value based on the match</p></li></ol><p>You’re probably familiar with this concept as a dictionary or hash map:</p></div><div id="wN3bMNauZG" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">d = {
    &quot;apple&quot;: 10,
    &quot;banana&quot;: 5,
    &quot;chair&quot;: 2,
}
print(d.keys())
print(d.values())
query = &quot;apple&quot;
d[query]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="27wq0zmtLlOaTGX6_E7ly" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>dict_keys([&#x27;apple&#x27;, &#x27;banana&#x27;, &#x27;chair&#x27;])
dict_values([10, 5, 2])
</span></code></pre></div></div><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>10</span></code></div></div></div><div id="Rrt71I3SWl" class="myst-jp-nb-block relative group/block"><p>Dictionaries let us perform lookups based on an exact string match. What if instead we wanted to do a lookup based on the meaning of a word?</p></div><div id="dKjVZHMY3D" class="myst-jp-nb-block relative group/block"><h5 id="key-value-lookups-based-on-meaning" class="relative group"><span class="heading-text">Key-Value Lookups based on Meaning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#key-value-lookups-based-on-meaning" title="Link to this Section" aria-label="Link to this Section">¶</a></h5></div><div id="bBvYeQVSdJ" class="myst-jp-nb-block relative group/block"><p>Say we wanted to look up the word “fruit” in our previous example, how do we choose which key is the best match? It’s obviously not “chair”, but both “apple” and “banana” seem like a good match. It’s hard to choose one or the other, fruit feels more like a combination of apple and banana rather than a strict match for either. So, let’s not choose. Instead, we’ll do exactly that, take a combination of apple and banana. For example, say we assign a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>60</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">60\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">60%</span></span></span></span></span> meaning based match for apple, a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>40</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">40\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">40%</span></span></span></span></span> match for banana, and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">0\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">0%</span></span></span></span></span> match for chair. We compute our final output value as the weighted sum of the values with the percentages:</p></div><div id="Xwek5QaLnQ" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">query = &quot;fruit&quot;
d = {&quot;apple&quot;: 10, &quot;banana&quot;: 5, &quot;chair&quot;: 2}
0.6 * d[&quot;apple&quot;] + 0.4 * d[&quot;banana&quot;] + 0.0 * d[&quot;chair&quot;]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="_q2MkssLpBgVMWu25UZHN" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>8.0</span></code></div></div></div><div id="n9IUPh74YA" class="myst-jp-nb-block relative group/block"><p>In a sense, we are determining how much attention our query should be paying to each key-value pair based on <code>meaning</code>. The amount of “attention” is represented as a decimal percentage, called an attention score. Mathematically, we can define our output as a simple weighted sum:</p><div id="mvTaL6gq9z" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>α</mi><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\sum_{i} \alpha_i v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#mvTaL6gq9z" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->4<!-- -->)</a></div></div><p>where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is our attention score for the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> kv pair and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> value. Remember, the attention scores are decimal percentages, that is they must be between <!-- -->0<!-- --> and <!-- -->1<!-- --> inclusive (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><msub><mi>α</mi><mi>i</mi></msub><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \leq \alpha_i \leq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.786em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span>) and their sum must be <!-- -->1<!-- --> (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sum_{i} \alpha_i = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span>). Okay, but where did we get these attention scores from? In our example, we kind of chose them based on what we felt. While we did a pretty good job, this approach doesn’t seem sustainable. Instead, let’s take a look at how word vectors can help solve our problem of determining attention scores.</p></div><div id="v3siOpy7Hk" class="myst-jp-nb-block relative group/block"><h5 id="word-vectors-and-similarity" class="relative group"><span class="heading-text">Word Vectors and Similarity</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#word-vectors-and-similarity" title="Link to this Section" aria-label="Link to this Section">¶</a></h5></div><div id="DEU0DUtVgZ" class="myst-jp-nb-block relative group/block"><p>Imagine we represent a word with a vector of numbers. Ideally, the values in the vector should in some way capture the <em>meaning</em> of the word it represents. For example, imagine we have the following word vectors (visualized in 2D space):</p></div><div id="HmoPLP5Wn7" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;2d_word_vectors_example.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="RydmcrSkuQfGsquzd6Bp1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/62ff8935ab01a5371f3de4e1af37f529.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="mrkrSFBRZO" class="myst-jp-nb-block relative group/block"><p>You can see that words that are <em>similar</em> are clustered together. Fruits are clustered at the top right, vegetables are clustered at the top left, and furniture is clustered at the bottom. In fact, you can even see that the vegetable and fruit clusters are closer to each other than they are to the furniture cluster, since they are more closely related things. You can even imagine doing arithmetic on word vectors. For example, given the words “king”, “queen”, “man”, and “woman” and their respective vector representations <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>k</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{king}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">kin</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>e</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{queen}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">ee</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>m</mi><mi>a</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{man}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">man</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>w</mi><mi>o</mi><mi>m</mi><mi>a</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{woman}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">man</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, we can imagine that:</p><div id="rUNTu7bsyl" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>v</mi><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>e</mi><mi>n</mi></mrow></msub><mo>−</mo><msub><mi>v</mi><mrow><mi>w</mi><mi>o</mi><mi>m</mi><mi>a</mi><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>v</mi><mrow><mi>m</mi><mi>a</mi><mi>n</mi></mrow></msub><mo>∼</mo><msub><mi>v</mi><mrow><mi>k</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{queen} - v_{woman} + v_{man} \sim v_{king}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">ee</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">man</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">man</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">kin</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#rUNTu7bsyl" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->5<!-- -->)</a></div></div><p>That is, the vector for “queen” minus “woman” plus “man” should result in a vector that is <em>similar</em> to the vector for “king”. But what does it exactly mean for two vectors to be <em>similar</em>? In the fruits/vegetables example, we were using distance as a measure of similarity (in particular, <a href="https://en.wikipedia.org/wiki/Euclidean_distance" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">euclidean distance</a>). There are also <a target="_blank" rel="noreferrer" href="https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa" class="link">other ways to measure similarity between two vectors<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, each with its own advantages and disadvantages. Possibly the simplest measure of similarity between two vectors is their dot product:</p><div id="HKveVItGEv" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext mathvariant="bold">v</mtext><mo>⋅</mo><mtext mathvariant="bold">w</mtext><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>v</mi><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\textbf{v} \cdot \textbf{w} = \sum_{i} v_i w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord text"><span class="mord textbf">v</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">w</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#HKveVItGEv" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->6<!-- -->)</a></div></div><p><a target="_blank" rel="noreferrer" href="https://www.youtube.com/watch?v=LyGKycYT2v0" class="link">3blue1brown has a great video on the intuition behind dot product<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, but for our purposes all we need to know is:</p><ul><li><p>If two vectors are pointing in the same direction, the dot product will be <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">&gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span> (i.e. <em>similar</em>)</p></li><li><p>If they are pointing in opposing directions, the dot product will be <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">&lt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span> (i.e. <em>dissimilar</em>)</p></li><li><p>If they are exactly perpendicular, the dot product will be <!-- -->0<!-- --> (i.e. <em>neutral</em>)</p></li></ul><p>Using this information, we can define a simple heuristic to determine the similarity between two word vectors: The greater the dot product, the more similar two words are in <em>meaning</em>.</p><p><em>Note</em>: You’ll note that the magnitude of the vectors have an influence on the output of dot product. For example, given 3 vectors, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">a = [1, 1, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><mo stretchy="false">[</mo><mn>1000</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">b = [1000, 0, 0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1000</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mclose">]</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">c = [2, 2, 2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span></span>, our dot product heuristic would tell us that because <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>⋅</mo><mi>b</mi><mo>&gt;</mo><mi>a</mi><mo>⋅</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">a \cdot b &gt; a \cdot c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span>, that <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></span> is more similar to <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span> than <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></span> is to <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span>. This doesn’t seem right, since <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span> are pointing in the exact same direction, while <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span> are not. <a href="https://en.wikipedia.org/wiki/Cosine_similarity" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">Cosine similarity</a> accounts for this normalizing the vectors to unit vectors before taking the dot product, essentially ignoring the magnitudes and only caring about the direction. So why don’t we take the cosine similarity? In a deep learning setting, the magnitude of a vector might actually contain information we care about (and we shouldn’t get rid of it). Also, if we regularize our networks properly, outlier examples like the above should not occur.</p><p>Okay cool, but where do these word vectors actually come from? They usually come from some kind of learned embedding or latent representation. That is, initially the word vectors are just random numbers, but as the <strong>nn</strong> is trained, their values are adjusted to become better and better representations for words.</p></div><div id="mH4rbuATaK" class="myst-jp-nb-block relative group/block"><h5 id="attention-scores-using-the-dot-product" class="relative group"><span class="heading-text">Attention Scores using the Dot Product</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#attention-scores-using-the-dot-product" title="Link to this Section" aria-label="Link to this Section">¶</a></h5></div><div id="zWlYMpi65h" class="myst-jp-nb-block relative group/block"><p>Let’s return to our example of fruits, but this time around using word vectors to represent our words. That is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">q</mtext><mo>=</mo><msub><mtext mathvariant="bold">v</mtext><mrow><mi>f</mi><mi>r</mi><mi>u</mi><mi>i</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\textbf{q} = \textbf{v}_{fruit}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7305em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">v</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">k</mtext><mo>=</mo><mo stretchy="false">[</mo><msub><mtext mathvariant="bold">v</mtext><mrow><mi>a</mi><mi>p</mi><mi>p</mi><mi>l</mi><mi>e</mi></mrow></msub><msub><mtext mathvariant="bold">v</mtext><mrow><mi>b</mi><mi>a</mi><mi>n</mi><mi>a</mi><mi>n</mi><mi>a</mi></mrow></msub><msub><mtext mathvariant="bold">v</mtext><mrow><mi>c</mi><mi>h</mi><mi>a</mi><mi>i</mi><mi>r</mi></mrow></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\textbf{k} = [\textbf{v}_{apple} \textbf{v}_{banana} \textbf{v}_{chair}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord textbf">k</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">[</span><span class="mord"><span class="mord text"><span class="mord textbf">v</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">ppl</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord text"><span class="mord textbf">v</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">banana</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord text"><span class="mord textbf">v</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">hai</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span>, such that <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">v</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><msub><mi>d</mi><mi>k</mi></msub></msup></mrow><annotation encoding="application/x-tex">\textbf{v} \in \mathbb{R}^{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord text"><span class="mord textbf">v</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> (that is each vector has the same dimensionality of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, which is a value we choose when training a <strong>nn</strong>). Using our new dot product similarity measure, we can compute the similarity between the query and the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> key as:</p><div id="taFJXh575D" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext mathvariant="bold">x</mtext><mi>i</mi></msub><mo>=</mo><mtext mathvariant="bold">q</mtext><mo>⋅</mo><msub><mtext mathvariant="bold">k</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\textbf{x}_i = \textbf{q} \cdot \textbf{k}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">k</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#taFJXh575D" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->7<!-- -->)</a></div></div><p>where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="bold">a</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\textbf{a}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">a</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is the attention score for the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> key-value pair.  Generalizing this further, we can compute the dot product for all <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> keys with:</p><div id="jvpZNS4mNE" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext mathvariant="bold">x</mtext><mo>=</mo><mtext mathvariant="bold">q</mtext><mo>⋅</mo><msup><mtext mathvariant="bold">K</mtext><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\textbf{x} = \textbf{q} \cdot \textbf{K}^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">x</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9173em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#jvpZNS4mNE" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->8<!-- -->)</a></div></div><p>where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">x</mtext></mrow><annotation encoding="application/x-tex">\textbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">x</span></span></span></span></span></span> is our vector of dot products <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">x</mtext><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mrow><msub><mi>n</mi><mi>k</mi></msub><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>x</mi><msub><mi>n</mi><mi>k</mi></msub></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\textbf{x} = [x_1, x_2, ..., x_{n_k - 1}, x_{n_k}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">x</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0059em;vertical-align:-0.2559em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span> is a row-wise matrix of our key vectors (i.e. our key vectors stacked on-top of each-other to form a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">n_k \times d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> matrix such that <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">k_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> row of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span>). If you’re having trouble understanding this, here’s an explanation:</p><p>Basically, instead of computing each dot product separately:</p><div id="sMujkMWxiV" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mtext mathvariant="bold">q</mtext><mo>⋅</mo><msub><mtext mathvariant="bold">k</mtext><mn>1</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo><mo>⋅</mo><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mo>−</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">x_1 = \textbf{q} \cdot \textbf{k}_1 = [2, 1, 3] \cdot [-1, 2, -1] = -3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">k</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">3</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#sMujkMWxiV" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->9<!-- -->)</a></div></div><div id="ibBu2mloAE" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mtext mathvariant="bold">q</mtext><mo>⋅</mo><msub><mtext mathvariant="bold">k</mtext><mn>2</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo><mo>⋅</mo><mo stretchy="false">[</mo><mn>1.5</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x_2 = \textbf{q} \cdot \textbf{k}_2 = [2, 1, 3] \cdot [1.5, 0, -1] = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">k</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1.5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#ibBu2mloAE" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->10<!-- -->)</a></div></div><div id="k9Zqd67Dfy" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><mn>3</mn></msub><mo>=</mo><mtext mathvariant="bold">q</mtext><mo>⋅</mo><msub><mtext mathvariant="bold">k</mtext><mn>3</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo><mo>⋅</mo><mo stretchy="false">[</mo><mn>4</mn><mo separator="true">,</mo><mo>−</mo><mn>2</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">x_3 = \textbf{q} \cdot \textbf{k}_3 = [2, 1, 3] \cdot [4, -2, -1] = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">k</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#k9Zqd67Dfy" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->11<!-- -->)</a></div></div><p>You compute it all at once:</p><div id="TQ3VTh81bu" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext mathvariant="bold">x</mtext><mo>=</mo><mtext mathvariant="bold">q</mtext><mo>⋅</mo><msup><mtext mathvariant="bold">K</mtext><mi>T</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo><mo>⋅</mo><msup><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1.5</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>4</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mi>T</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo><mo>⋅</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1.5</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>4</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>2</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mo stretchy="false">[</mo><mo>−</mo><mn>3</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\textbf{x} = \textbf{q} \cdot \textbf{K}^T = [2, 1, 3] \cdot \begin{bmatrix} -1 &amp; 2 &amp; -1 \\ 1.5 &amp; 0 &amp; -1 \\ 4 &amp; -2 &amp; -1 \end{bmatrix}^T = [2, 1, 3] \cdot \begin{bmatrix} -1 &amp; 1.5 &amp; 4 \\ 2 &amp; 0 &amp; -2 \\ -1 &amp; -1 &amp; -1 \end{bmatrix} = [-3, 0, 3] = [x_1, x_2, x_3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">x</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord textbf">q</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9173em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.8313em;vertical-align:-1.55em;"></span><span class="minner"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-2.25em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-3.397em;"><span class="pstrut" style="height:3.155em;"></span><span style="height:0.016em;width:0.6667em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'><path d='M319 0 H403 V16 H319z M319 0 H403 V16 H319z'/></svg></span></span><span style="top:-4.05em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1.5</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-2.25em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-3.397em;"><span class="pstrut" style="height:3.155em;"></span><span style="height:0.016em;width:0.6667em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'><path d='M263 0 H347 V16 H263z M263 0 H347 V16 H263z'/></svg></span></span><span style="top:-4.05em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:2.2813em;"><span style="top:-4.5029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-2.25em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-3.397em;"><span class="pstrut" style="height:3.155em;"></span><span style="height:0.016em;width:0.6667em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'><path d='M319 0 H403 V16 H319z M319 0 H403 V16 H319z'/></svg></span></span><span style="top:-4.05em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1.5</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">2</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-2.25em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-3.397em;"><span class="pstrut" style="height:3.155em;"></span><span style="height:0.016em;width:0.6667em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'><path d='M263 0 H347 V16 H263z M263 0 H347 V16 H263z'/></svg></span></span><span style="top:-4.05em;"><span class="pstrut" style="height:3.155em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#TQ3VTh81bu" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->12<!-- -->)</a></div></div><p>Now, recall that our attention scores need to be decimal percentages (between <!-- -->0<!-- --> and <!-- -->1<!-- --> and sum to <!-- -->1<!-- -->). Our dot product values however can be any real number (i.e. between <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">-\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">∞</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord">∞</span></span></span></span></span>). To transform our dot product values to decimal percentages, we’ll use the softmax function:</p><div id="dqZB56E8OA" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>softmax</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><msub><mi>x</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{softmax}(x) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4632em;vertical-align:-1.1218em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#dqZB56E8OA" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->13<!-- -->)</a></div></div><p>e.g.</p></div><div id="U1tLE9iThF" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">softmax(np.array([4.0, -1.0, 2.1]))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YPuyXmtfaswlc37HCHZdr" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>array([0.86482256, 0.00582713, 0.12935032])</span></code></div></div></div><div id="CoKB3yiE1b" class="myst-jp-nb-block relative group/block"><p>Notice:</p><ul><li><p>✅ Each number is between <!-- -->0<!-- --> and <!-- -->1</p></li><li><p>✅ The numbers sum to <!-- -->1</p></li><li><p>✅ The larger valued inputs get more “weight”</p></li><li><p>✅ The sorted order is preserved (i.e. the <!-- -->4.0<!-- --> is still the largest after softmax, and <!-- -->-1.0<!-- --> is still the lowest), this is because softmax is a <a href="https://en.wikipedia.org/wiki/Monotonic_function" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">monotonic function</a></p></li></ul><p>This satisfies all the desired properties of an attention scores. Thus, we can compute the attention score for the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> key-value pair with:</p><div id="WBxi1pGO7P" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">q</mtext><msup><mtext mathvariant="bold">K</mtext><mi>T</mi></msup><msub><mo stretchy="false">)</mo><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">a_i = \text{softmax}(x)_i = \text{softmax}(\textbf{q} \textbf{K}^T)_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1673em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">q</span></span><span class="mord"><span class="mord text"><span class="mord textbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#WBxi1pGO7P" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->14<!-- -->)</a></div></div><p>Plugging this into our weighted sum we get:</p><div id="MJyPihiFBG" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>a</mi><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mtext>softmax</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">x</mtext><msub><mo stretchy="false">)</mo><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mtext>softmax</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">q</mtext><msup><mtext mathvariant="bold">K</mtext><mi>T</mi></msup><msub><mo stretchy="false">)</mo><mi>i</mi></msub><msub><mi>v</mi><mi>i</mi></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">q</mtext><msup><mtext mathvariant="bold">K</mtext><mi>T</mi></msup><mo stretchy="false">)</mo><mtext mathvariant="bold">v</mtext></mrow><annotation encoding="application/x-tex">\sum_{i} a_i v_i = \sum_{i} \text{softmax}(\textbf{x})_i v_i = \sum_{i} \text{softmax}(\textbf{q} \textbf{K}^T)_i v_i = \text{softmax}(\textbf{q} \textbf{K}^T) \textbf{v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">x</span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">q</span></span><span class="mord"><span class="mord text"><span class="mord textbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1673em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">q</span></span><span class="mord"><span class="mord text"><span class="mord textbf">K</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord text"><span class="mord textbf">v</span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#MJyPihiFBG" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->15<!-- -->)</a></div></div><p>Note: In the last step, we pack our values into a vector <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">v</mtext><mo>=</mo><mo stretchy="false">[</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mrow><msub><mi>n</mi><mi>k</mi></msub><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>v</mi><msub><mi>n</mi><mi>k</mi></msub></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\textbf{v} = [v_1, v_2, ..., v_{n_k - 1}, v_{n_k}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">v</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0059em;vertical-align:-0.2559em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span>, which allows us to get rid of the summation notation in favor of a dot product. And that’s it, we have a full working definition for attention:</p><div id="t6aClwhUaK" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">q</mtext><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mtext mathvariant="bold">v</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><msup><mtext mathvariant="bold">qK</mtext><mi>T</mi></msup><mo stretchy="false">)</mo><mtext mathvariant="bold">v</mtext></mrow><annotation encoding="application/x-tex">\text{attention}(\textbf{q}, K, \textbf{v}) = \text{softmax}(\textbf{qK}^T)\textbf{v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">q</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord textbf">v</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1673em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord textbf">qK</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord text"><span class="mord textbf">v</span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#t6aClwhUaK" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->16<!-- -->)</a></div></div><p>In code:</p></div><div id="oNGQyEbNKy" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def get_word_vector(word, d_k=8):
    &quot;&quot;&quot;Hypothetical mapping that returns a word vector of size
    d_k for the given word. For demonstrative purposes, we initialize
    this vector randomly, but in practice this would come from a learned
    embedding or some kind of latent representation.&quot;&quot;&quot;
    return np.random.normal(size=(d_k,))


def attention(q, K, v):
    # assumes q is a vector of shape (d_k)
    # assumes K is a matrix of shape (n_k, d_k)
    # assumes v is a vector of shape (n_k)
    return softmax(q @ K.T) @ v


def kv_lookup(query, keys, values):
    return attention(
        q=get_word_vector(query),
        K=np.array([get_word_vector(key) for key in keys]),
        v=values,
    )


# returns some float number
print(kv_lookup(&quot;fruit&quot;, [&quot;apple&quot;, &quot;banana&quot;, &quot;chair&quot;], [10, 5, 2]))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="p7thC6R3qzu8PNvaU4zbi" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>6.589311199486881
</span></code></pre></div></div></div></div><div id="MtdIkR5qXo" class="myst-jp-nb-block relative group/block"><h5 id="scaled-dot-product-attention" class="relative group"><span class="heading-text">Scaled Dot Product Attention</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#scaled-dot-product-attention" title="Link to this Section" aria-label="Link to this Section">¶</a></h5></div><div id="StB90l1HO4" class="myst-jp-nb-block relative group/block"><p>In principle, the attention equation we derived in the last section is complete. However, we’ll need to make a couple of changes to match the version in <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1706.03762.pdf" class="link">Attention is All You Need<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p><p><strong>Values as Vectors</strong></p><p>Currently, our values in the key-value pairs are just numbers. However, we could also instead replace them with vectors of some size <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>. For example, with <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">d_v = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span></span></span></span></span>, you might have:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">d = {
    &quot;apple&quot;: [0.9, 0.2, -0.5, 1.0]
    &quot;banana&quot;: [1.2, 2.0, 0.1, 0.2]
    &quot;chair&quot;: [-1.2, -2.0, 1.0, -0.2]
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>When we compute our output via a weighted sum, we’d be doing a weighted sum over vectors instead of numbers (i.e. scalar-vector multiplication instead of scalar-scalar multiplication). This is desirable because vectors let us hold/convey more information than just a single number. To adjust for this change in our equation, instead of multiplying our attention scores by a vector <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span></span>, we multiply it by the row-wise matrix of our value vectors <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span> (similar to how we stacked our keys to form <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span>):</p><div id="n4CPFDBnBo" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">q</mtext><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><msup><mtext mathvariant="bold">qK</mtext><mi>T</mi></msup><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{attention}(\textbf{q}, K, V) = \text{softmax}(\textbf{qK}^T)V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">q</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1673em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord textbf">qK</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#n4CPFDBnBo" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->17<!-- -->)</a></div></div><p>Of course, our output is no longer a scalar, instead it would be a vector of dimensionality <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>.</p><p><strong>Scaling</strong></p><p>The dot product between our query and keys can get really large in magnitude if <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> is large. This makes the output of softmax more <em>extreme</em>. For example, <code>softmax([3, 2, 1]) = [0.665, 0.244, 0.090]</code>, but with larger values <code>softmax([30, 20, 10]) = [9.99954600e-01, 4.53978686e-05, 2.06106005e-09]</code>. When training a <strong>nn</strong>, this would mean the gradients would become really small which is undesirable. As a solution, we scale our pre-softmax scores by <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{d_k}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3831em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>:</p><div id="mL5fnsXTNU" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mtext mathvariant="bold">q</mtext><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><msup><mtext mathvariant="bold">qK</mtext><mi>T</mi></msup><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{attention}(\textbf{q}, K, V) = \text{softmax}(\frac{\textbf{qK}^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord text"><span class="mord textbf">q</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.5243em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5943em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord text"><span class="mord textbf">qK</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9173em;"><span style="top:-3.139em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#mL5fnsXTNU" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->18<!-- -->)</a></div></div><p><strong>Multiple Queries</strong></p><p>In practice, we often want to perform multiple lookups for <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">n_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span> different queries rather than just a single query. Of course, we could always do this one at a time, plugging each query individually into the above equation. However, if we stack of query vectors row-wise as a matrix <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span> (in the same way we did for <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span>), we can compute our output as an <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>q</mi></msub><mo>×</mo><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">n_q \times d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> matrix where row <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> is the output vector for the attention on the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">ith</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> query:</p><div id="pSFuybg4ZD" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#pSFuybg4ZD" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->19<!-- -->)</a></div></div><p>that is, </p><div id="okM0bOQYef" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mtext>attention</mtext><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{attention}(Q, K, V)_i = \text{attention}(q_i, K, V)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#okM0bOQYef" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->20<!-- -->)</a></div></div><p>This makes computation faster than if we ran attention for each query sequentially (say, in a for loop) since we can parallelize calculations (particularly when using a GPU). Note, our input to softmax becomes a matrix instead of a vector. When we write softmax here, we mean that we are taking the softmax along each row of the matrix independently, as if we were doing things sequentially.</p><p><strong>Result</strong></p><p>With that, we have our final equation for scaled dot product attention as it’s written in the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1706.03762.pdf" class="link">original transformer paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>:</p><div id="QXuz4wWBzt" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#QXuz4wWBzt" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->21<!-- -->)</a></div></div><p>In code:</p></div><div id="FAnNXJT6wH" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def attention(q, k, v):  # [n_q, d_k], [n_k, d_k], [n_k, d_v] -&gt; [n_q, d_v]
    # assumes q is a matrix of shape [n_q, d_k]
    # assumes k is a matrix of shape [n_k, d_k]
    # assumes v is a matrix of shape [n_k, d_v]
    # output is a matrix of shape [n_q, d_v]
    d_k = k.shape[-1]
    return softmax(q @ k.T / np.sqrt(d_k)) @ v</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="pwnHRNLY0vDuIfXmQPn31" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="AFlOTWmDz5" class="myst-jp-nb-block relative group/block"><h4 id="self" class="relative group"><span class="heading-text">Self</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#self" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="iWa1aJUpBt" class="myst-jp-nb-block relative group/block"><p>When <code>q</code>, <code>k</code>, and <code>v</code> all come from the same source, we are performing <a target="_blank" rel="noreferrer" href="https://lilianweng.github.io/posts/2018-06-24-attention/#self-attention" class="link">self-attention<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> (i.e. letting our input sequence attend to itself):</p></div><div id="FNEXtaoYxA" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def self_attention(x):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    return attention(q=x, k=x, v=x)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="iDy8hN4yczsRTlJOhq12b" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="uNKZOy2xYw" class="myst-jp-nb-block relative group/block"><p>For example, if our input is <code>Jay went to the store, he bought 10 apples.</code>, we would be letting the word <code>he</code> attend to all the other words, including <code>Jay</code>, meaning the model can learn to recognize that <code>he</code> is referring to <code>Jay</code>. We can enhance self attention by introducing projections for <code>q</code>, <code>k</code>, <code>v</code> and the attention output:</p></div><div id="ANjlfxmLNr" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def self_attention(x, w_k, w_q, w_v, w_proj):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # qkv projections
    q = x @ w_q  # [n_seq, n_embd] @ [n_embd, n_embd] -&gt; [n_seq, n_embd]
    k = x @ w_k  # [n_seq, n_embd] @ [n_embd, n_embd] -&gt; [n_seq, n_embd]
    v = x @ w_v  # [n_seq, n_embd] @ [n_embd, n_embd] -&gt; [n_seq, n_embd]

    # perform self attention
    x = attention(q, k, v)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]

    # out projection
    x = x @ w_proj  # [n_seq, n_embd] @ [n_embd, n_embd] -&gt; [n_seq, n_embd]

    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="eAie5PZbsUxWzHSuF4MI5" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="PXIxvGnvnT" class="myst-jp-nb-block relative group/block"><p>This enables our model to learn a mapping for <code>q</code>, <code>k</code>, and <code>v</code> that best helps attention distinguish relationships between inputs. We can reduce the number of matrix multiplication from <!-- -->4<!-- --> to just <!-- -->2<!-- --> if we combine <code>w_q</code>, <code>w_k</code> and <code>w_v</code> into a single matrix <code>w_fc</code>, perform the projection, and then split the result:</p></div><div id="pC5mDozbRW" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def self_attention(x, w_fc, w_proj):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # qkv projections
    x = x @ w_fc  # [n_seq, n_embd] @ [n_embd, 3*n_embd] -&gt; [n_seq, 3*n_embd]

    # split into qkv
    q, k, v = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -&gt; 3 of [n_seq, n_embd]

    # perform self attention
    x = attention(q, k, v)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]

    # out projection
    x = x @ w_proj  # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]

    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="-hFzuioPTK_IJvJ9MAgeY" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="TQMpRcHBRx" class="myst-jp-nb-block relative group/block"><p>This is a bit more efficient as modern accelerators (GPUs) can take better advantage of one large matrix multiplication rather than <!-- -->3<!-- --> separate small ones happening sequentially. Finally, we add bias vectors to match the implementation of <strong>GPT</strong>-2, use our <code>linear</code> function, and rename our parameters to match our <code>params</code> dictionary:</p></div><div id="c2Pa321b96" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def self_attention(x, c_attn, c_proj):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # qkv projections
    x = linear(x, **c_attn)  # [n_seq, n_embd] -&gt; [n_seq, 3*n_embd]

    # split into qkv
    q, k, v = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -&gt; 3 of [n_seq, n_embd]

    # perform self attention
    x = attention(q, k, v)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]

    # out projection
    x = linear(x, **c_proj)  # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]

    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Eu9_Cq_S3sZiA0UMjUAZj" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="QNSd3kEau7" class="myst-jp-nb-block relative group/block"><p>Recall, from our <code>params</code> dictionary, our <code>attn</code> params look like this:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">&quot;attn&quot;: {
    &quot;c_attn&quot;: {&quot;b&quot;: [3*n_embd], &quot;w&quot;: [n_embd, 3*n_embd]},
    &quot;c_proj&quot;: {&quot;b&quot;: [n_embd], &quot;w&quot;: [n_embd, n_embd]},
},</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="oHoHslKAEO" class="myst-jp-nb-block relative group/block"><h4 id="causal" class="relative group"><span class="heading-text">Causal</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#causal" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="GQ8RoBbY50" class="myst-jp-nb-block relative group/block"><p>There is a bit of an issue with our current self-attention setup, our inputs can see into the future! For example, if our input is <code>[&quot;not&quot;, &quot;all&quot;, &quot;heroes&quot;, &quot;wear&quot;, &quot;capes&quot;]</code>, during self attention we are allowing <code>&quot;wear&quot;</code> to see <code>&quot;capes&quot;</code>. This means our output probabilities for <code>&quot;wear&quot;</code> will be biased since the model already knows the correct answer is <code>&quot;capes&quot;</code>. This is no good since our model will just learn that the correct answer for input <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> can be taken from input <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7429em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span>. To prevent this, we need to somehow modify our attention matrix to <em>hide</em> or <strong>mask</strong> our inputs from being able to see into the future. For example, let’s pretend our attention matrix looks like this:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">       not    all    heroes wear   capes
   not 0.116  0.159  0.055  0.226  0.443
   all 0.180  0.397  0.142  0.106  0.175
heroes 0.156  0.453  0.028  0.129  0.234
  wear 0.499  0.055  0.133  0.017  0.295
 capes 0.089  0.290  0.240  0.228  0.153</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Each row corresponds to a query and the columns to a key. In this case, looking at the row for <code>wear</code>, you can see that it is attending to <code>capes</code> in the last column with a weight of <!-- -->0.295<!-- -->. To prevent this, we want to set that entry to <!-- -->0.000<!-- -->:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">        not    all    heroes wear   capes
   not 0.116  0.159  0.055  0.226  0.443
   all 0.180  0.397  0.142  0.106  0.175
heroes 0.156  0.453  0.028  0.129  0.234
  wear 0.499  0.055  0.133  0.017  0.000
 capes 0.089  0.290  0.240  0.228  0.153</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>In general, to prevent all the queries in our input from looking into the future, we set all positions <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i, j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span></span> where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>&gt;</mo><mi>i</mi></mrow><annotation encoding="application/x-tex">j &gt; i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> to <!-- -->0.000<!-- -->:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">        not    all    heroes wear   capes
   not 0.116  0.000  0.000  0.000  0.000
   all 0.180  0.397  0.000  0.000  0.000
heroes 0.156  0.453  0.028  0.000  0.000
  wear 0.499  0.055  0.133  0.017  0.000
 capes 0.089  0.290  0.240  0.228  0.153</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>We call this <strong>masking</strong>. One issue with our above <strong>masking</strong> approach is our rows no longer sum to <!-- -->1<!-- --> (since we are setting them to <!-- -->0<!-- --> after the <code>softmax</code> has been applied). To make sure our rows still sum to <!-- -->1<!-- -->, we need to modify our attention matrix before the <code>softmax</code> is applied. This can be achieved by setting entries that are to be masked to <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">-\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">∞</span></span></span></span></span> prior to the <code>softmax</code>.</p><p><em>Note</em>: If you’re not convinced, stare at the softmax equation and convince yourself this is true (maybe even pull out a pen and paper):</p><div id="R3SNMJeZiY" class="flex my-5 group"><div class="flex-grow overflow-x-auto overflow-y-hidden"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>softmax</mtext><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><msub><mi>x</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{softmax}(\vec{x})_{i} = \frac{e^{x_i}}{\sum_{j} e^{x_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2077em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4632em;vertical-align:-1.1218em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="relative self-center flex-none pl-2 m-0 text-right select-none"><a class="no-underline text-inherit hover:text-inherit text-inherit hover:text-inherit select-none hover:underline" href="#R3SNMJeZiY" title="Link to this Equation" aria-label="Link to this Equation">(<!-- -->22<!-- -->)</a></div></div></div><div id="UhtOdjE2r3" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def attention(
    q, k, v, mask
):  # [n_q, d_k], [n_k, d_k], [n_k, d_v], [n_q, n_k] -&gt; [n_q, d_v]
    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="bygcNm4FNDX3E7jgY6TMw" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="BCM9QA9sE7" class="myst-jp-nb-block relative group/block"><p>where <code>mask</code> is the matrix (for <code>n_seq=5</code>):</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">0 -1e10 -1e10 -1e10 -1e10
0   0   -1e10 -1e10 -1e10
0   0     0   -1e10 -1e10
0   0     0     0   -1e10
0   0     0     0     0</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="GLdsA4Ubmn" class="myst-jp-nb-block relative group/block"><p>We use <code>-1e10</code> instead of <code>-np.inf</code> as <code>-np.inf</code> can cause <code>nan</code>s. Adding <code>mask</code> to our attention matrix instead of just explicitly setting the values to <code>-1e10</code> works because practically, any number plus <code>-inf</code> is just <code>-inf</code>. We can compute the mask matrix in NumPy with <code>(1 - np.tri(n_seq)) * -1e10</code>. Putting it all together, we get:</p></div><div id="zPW7aJ1Ue8" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def attention(
    q, k, v, mask
):  # [n_q, d_k], [n_k, d_k], [n_k, d_v], [n_q, n_k] -&gt; [n_q, d_v]
    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v


def causal_self_attention(x, c_attn, c_proj):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # qkv projections
    x = linear(x, **c_attn)  # [n_seq, n_embd] -&gt; [n_seq, 3*n_embd]

    # split into qkv
    q, k, v = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -&gt; 3 of [n_seq, n_embd]

    # causal mask to hide future inputs from being attended to
    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]

    # perform causal self attention
    x = attention(q, k, v, causal_mask)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]

    # out projection
    x = linear(x, **c_proj)  # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]

    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="2vmbwLcq_cNjN_b56f_Ls" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="jiFasNvRVw" class="myst-jp-nb-block relative group/block"><h4 id="multi-head" class="relative group"><span class="heading-text">Multi-Head</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#multi-head" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="eulR3RaXwj" class="myst-jp-nb-block relative group/block"><p>We can further improve our implementation by performing <code>n_head</code> separate attention computations, splitting our queries, keys, and values into heads:</p></div><div id="keXnPhKPzq" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def mha(x, c_attn, c_proj, n_head):  # [n_seq, n_embd] -&gt; [n_seq, n_embd]
    # qkv projection
    x = linear(x, **c_attn)  # [n_seq, n_embd] -&gt; [n_seq, 3*n_embd]

    # split into qkv
    qkv = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -&gt; [3, n_seq, n_embd]

    # split into heads
    qkv_heads = list(
        map(lambda x: np.split(x, n_head, axis=-1), qkv)
    )  # [3, n_seq, n_embd] -&gt; [3, n_head, n_seq, n_embd/n_head]

    # causal mask to hide future inputs from being attended to
    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]

    # perform attention over each head
    out_heads = [
        attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)
    ]  # [3, n_head, n_seq, n_embd/n_head] -&gt; [n_head, n_seq, n_embd/n_head]

    # merge heads
    x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -&gt; [n_seq, n_embd]

    # out projection
    x = linear(x, **c_proj)  # [n_seq, n_embd] -&gt; [n_seq, n_embd]

    return x</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="FLWQZfyEQVEhw6adVkzFe" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="JQYr48PNmq" class="myst-jp-nb-block relative group/block"><p>There are three steps added here:</p><ol start="1"><li><p>Split <code>q</code>, <code>k</code>, <code>v</code> into <code>n_head</code> heads:</p></li></ol><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># split into heads
qkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), qkv))  # [3, n_seq, n_embd] -&gt; [n_head, 3, n_seq, n_embd/n_head]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><ol start="2"><li><p>Compute attention for each head:</p></li></ol><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># perform attention over each head
out_heads = [attention(q, k, v) for q, k, v in zip(*qkv_heads)]  # [n_head, 3, n_seq, n_embd/n_head] -&gt; [n_head, n_seq, n_embd/n_head]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><ol start="3"><li><p>Merge the outputs of each head:</p></li></ol><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># merge heads
x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -&gt; [n_seq, n_embd]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="SzWA0OHZ48" class="myst-jp-nb-block relative group/block"><p>Notice, this reduces the dimension from <code>n_embd</code> to <code>n_embd/n_head</code> for each attention computation. This is a tradeoff. For reduced dimensionality, our model gets additional subspaces to work when modeling relationships via attention. For example, maybe one attention head is responsible for connecting pronouns to the person the pronoun is referencing. Maybe another might be responsible for grouping sentences by periods. Another could simply be identifying which words are entities, and which are not. Although, it’s probably just another <strong>nn</strong> black box. The code we wrote performs the attention computations over each head sequentially in a loop (one at a time), which is not very efficient. In practice, you’d want to do these in parallel. For simplicity, we’ll just leave this sequential. With that, we’re finally done our <strong>GPT</strong> implementation! Now, all that’s left to do is put it all together and run our code.</p></div><div id="LOXvwasyNM" class="myst-jp-nb-block relative group/block"><h2 id="putting-it-all-together" class="relative group"><span class="heading-text">Putting it All Together</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#putting-it-all-together" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="BKZ3A8G28b" class="myst-jp-nb-block relative group/block"><p>Having put everything together, we get the equivalent of <a href="https://github.com/jaymody/picoGPT/blob/main/gpt2.py" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">gpt2.py</a>, which in its entirety is a mere <!-- -->120<!-- --> lines of code (<a href="https://github.com/jaymody/picoGPT/blob/a750c145ba4d09d5764806a6c78c71ffaff88e64/gpt2_pico.py#L3-L58" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">60<!-- --> lines if you remove comments and whitespace!</a>). All that remains, it to test our implementation by prompting our tiny <strong>GPT</strong>-2 model:</p></div><div id="P4YHxysMEC" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">output = prompt_gpt(&quot;Alan Turing theorized that computers would one day become&quot;, n_tokens_to_generate=8)
assert output == &quot; the most powerful machines on the planet.&quot;
print(output)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="gbwLNCzYZ4jFQ7SvVCWHq" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>2025-02-18 12:27:30.196142: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.
generating: 100%|██████████| 8/8 [00:07&lt;00:00,  1.03it/s]</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span> the most powerful machines on the planet.
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>
</span></code></pre></div></div></div></div><div id="c4QwSVPiha" class="myst-jp-nb-block relative group/block"><p>It works! We can also test that our implementation gives identical results to OpenAI’s official <strong>GPT</strong>-2 repo by building and executing the Docker container as follows:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-bash" style="white-space:pre">docker build -t &quot;openai-gpt-2&quot; - &lt;&lt;EOF
FROM tensorflow/tensorflow:1.13.2-py3

ENV DEBIAN_FRONTEND=noninteractive
RUN apt update -y &amp;&amp; apt upgrade -y &amp;&amp; apt install git -y

RUN git clone https://github.com/openai/gpt-2 /gpt-2
WORKDIR /gpt-2

RUN python3 -m pip install --upgrade pip &amp;&amp; python3 -m pip install -r requirements.txt
RUN python3 download_model.py 124M
RUN python3 download_model.py 355M
RUN python3 download_model.py 774M
RUN python3 download_model.py 1558M
EOF

docker run -dt --name &quot;openai-gpt-2-app&quot; openai-gpt-2
docker exec -it &quot;openai-gpt-2-app&quot; /bin/bash -c &#x27;python3 src/interactive_conditional_samples.py --length 8 --model_type 124M --top_k 1&#x27;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>and then pasting the following when prompted:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-bash" style="white-space:pre">&quot;Alan Turing theorized that computers would one day become&quot;</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="xuNwPghks3" class="myst-jp-nb-block relative group/block"><p>This should yield an identical result:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre"> the most powerful machines on the planet.</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="PgKuwbGKrE" class="myst-jp-nb-block relative group/block"><h2 id="what-next" class="relative group"><span class="heading-text">What Next?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#what-next" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="VaNRlCSW1h" class="myst-jp-nb-block relative group/block"><p>This implementation is cool and all, but it’s missing a ton of bells and whistles:</p></div><div id="QWTYMZMBLh" class="myst-jp-nb-block relative group/block"><h3 id="gpu-tpu-support" class="relative group"><span class="heading-text">GPU/TPU Support</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gpu-tpu-support" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="O0XrKr9OrG" class="myst-jp-nb-block relative group/block"><p>Replace NumPy with <a target="_blank" rel="noreferrer" href="https://github.com/google/jax" class="link">JAX<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import jax.numpy as np</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>That’s it. You can now use the code with GPUs and even <a target="_blank" rel="noreferrer" href="https://cloud.google.com/tpu/docs/system-architecture-tpu-vm" class="link">TPUs<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>! Just make sure you <a target="_blank" rel="noreferrer" href="https://github.com/google/jax#installation" class="link">install JAX correctly<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></div><div id="iSeS8htlJB" class="myst-jp-nb-block relative group/block"><h3 id="backprop" class="relative group"><span class="heading-text"><strong>Backprop</strong></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#backprop" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="XOW5r9obmK" class="myst-jp-nb-block relative group/block"><p>Again, if we replace NumPy with JAX:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import jax.numpy as np</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Then computing the gradients is as easy as:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def lm_loss(params, inputs, n_head) -&gt; float:
    x, y = inputs[:-1], inputs[1:]
    logits = gpt2(x, **params, n_head=n_head)
    loss = np.mean(-log_softmax(logits)[y])
    return loss

grads = jax.grad(lm_loss)(params, inputs, n_head)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="yEKzcK2yku" class="myst-jp-nb-block relative group/block"><h3 id="batching" class="relative group"><span class="heading-text">Batching</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#batching" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="PNYO3qu8WO" class="myst-jp-nb-block relative group/block"><p>Once again, if we replace NumPy with JAX:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import jax.numpy as np</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Then, making our <code>gpt2</code> function batched is as easy as:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">gpt2_batched = jax.vmap(gpt2, in_axes=[0, None, None, None, None, None])
gpt2_batched(batched_inputs)  # [batch, seq_len] -&gt; [batch, seq_len, vocab]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="gZjYsoU9wJ" class="myst-jp-nb-block relative group/block"><h3 id="jax-test" class="relative group"><span class="heading-text">JAX test</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#jax-test" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="llbexYhwaZ" class="myst-jp-nb-block relative group/block"><p>Let’s verify that switching to JAX is indeed as easy as described:</p></div><div id="d1GkPJWJbS" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import jax.numpy as np

# all references to np are now references to jax.numpy
output = prompt_gpt(&quot;Alan Turing theorized that computers would one day become&quot;, n_tokens_to_generate=8)
assert output == &quot; the most powerful machines on the planet.&quot;
print(output)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="jHjjPi9AgMIDOyY6OhDV5" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>2025-02-18 12:27:38.750777: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.
generating: 100%|██████████| 8/8 [00:10&lt;00:00,  1.30s/it]</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span> the most powerful machines on the planet.
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>
</span></code></pre></div></div></div></div><div id="wQHjOMAaZx" class="myst-jp-nb-block relative group/block"><h3 id="inference-optimization" class="relative group"><span class="heading-text">Inference Optimization</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#inference-optimization" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="OcxvpAn0Aw" class="myst-jp-nb-block relative group/block"><p>Our implementation is quite inefficient. The quickest and most impactful optimization you can make (outside of GPU + batching support) would be to implement a <a target="_blank" rel="noreferrer" href="https://kipp.ly/blog/transformer-inference-arithmetic/#kv-cache" class="link">kv cache<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. Also, we implemented our attention head computations sequentially, when we should really be doing it in parallel. Using JAX, this is as simple as</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">heads = jax.vmap(attention, in_axes=(0, 0, 0, None))(q, k, v, causal_mask)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>There’s many many more inference optimizations. Here’s two recommendations as a starting point:</p><ol start="1"><li><p><a target="_blank" rel="noreferrer" href="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/" class="link">Lillian Weng’s Large Transformer Model Inference Optimization<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a></p></li><li><p><a target="_blank" rel="noreferrer" href="https://kipp.ly/blog/transformer-inference-arithmetic/" class="link">Kipply’s Transformer Inference Arithmetic<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a></p></li></ol></div><div id="I5IwrflLKo" class="myst-jp-nb-block relative group/block"><h3 id="training-1" class="relative group"><span class="heading-text">Training</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#training-1" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="xi9CLKTOru" class="myst-jp-nb-block relative group/block"><p>Training a <strong>GPT</strong> is pretty standard for a <strong>nn</strong> (gradient descent <strong>w.r.t</strong> a <strong>loss</strong> function). Of course, you also need to use the standard bag of tricks when training a <strong>GPT</strong> (i.e. use the Adam optimizer, find the optimal learning rate, regularization via dropout and/or weight decay, use a learning rate scheduler, use the correct weight initialization, batching, etc ...). Though the real challenge to training a good <strong>GPT</strong> model is the ability to scale the data and the model. For scaling data, you’ll want a corpus of text that is big, high quality, and diverse.</p><ul><li><p>Big means billions of tokens (terabytes of data). For example, check out <a target="_blank" rel="noreferrer" href="https://pile.eleuther.ai/" class="link">The Pile<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, which is an open source pre-training dataset for large language models.</p></li><li><p>High quality means you want to filter out duplicate examples, unformatted text, incoherent text, garbage text, etc ...</p></li><li><p>Diverse means varying sequence lengths, about lots of different topics, from different sources, with differing perspectives, etc ... Of course, if there are any biases in the data, it will reflect in the model, so you need to be careful of that as well.</p></li></ul><p>Scaling the model to billions of parameters involves a cr*p ton of engineering (and money lol). Training frameworks can get <a target="_blank" rel="noreferrer" href="https://github.com/NVIDIA/Megatron-LM" class="link">absurdly long and complex<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. A good place to start would be <a target="_blank" rel="noreferrer" href="https://lilianweng.github.io/posts/2021-09-25-train-large/" class="link">Lillian Weng’s How to Train Really Large Models on Many GPUs<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. On the topic there’s also the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1909.08053.pdf" class="link">NVIDIA’s Megatron Framework<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2204.06514.pdf" class="link">Cohere’s Training Framework<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2204.02311.pdf" class="link">Google’s PALM<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, the open source <a target="_blank" rel="noreferrer" href="https://github.com/kingoflolz/mesh-transformer-jax" class="link">mesh<wbr/>-transformer<wbr/>-jax<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> (used to train EleutherAI’s open source models), and <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2203.15556.pdf" class="link">many<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" class="link">many<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2005.14165.pdf" class="link">more<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></div><div id="KOl56nNwiu" class="myst-jp-nb-block relative group/block"><h3 id="evaluation" class="relative group"><span class="heading-text">Evaluation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#evaluation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="GcsHt5oIKN" class="myst-jp-nb-block relative group/block"><p>Oh boy, how does one even evaluate LLMs? Honestly, it’s really hard problem. <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/2211.09110" class="link">HELM<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> is pretty comprehensive and a good place to start, but you should always be skeptical of <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">benchmarks and evaluation metrics</a>.</p></div><div id="qTgShGXrWu" class="myst-jp-nb-block relative group/block"><h3 id="architecture-improvements" class="relative group"><span class="heading-text">Architecture Improvements</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#architecture-improvements" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="w062cFotl6" class="myst-jp-nb-block relative group/block"><p>You can also take a look at <a target="_blank" rel="noreferrer" href="https://github.com/lucidrains/x-transformers" class="link">Phil Wang’s X-Transformer’s<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2102.11972.pdf" class="link">This paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> is also a pretty good summary (see Table 1). Facebook’s <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2302.13971.pdf" class="link">LLaMA paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> is also probably a good reference for standard architecture improvements (at least as of February 2023 it was).</p></div><div id="UgN5qm7Z8P" class="myst-jp-nb-block relative group/block"><h3 id="stopping-generation" class="relative group"><span class="heading-text">Stopping Generation</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#stopping-generation" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="nR1tIvymZT" class="myst-jp-nb-block relative group/block"><p>Our current implementation requires us to specify the exact number of tokens we’d like to generate ahead of time. This is not a very good approach as our generations end up being too long, too short, or cutoff mid-sentence. To resolve this, we can introduce a special end of sentence (EOS) token. During pre-training, we append the EOS token to the end of our input (i.e. <code>tokens = [&quot;not&quot;, &quot;all&quot;, &quot;heroes&quot;, &quot;wear&quot;, &quot;capes&quot;, &quot;.&quot;, &quot;&lt;|EOS|&gt;&quot;]</code>). During generation, we simply stop whenever we encounter the EOS token (or if we hit some maximum sequence length):</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def generate(inputs, eos_id, max_seq_len):
	prompt_len = len(inputs)
	while inputs[-1] != eos_id and len(inputs) &lt; max_seq_len:
        output = gpt(inputs)
        next_id = np.argmax(output[-1])
        inputs.append(int(next_id))
    return inputs[prompt_len:]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p><strong>GPT</strong>-2 was not pre-trained with an EOS token, so we can’t use this approach in our code, but most LLMs nowadays use an EOS token.</p></div><div id="iLqwgDLsll" class="myst-jp-nb-block relative group/block"><h3 id="fine-tuning" class="relative group"><span class="heading-text">Fine-tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#fine-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="XmJ2umBuEe" class="myst-jp-nb-block relative group/block"><p>We briefly touched on fine-tuning in the training section. Recall, fine-tuning is when we re-use the pre-trained weights to train the model on some downstream task. We call this process transfer-learning. In theory, we could use zero-shot or few-shot prompting to get the model to complete our task, however, if you have access to a labelled dataset, fine-tuning a <strong>GPT</strong> is going to yield better results (results that can scale given additional data and higher quality data). There are a couple different topics related to fine-tuning, as described below:</p></div><div id="l7LBGqW2jf" class="myst-jp-nb-block relative group/block"><h4 id="classification-fine-tuning" class="relative group"><span class="heading-text">Classification Fine-tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#classification-fine-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="vWcFxU5b0S" class="myst-jp-nb-block relative group/block"><p>In classification fine-tuning, we give the model some text and we ask it to predict which class it belongs to. For example, consider the <a target="_blank" rel="noreferrer" href="https://huggingface.co/datasets/imdb" class="link">IMDB dataset<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, which contains movie reviews that rate the movie as either good, or bad:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">--- Example 1 ---
Text: I wouldn&#x27;t rent this one even on dollar rental night.
Label: Bad
--- Example 2 ---
Text: I don&#x27;t know why I like this movie so well, but I never get tired of watching it.
Label: Good
--- Example 3 ---
...</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>To fine-tune our model, we replace the language modeling head with a classification head, which we apply to the last token output:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def gpt2(inputs, wte, wpe, blocks, ln_f, cls_head, n_head):
    x = wte[inputs] + wpe[range(len(inputs))]
    for block in blocks:
        x = transformer_block(x, **block, n_head=n_head)
    x = layer_norm(x, **ln_f)

	# project to n_classes
	# [n_embd] @ [n_embd, n_classes] -&gt; [n_classes]
    return x[-1] @ cls_head</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>We only use the last token output <code>x[-1]</code> because we only need to produce a single probability distribution for the entire input instead of <code>n_seq</code> distributions as in the case of language modeling. We take the last token in particular (instead of say the first token or a combination of all the tokens) because the last token is the only token that is allowed to attend to the entire sequence and thus has information about the input text as a whole. As per usual, we optimize <strong>w.r.t.</strong> the cross entropy <strong>loss</strong>:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def singe_example_loss_fn(inputs: list[int], label: int, params) -&gt; float:
    logits = gpt(inputs, **params)
    probs = softmax(logits)
    loss = -np.log(probs[label]) # cross entropy loss
    return loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="a123AkV3kP" class="myst-jp-nb-block relative group/block"><h4 id="generative-fine-tuning" class="relative group"><span class="heading-text">Generative Fine-tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#generative-fine-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="IxyrKzACI9" class="myst-jp-nb-block relative group/block"><p>Some tasks can’t be neatly categorized into classes. For example, consider the task of summarization. We can fine-tune these types of task by simply performing language modeling on the input concatenated with the label. For example, here’s what a single summarization training sample might look like:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">--- Article ---
This is an article I would like to summarize.
--- Summary ---
This is the summary.</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>We train the model as we do during pre-training (optimize <strong>w.r.t</strong> language modeling <strong>loss</strong>). At predict time, we feed the model the everything up to <code>--- Summary ---</code> and then perform auto-regressive language modeling to generate the summary. The choice of the delimiters <code>--- Article ---</code> and <code>--- Summary ---</code> are arbitrary. How you choose to format the text is up to you, as long as it is consistent between training and inference. Notice, we can also formulate classification tasks as generative tasks (for example with IMDB):</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">--- Text ---
I wouldn&#x27;t rent this one even on dollar rental night.
--- Label ---
Bad</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>However, this will probably perform worse than doing classification fine-tuning directly (<strong>loss</strong> includes language modeling on the entire sequence, not just the final prediction, so the <strong>loss</strong> specific to the prediction will get diluted)</p></div><div id="RKkNbmqLJn" class="myst-jp-nb-block relative group/block"><h4 id="instruction-fine-tuning" class="relative group"><span class="heading-text">Instruction Fine-tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#instruction-fine-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="KINxzRFLP2" class="myst-jp-nb-block relative group/block"><p>Most state-of-the-art large language models these days also undergo an additional instruction fine-tuning step after being pre-trained. In this step, the model is fine-tuned (generative) on thousands of instruction prompt + completion pairs that were human labeled. Instruction fine-tuning can also be referred to as supervised fine-tuning, since the data is human labelled (i.e. supervised). So what’s the benefit of instruction fine-tuning? While predicting the next word in a wikipedia article makes the model is good at continuing sentences, it doesn’t make it particularly good at following instructions, or having a conversation, or summarizing a document (all the things we would like a <strong>GPT</strong> to do). Fine-tuning them on human labelled instruction + completion pairs is a way to teach the model how it can be more useful, and make them easier to interact with. This call this AI alignment, as we are aligning the model to do and behave as we want it to. Alignment is an active area of research, and includes more than just following instructions (bias, safety, intent, etc ...). What does this instruction data look like exactly? Google’s <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2109.01652.pdf" class="link">FLAN<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> models were trained on various academic NLP datasets (which are already human labelled):</p></div><div id="ZpwpHlz9fQ" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;fig_3_from_flan_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="TZhcQ5OrY-dKn472BtC2-" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/269015026799f69183904e1e2efa752b.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="uPALvdtonO" class="myst-jp-nb-block relative group/block"><p>OpenAI’s <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2203.02155.pdf" class="link">InstructGPT<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> on the other hand was trained on prompts collected from their own API. They then paid workers to write completions for those prompts. Here’s a breakdown of the data:</p></div><div id="s8p4dVa3ir" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;table_1_and_2_from_instructgpt_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="VC3nqeCY9PGPfBa2GFC3R" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/0ac97a4b8b67347c6ccd5b68b7057f03.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="UrCvkZRSJ9" class="myst-jp-nb-block relative group/block"><h4 id="parameter-efficient-fine-tuning" class="relative group"><span class="heading-text">Parameter Efficient Fine-tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#parameter-efficient-fine-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="MBkpSOMQMW" class="myst-jp-nb-block relative group/block"><p>When we talk about fine-tuning in the above sections, it is assumed that we are updating all of the model parameters. While this yields the best performance, it is costly both in terms of compute (need to back propagate over the entire model) and in terms of storage (for each fine-tuned model, you need to store a completely new copy of the parameters). For instruction fine-tuning, this is fine, we want maximum performance, but if you then wanted to fine-tune 100 different models for various downstream tasks, then you’d have a problem. The most simple approach to this problem is to only update the head and freeze (i.e. make untrainable) the rest of the model. This would speed up training and greatly reduce the number of new parameters, however it would not perform nearly as well as a full fine-tune (we are lacking the deep in deep learning). We could instead selectively freeze specific layers (i.e. freeze all layers except the last 4, or freeze every other layer, or freeze all parameters except multi-head attention parameters), which would help restore some of the depth. This will perform a lot better, but we become a lot less parameter efficient and reduce our training speed ups. Instead, we can utilize parameter-efficient fine-tuning (PEFT) methods. PEFT is active area of research, and there are <a target="_blank" rel="noreferrer" href="https://aclanthology.org/2021.emnlp-main.243.pdf" class="link">lots<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2110.07602.pdf" class="link">of<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2101.00190.pdf" class="link">different<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2103.10385.pdf" class="link">methods<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/2106.09685.pdf" class="link">to<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1902.00751.pdf" class="link">choose<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/2205.05638" class="link">from<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. As an example, take the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1902.00751.pdf" class="link">Adapters paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. In this approach, we add an additional “adapter” layer after the FFN and MHA layers in the transformer block. The adapter layer is just a simple 2 layer fully connected <strong>nn</strong>, where the input and output dimensions are <code>n_embd</code>, and the hidden dimension is smaller than <code>n_embd</code>:</p></div><div id="msYULsVHEF" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;fig_2_from_the_adapters_paper.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="oI0sq3jaXegfPn2PUfeuW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/8a2b43381f7a8309dc25f86c906c8d7f.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div class="myst-backmatter-parts"></div><div class="myst-footer-links flex pt-10 mb-10 space-x-4"><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-prev" href="/micrograduate/makemore5"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">microgra∇uate</div>6. makemore (part 5): building a WaveNet</div></div></a></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/build/_shared/chunk-7UUHRSK3.js"/><link rel="modulepreload" href="/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-EDJFWIEV.js"/><link rel="modulepreload" href="/build/_shared/chunk-ECLX7DIY.js"/><link rel="modulepreload" href="/build/routes/$-AD65NCUT.js"/><script>window.__remixContext = {"url":"/micrograduate/picogpt","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.8.0","options":{"favicon":"/build/logo-0c799f4fa809820562f5343e2dfd511f.png","logo":"/build/logo-0c799f4fa809820562f5343e2dfd511f.png","folders":true},"nav":[],"actions":[],"projects":[{"title":"microgra∇uate","github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","toc":[{"file":"index.md"},{"file":"micrograduate/micrograd.ipynb"},{"file":"micrograduate/makemore1.ipynb"},{"file":"micrograduate/makemore2.ipynb"},{"file":"micrograduate/makemore3.ipynb"},{"file":"micrograduate/makemore4.ipynb"},{"file":"micrograduate/makemore5.ipynb"},{"file":"micrograduate/picogpt.ipynb"}],"thumbnail":"/build/heading-5136875723662cf20389e350ea1e81d6.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"micrograduate.micrograd","title":"1. micrograd: implementing an autograd engine","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore1","title":"2. makemore (part 1): implementing a bigram character-level language model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore2","title":"3. makemore (part 2): mlp","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore3","title":"4. makemore (part 3): activations \u0026 gradients, batchnorm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore4","title":"5. makemore (part 4): becoming a backprop ninja","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore5","title":"6. makemore (part 5): building a WaveNet","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.picogpt","title":"7. picoGPT: implementing a tiny GPT from scratch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":3,"myst":"1.8.0","options":{"favicon":"/build/logo-0c799f4fa809820562f5343e2dfd511f.png","logo":"/build/logo-0c799f4fa809820562f5343e2dfd511f.png","folders":true},"nav":[],"actions":[],"projects":[{"title":"microgra∇uate","github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","toc":[{"file":"index.md"},{"file":"micrograduate/micrograd.ipynb"},{"file":"micrograduate/makemore1.ipynb"},{"file":"micrograduate/makemore2.ipynb"},{"file":"micrograduate/makemore3.ipynb"},{"file":"micrograduate/makemore4.ipynb"},{"file":"micrograduate/makemore5.ipynb"},{"file":"micrograduate/picogpt.ipynb"}],"thumbnail":"/build/heading-5136875723662cf20389e350ea1e81d6.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"micrograduate.micrograd","title":"1. micrograd: implementing an autograd engine","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore1","title":"2. makemore (part 1): implementing a bigram character-level language model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore2","title":"3. makemore (part 2): mlp","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore3","title":"4. makemore (part 3): activations \u0026 gradients, batchnorm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore4","title":"5. makemore (part 4): becoming a backprop ninja","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore5","title":"6. makemore (part 5): building a WaveNet","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.picogpt","title":"7. picoGPT: implementing a tiny GPT from scratch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":3,"kind":"Notebook","sha256":"ef56e6fa946a34d600c25b431fc08992f20dd6d1ca4fcda438c0ba10e99be023","slug":"micrograduate.picogpt","location":"/micrograduate/picogpt.ipynb","dependencies":[],"frontmatter":{"title":"7. picoGPT: implementing a tiny GPT from scratch","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"micrograduate-env","language":"python"},"github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","source_url":"https://github.com/ckaraneen/micrograduate/blob/main/micrograduate/picogpt.ipynb","edit_url":"https://github.com/ckaraneen/micrograduate/edit/main/micrograduate/picogpt.ipynb","exports":[{"format":"ipynb","filename":"picogpt.ipynb","url":"/build/picogpt-bec72013e906ff96e8503907e53a421f.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import sys\n\nIN_COLAB = \"google.colab\" in sys.modules\nif IN_COLAB:\n    print(\"Cloning repo...\")\n    !git clone --quiet https://github.com/ckaraneen/micrograduate.git \u003e /dev/null\n    %cd micrograduate\n    print(\"Installing requirements...\")\n    !pip install --quiet uv\n    !uv pip install --system --quiet -r requirements.txt","key":"p1Lum7484W"},{"type":"outputs","id":"NFZDLkr12ElDx8u-sKkiv","children":[],"key":"AHW66h5sy6"}],"key":"IMsyE1e2gs"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Intro","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TduNyoUskn"}],"identifier":"intro","label":"Intro","html_id":"intro","implicit":true,"key":"hTaeRRiyIV"}],"key":"sDgmZPrpVd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In this lesson, we’ll implement a tiny ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GlUCCsZDug"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yDetKtB0nB"}],"key":"PEZH2I8Ma5"},{"type":"text","value":" from scratch in just a few lines of NumPy. To keep things simple, we’ll then load the trained ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zQCOyhIrhE"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Nhj4jbQwHG"}],"key":"qbLstH2cq0"},{"type":"text","value":"-2 model weights released by OpenAI into our implementation and generate some text. Sounds straightforward, right? Well, that’s because it is! Let’s get started.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eXirKkjP0r"}],"key":"gd8gTmC6en"}],"key":"da96wI87wJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lYQXToBBNT"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YuFc2RPgLt"}],"key":"vIAW8fBZUs"},{"type":"text","value":"?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qWDzS0YmP7"}],"identifier":"what-is-a-gpt","label":"What is a GPT?","html_id":"what-is-a-gpt","implicit":true,"key":"mNoTTaL6MN"}],"key":"mteC4DWxuP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hBljbCTAew"}],"key":"CF6gjUyG8H"},{"type":"text","value":" stands for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MmwNie0ffB"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Generative Pre-trained Transformer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MIC5JXWxmy"}],"key":"OfaQzR9NXQ"},{"type":"text","value":". It’s a type of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PDoYrsI7qy"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ut6jllspKO"}],"key":"KXwMIibkvL"},{"type":"text","value":" architecture based on the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nq6qcBNeN4"},{"type":"link","url":"https://arxiv.org/pdf/1706.03762.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Transformer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LRR0XaGUcc"}],"urlSource":"https://arxiv.org/pdf/1706.03762.pdf","key":"KDs2M0YAa8"},{"type":"text","value":". ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pWqEx1paV0"},{"type":"link","url":"https://jalammar.github.io/how-gpt3-works-visualizations-animations/","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Jay Alammar’s How ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"s5wRFuZUr7"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"X8p9msYVtR"}],"key":"yFvcv8VDGC"},{"type":"text","value":"3 Works","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ng44TfEjLn"}],"urlSource":"https://jalammar.github.io/how-gpt3-works-visualizations-animations/","key":"aTu637kD0m"},{"type":"text","value":" is an excellent introduction to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XUiswgt2zS"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"owi25kaHFs"}],"key":"hrl4uBFj7R"},{"type":"text","value":"s at a high level, but here’s the tl;dr:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K0EvENHLDb"}],"key":"n3Hp5ftNPC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Generative: A ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"BRT2N6xgun"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"YMGh3tnTEp"}],"key":"th1Z7aQiBL"},{"type":"text","value":" generates text.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"sJ1fdBK6xW"}],"key":"n51y2XjQaT"}],"key":"X15iFVirUH"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Pre-trained: A ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kFn2mb5reR"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nI9ZpdKda3"}],"key":"vKRbRreiEr"},{"type":"text","value":" is trained on lots of text from books, the internet, etc ...","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"se6YWWVWdi"}],"key":"N2VwoUbVz6"}],"key":"Xo1WjTRiCb"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Transformer: A ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"uOjdy7E31b"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"JvhKwRYglF"}],"key":"aPaIusQpzx"},{"type":"text","value":" is a decoder-only transformer ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Gk0ZOvevrs"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"BwGTAySecW"}],"key":"jUIAMteDzK"},{"type":"text","value":".","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"WYdtmYb4xZ"}],"key":"QjaWKKDDks"}],"key":"LYVHnI8xTR"}],"key":"Q3HEaeDspG"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Large Language Models (LLMs), like ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lh9rJnZ6WE"},{"type":"link","url":"https://en.wikipedia.org/wiki/GPT-3","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"OpenAI’s ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"SHcIBLKxsy"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"L3ikZDqVg6"}],"key":"sxZhL9ELLT"},{"type":"text","value":"-3","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"bVSsPtig93"}],"urlSource":"https://en.wikipedia.org/wiki/GPT-3","data":{"page":"GPT-3","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"YOyatlvJcf"},{"type":"text","value":", are just ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"LjhoFO0Iat"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Cdtkbg6GhE"}],"key":"WpwtinSEby"},{"type":"text","value":"s under the hood. What makes them special is they happen to be:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"vd3TL8m7D3"}],"key":"YOBf75gkRg"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"very big (billions of parameters) and","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YsuFoILEJk"}],"key":"DOKJrbG16b"}],"key":"Xt9fNs7Jbs"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"trained on lots of data (hundreds of gigabytes of text).","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"SkaZ4qyawU"}],"key":"kUQ3A09r1L"}],"key":"Pp9x07VUNj"}],"key":"FCicCgx8pH"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Fundamentally, a ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"V7Q2rOFS5a"},{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"Nb4y0oUbXS"}],"key":"Ynqoc9Am93"},{"type":"text","value":" generates text given a prompt. Even with this very simple API (input = text, output = text), a well-trained ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"n7AQWyQViM"},{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"czQ6zWIsWw"}],"key":"JtN8yQs0B3"},{"type":"text","value":" can do some pretty awesome stuff like ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"KiIflN3sue"},{"type":"link","url":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Demo-of-Drafting-an-Email.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"write your emails","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"WQRzoQimN8"}],"urlSource":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Demo-of-Drafting-an-Email.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","key":"lyP7Kq5ZEJ"},{"type":"text","value":", ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"GaVS0ahdBZ"},{"type":"link","url":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Example-Book-Summarization.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"summarize a book","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"pgahCqT82f"}],"urlSource":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Example-Book-Summarization.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","key":"w4dyPOzezp"},{"type":"text","value":", ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"JFgXJGChZM"},{"type":"link","url":"https://khrisdigital.com/wp-content/uploads/2022/12/image-1.png","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"give you instagram caption ideas","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"nbF8zDSVIu"}],"urlSource":"https://khrisdigital.com/wp-content/uploads/2022/12/image-1.png","key":"IlXhfcKmnZ"},{"type":"text","value":", ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"C0JykofTIi"},{"type":"link","url":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Examples-Explaining-Black-Holes.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"explain black holes to a 5 year old","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"d4AGr9dSkK"}],"urlSource":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Examples-Explaining-Black-Holes.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","key":"kuZjcJp0VN"},{"type":"text","value":", ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"MiJ769PghM"},{"type":"link","url":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Demo-of-Writing-SQL-Queries.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"code in SQL","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"VpFlKzp5ov"}],"urlSource":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/ChatGPT-Demo-of-Writing-SQL-Queries.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","key":"fUxYV7fgOG"},{"type":"text","value":", and even ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"F3hPy6tJjU"},{"type":"link","url":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/Chat-GPT-Example-Writing-a-Will.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"write your will","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"y0TvPN2NEX"}],"urlSource":"https://machinelearningknowledge.ai/ezoimgfmt/b2611031.smushcdn.com/2611031/wp-content/uploads/2022/12/Chat-GPT-Example-Writing-a-Will.png?lossy=0\u0026strip=1\u0026webp=1\u0026ezimgfmt=ng:webp/ngcb1","key":"n4B2l4BDNB"},{"type":"text","value":". So that’s a high-level overview of ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"c4qBAzXA1x"},{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"sgnqtw27b9"}],"key":"kXjLR5NlKU"},{"type":"text","value":"s and their capabilities. Let’s dig into some more specifics.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"FTEFKxE5aG"}],"key":"GVl8ohZDb5"}],"key":"GdMiIiCj7J"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Input / Output","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Pf4IvDyUQC"}],"identifier":"input-output","label":"Input / Output","html_id":"input-output","implicit":true,"key":"P7z9EjotWx"}],"key":"sDcfXVtyyZ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The function signature for a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hiCLSCGtxy"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xkVS8wfREX"}],"key":"zOef3lPQ1x"},{"type":"text","value":" looks roughly like this:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Abk9YHV3Q1"}],"key":"XeO4ZDuzA7"}],"key":"YSOAxLEaL9"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"def gpt(inputs: list[int]) -\u003e list[list[float]]:\n    # inputs has shape [n_seq]\n    # output has shape [n_seq, n_vocab]\n    output = # beep boop neural network magic\n    return output","position":{"start":{"line":1,"column":1},"end":{"line":7,"column":1}},"key":"EtnWlebT58"}],"key":"EpwDJgC0qV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Input","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bfm3Mty6CU"}],"identifier":"input","label":"Input","html_id":"input","implicit":true,"key":"liFUc1qDMh"}],"key":"xKmVsE0OEM"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The input is some text represented by a sequence of integers that map to tokens in the text:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nrV1cMlTYv"}],"key":"Fo1ek394Rk"}],"key":"agHTjhblM4"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"# integers represent tokens in our text, for example:\n# text   = \"not all heroes wear capes\":\n# tokens = \"not\"  \"all\" \"heroes\" \"wear\" \"capes\"\ninputs =   [1,     0,    2,      4,     6]","position":{"start":{"line":1,"column":1},"end":{"line":6,"column":1}},"key":"zVYxzjaAYB"}],"key":"AfsaMc8Mm2"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Tokens are sub-pieces of the text, which are produced using some kind of tokenizer. We can map tokens to integers using a vocabulary:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nAByiGFLkv"}],"key":"QNoGlwLro5"}],"key":"r1ocBtXYJK"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"# the index of a token in the vocab represents the integer id for that token\n# i.e. the integer id for \"heroes\" would be 2, since vocab[2] = \"heroes\"\nvocab = [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\n\n# a pretend tokenizer that tokenizes on whitespace\ntokenizer = WhitespaceTokenizer(vocab)\n\n# the encode() method converts a str -\u003e list[int]\nids = tokenizer.encode(\"not all heroes wear\") # ids = [1, 0, 2, 4]\n\n# we can see what the actual tokens are via our vocab mapping\ntokens = [tokenizer.vocab[i] for i in ids] # tokens = [\"not\", \"all\", \"heroes\", \"wear\"]\n\n# the decode() method converts back a list[int] -\u003e str\ntext = tokenizer.decode(ids) # text = \"not all heroes wear\"","position":{"start":{"line":1,"column":1},"end":{"line":17,"column":1}},"key":"RcvOzjn3gm"}],"key":"dvf0wPRqZf"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In short:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gooqgskfyY"}],"key":"eekksvXrPg"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We have a string.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"DlC1fdfEdz"}],"key":"lF9ZCtT0UX"}],"key":"Wy6OEiuCc8"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We use a tokenizer to break it down into smaller pieces called tokens.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mm8xou5OHv"}],"key":"XR0pV2jpDg"}],"key":"cnYjS7xFzk"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We use a vocabulary to map those tokens to integers.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"LZjLvxF1jT"}],"key":"LL1ELRxWSC"}],"key":"PkVThnZCYi"}],"key":"nXSicRALup"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"In practice, we use more advanced methods of tokenization than simply splitting by whitespace, such as ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"EQWs0U1DDC"},{"type":"link","url":"https://huggingface.co/course/chapter6/5?fw=pt","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Byte-Pair Encoding","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"gD2AtJRswW"}],"urlSource":"https://huggingface.co/course/chapter6/5?fw=pt","key":"Ii9Pe3d0Hz"},{"type":"text","value":" or ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lMEpu7f9Fk"},{"type":"link","url":"https://huggingface.co/course/chapter6/6?fw=pt","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"WordPiece","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"VHyibZzIVH"}],"urlSource":"https://huggingface.co/course/chapter6/6?fw=pt","key":"WmLSXTMKjQ"},{"type":"text","value":", but the principle is the same:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Rsz2oy4gZK"}],"key":"lU55Jyc4Xh"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"There is a ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"pEdVNTQ7Eu"},{"type":"inlineCode","value":"vocab","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"DYZul5GuqR"},{"type":"text","value":" that maps string tokens to integer indices","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ix7Fat3ltV"}],"key":"xgEuhlcRTz"}],"key":"GVXJAW3Qbf"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"There is an ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"W4ywG7WZnE"},{"type":"inlineCode","value":"encode","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"PUjlCEVlAJ"},{"type":"text","value":" method that converts ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ggXQ8gOOV5"},{"type":"inlineCode","value":"str -\u003e list[int]","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cvZRQNNCr8"}],"key":"Jjy0eCiQmf"}],"key":"KK41xOjVqP"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"There is a ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"dv7Gc5b9tI"},{"type":"inlineCode","value":"decode","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"rnkoFddmSy"},{"type":"text","value":" method that converts ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"VYJqtKh4Q6"},{"type":"inlineCode","value":"list[int] -\u003e str","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"Pen28NcZ6L"}],"key":"M3Ein1lPUG"}],"key":"waoiuUy67J"}],"key":"X2CA73iFqb"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"mUcBWegJHl"}],"key":"Y9zLknsPjx"},{"type":"text","value":": For certain applications, the tokenizer doesn’t require a decode method. For example, if you want to classify if a movie review is saying the movie was good or bad, you only need to be able to encode the text and do a forward pass of the model, there is no need for decode. For generating text however, decode is a requirement. ↩︎","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"gdKrBkapCL"}],"key":"POLmZMVFjO"}],"key":"PNaBDWGQGF"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Output","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ryh3aRkmKI"}],"identifier":"output","label":"Output","html_id":"output","implicit":true,"key":"lMQLBxHRI0"}],"key":"F3QbFfgSW9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The output is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yvDiA0XRcb"},{"type":"inlineMath","value":"2D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"w60mjUYqYX"},{"type":"text","value":" array, where ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MbfPBScG1s"},{"type":"inlineCode","value":"output[i][j]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wOxGfRC37W"},{"type":"text","value":" is the model’s predicted probability that the token at ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Av7YkWozyf"},{"type":"inlineCode","value":"vocab[j]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QEqQnydlYk"},{"type":"text","value":" is the next token ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nGFn62CE0N"},{"type":"inlineCode","value":"inputs[i+1]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v6lNub9Ina"},{"type":"text","value":". For example:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kjTM44vRry"}],"key":"ZXUSPZS2mH"}],"key":"kr1xXMRGas"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"vocab = [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\ninputs = [1, 0, 2, 4] # \"not\" \"all\" \"heroes\" \"wear\"\noutput = gpt(inputs)\n#              [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\n# output[0] =  [0.75    0.1     0.0       0.15    0.0   0.0    0.0  ]\n# given just \"not\", the model predicts the word \"all\" with the highest probability\n\n#              [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\n# output[1] =  [0.0     0.0      0.8     0.1    0.0    0.0   0.1  ]\n# given the sequence [\"not\", \"all\"], the model predicts the word \"heroes\" with the highest probability\n\n#              [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\n# output[-1] = [0.0     0.0     0.0     0.1     0.0    0.05  0.85  ]\n# given the whole sequence [\"not\", \"all\", \"heroes\", \"wear\"], the model predicts the word \"capes\" with the highest probability","position":{"start":{"line":1,"column":1},"end":{"line":16,"column":1}},"key":"oed61zRtWM"}],"key":"JMm9uikZzE"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To get a next token prediction for the whole sequence, we simply take the token with the highest probability in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VHrhGpBPi2"},{"type":"inlineCode","value":"output[-1]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dtONq5k35Z"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"etEXRh4B1I"}],"key":"escdqGXkDW"}],"key":"h1hQpmMzCP"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"vocab = [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\ninputs = [1, 0, 2, 4] # \"not\" \"all\" \"heroes\" \"wear\"\noutput = gpt(inputs)\nnext_token_id = np.argmax(output[-1]) # next_token_id = 6\nnext_token = vocab[next_token_id] # next_token = \"capes\"","position":{"start":{"line":1,"column":1},"end":{"line":7,"column":1}},"key":"I1yCYVrsOL"}],"key":"kyHcJsqR6f"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Taking the token with the highest probability as our prediction is known as ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"B3nCKUuKYO"},{"type":"link","url":"https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#1-pick-the-top-token-greedy-decoding","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"greedy decoding","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"twWZo8hYok"}],"urlSource":"https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#1-pick-the-top-token-greedy-decoding","key":"DvovTk3Jhu"},{"type":"text","value":" or greedy sampling. The task of predicting the next logical word in a sequence is called language modeling. As such, we can call a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RPzJz6fW8q"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JVxrxN1JsD"}],"key":"S7aOo7Tkxn"},{"type":"text","value":" a language model. Generating a single word is cool and all, but what about entire sentences, paragraphs, etc ...?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xWlJfzGhTA"}],"key":"bftPgk5alt"}],"key":"Vh9KJmjoWc"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Generating text","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YmTO4oO6MH"}],"identifier":"generating-text","label":"Generating text","html_id":"generating-text","implicit":true,"key":"EuQ4xsi6zt"}],"key":"F6SVH0ddkV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Autoregressive","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xmg6cZCEdu"}],"identifier":"autoregressive","label":"Autoregressive","html_id":"autoregressive","implicit":true,"key":"Bmn5gitrUy"}],"key":"hDyXZVFJ79"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can generate full sentences by iteratively getting the next token prediction from our model. At each iteration, we append the predicted token back into the input:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WxNsrCBLn1"}],"key":"yQMvvdbIi7"}],"key":"NZnyXhDS1Z"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"def generate(inputs, n_tokens_to_generate):\n    for _ in range(n_tokens_to_generate): # auto-regressive decode loop\n        output = gpt(inputs) # model forward pass\n        next_id = np.argmax(output[-1]) # greedy sampling\n        inputs.append(int(next_id)) # append prediction to input\n    return inputs[len(inputs) - n_tokens_to_generate :]  # only return generated ids\n\ninput_ids = [1, 0] # \"not\" \"all\"\noutput_ids = generate(input_ids, 3) # output_ids = [2, 4, 6]\noutput_tokens = [vocab[i] for i in output_ids] # \"heroes\" \"wear\" \"capes\"","position":{"start":{"line":1,"column":1},"end":{"line":12,"column":1}},"key":"piWXvE3IPt"}],"key":"gd1RERM1Is"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This process of predicting a future value (regression), and adding it back into the input (auto), is why you might see a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LG2AKbBj2D"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cBW9vKyOgt"}],"key":"PhOkFEGq72"},{"type":"text","value":" described as autoregressive.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eZrDmgYDSI"}],"key":"xv8j3pPxf4"}],"key":"aW5IEQy9oJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Sampling","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NlaX3TalU9"}],"identifier":"sampling","label":"Sampling","html_id":"sampling","implicit":true,"key":"OO8lRY673H"}],"key":"f9u2DOxFl6"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can introduce some stochasticity (randomness) to our generations by sampling from the probability distribution instead of being greedy:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iUFJSHcyvO"}],"key":"WzqQo1j8Ec"}],"key":"zRhRJChI3H"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"inputs = [1, 0, 2, 4] # \"not\" \"all\" \"heroes\" \"wear\"\noutput = gpt(inputs)\nnp.random.choice(np.arange(vocab_size), p=output[-1]) # capes\nnp.random.choice(np.arange(vocab_size), p=output[-1]) # hats\nnp.random.choice(np.arange(vocab_size), p=output[-1]) # capes\nnp.random.choice(np.arange(vocab_size), p=output[-1]) # capes\nnp.random.choice(np.arange(vocab_size), p=output[-1]) # pants","position":{"start":{"line":1,"column":1},"end":{"line":9,"column":1}},"key":"fqSu8bVPrR"}],"key":"GJIa3cRTvP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This allows us to generate different sentences given the same input. When combined with techniques like ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UhyFVxvYbd"},{"type":"link","url":"https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#2-pick-from-amongst-the-top-tokens-top-k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"top-k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"plyjgdJZQC"}],"urlSource":"https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#2-pick-from-amongst-the-top-tokens-top-k","key":"Il2fgY6hWJ"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xxVzpldexK"},{"type":"link","url":"https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#3-pick-from-amongst-the-top-tokens-whose-probabilities-add-up-to-15-top-p","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"top-p","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jRfKLPmWcT"}],"urlSource":"https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p#3-pick-from-amongst-the-top-tokens-whose-probabilities-add-up-to-15-top-p","key":"Iv7JVfphLj"},{"type":"text","value":", and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NdGGkAzIDK"},{"type":"link","url":"https://docs.cohere.ai/docs/temperature","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"temperature","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WR8C77cVMZ"}],"urlSource":"https://docs.cohere.ai/docs/temperature","key":"T7dhSc8Eyu"},{"type":"text","value":", which modify the distribution prior to sampling, the quality of our outputs is greatly increased. These techniques also introduce some hyperparameters that we can play around with to get different generation behaviors (for example, increasing temperature makes our model take more risks and thus be more “creative”.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"abALlan1lK"}],"key":"I1x6XPE17U"}],"key":"W37x6F7112"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zkST7xkDmS"}],"identifier":"training","label":"Training","html_id":"training","implicit":true,"key":"zbNLHjDzZi"}],"key":"TliegPATfP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We train a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OZ622FYYni"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CQhor44PF9"}],"key":"uzHABrnZSi"},{"type":"text","value":" like any other ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"su96sJCvL4"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eC9bbQjRFa"}],"key":"pzitueCSIH"},{"type":"text","value":", using gradient descent ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qqljToCUD7"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"w.r.t.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t3YQOe92kY"}],"key":"xZoK3AuXGm"},{"type":"text","value":" some ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kvaJW3WOf9"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GkNY7rsURg"}],"key":"xAatrY7I5L"},{"type":"text","value":" function. In the case of a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VxoilvCaGJ"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bpjLnkFf6i"}],"key":"ZOvmeSYzgj"},{"type":"text","value":", we take the cross entropy ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d62ErHages"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QsCCu2Ombu"}],"key":"ZEVm8FzSGG"},{"type":"text","value":" over the language modeling task:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VZBSvKBAfZ"}],"key":"TTFo36ROZh"}],"key":"WBC6Tn4bNL"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"def lm_loss(inputs: list[int], params) -\u003e float:\n    # the labels y are just the input shifted 1 to the left\n    #\n    # inputs = [not,     all,   heros,   wear,   capes]\n    #      x = [not,     all,   heroes,  wear]\n    #      y = [all,  heroes,     wear,  capes]\n    #\n    # of course, we don't have a label for inputs[-1], so we exclude it from x\n    #\n    # as such, for N inputs, we have N - 1 language modeling example pairs\n    x, y = inputs[:-1], inputs[1:] # both have shape [num_tokens_in_seq - 1]\n\n    # forward pass\n    # all the predicted next token probability distributions at each position\n    output = gpt(x, params) # has shape [num_tokens_in_seq - 1, num_tokens_in_vocab]\n\n    # cross entropy loss\n    # we take the average over all N-1 examples\n    loss = np.mean(-np.log(output[np.arange(len(output)), y]))\n\n    return loss\n\ndef train(texts: list[list[str]], params) -\u003e float:\n    for text in texts:\n        inputs = tokenizer.encode(text)\n        loss = lm_loss(inputs, params)\n        gradients = compute_gradients_via_backpropagation(loss, params)\n        params = gradient_descent_update_step(gradients, params)\n    return params","position":{"start":{"line":1,"column":1},"end":{"line":31,"column":1}},"key":"GW2oJBRNfI"}],"key":"eZxssZhGgE"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This is a heavily simplified training setup, but it illustrates the point. Notice the addition of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GR4GTJiHH7"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DrN7JEaw1N"},{"type":"text","value":" to our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QPzPqGTheZ"},{"type":"inlineCode","value":"gpt","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cn2ziICnwf"},{"type":"text","value":" function signature (we left this out in the previous sections for simplicity). During each iteration of the training loop:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ve0DHnwk1R"}],"key":"zEczTP4DzQ"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We compute the language modeling ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SSg02cEHq2"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cyoTZ75YFR"}],"key":"BD13epV4jq"},{"type":"text","value":" for the given input text example","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jvh4QxjEji"}],"key":"N8zwnq25aa"}],"key":"DP8wAhbwQt"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"wotZiOEkcA"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"bElMzalIW2"}],"key":"njZeeIfaIg"},{"type":"text","value":" determines our gradients, which we compute via ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"i6hBH6vfzQ"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"backprop","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Ea8IyfNxiW"}],"key":"FpaC4tds2G"}],"key":"K4q6rx97W7"}],"key":"LTDOaoS2ub"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We use the gradients to update our model parameters such that the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"KTA3EdA9i9"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zGotGVq2Me"}],"key":"djmkgi4IJO"},{"type":"text","value":" is minimized (gradient descent)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LPs4NBnMJU"}],"key":"G8t1MfbSSp"}],"key":"RZrkdObPKB"}],"key":"eLrZFLJKQT"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Notice, we don’t use explicitly labelled data. Instead, we are able to produce the input/label pairs from just the raw text itself. This is referred to as ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ZSuwC0lK7H"},{"type":"link","url":"https://en.wikipedia.org/wiki/Self-supervised_learning","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"self-supervised learning","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YGZ8PeUhYn"}],"urlSource":"https://en.wikipedia.org/wiki/Self-supervised_learning","data":{"page":"Self-supervised_learning","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"MLKZdUNjRU"},{"type":"text","value":". Self-supervision enables us to massively scale training data. Just get our hands on as much raw text as possible and throw it at the model. For example, ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NET7K7mQPd"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AcFug5px08"}],"key":"crxwP6XJjB"},{"type":"text","value":"-3 was trained on 300 billion tokens of text from the internet and books:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"teVdCFMdKl"}],"key":"uAQ7RegOkL"}],"key":"sewWS7dCgr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"table_2.2_gpt3_paper.png\"))","key":"aIU1O68dYT"},{"type":"outputs","id":"DB6F8jllVQw4ViYsvNDbI","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"a76b56e9630ed69223a51aa05e32ed05","path":"/build/a76b56e9630ed69223a51aa05e32ed05.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"ZTQUSHmwQ2"}],"key":"ml53qAMYBE"}],"key":"t9m8KtjWbL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Of course, you need a sufficiently large model to be able to learn from all this data, which is why ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IRoSO4zBM5"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"crmQYdJ2jw"}],"key":"snc895BQCW"},{"type":"text","value":"-3 has 175 billion parameters and probably cost between ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"APkpbyJ4NO"},{"type":"link","url":"https://twitter.com/eturner303/status/1266264358771757057","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"$1m-10m in compute cost to train","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M7hi167EaH"}],"urlSource":"https://twitter.com/eturner303/status/1266264358771757057","key":"JBkBLBda83"},{"type":"text","value":". This self-supervised training step is called pre-training, since we can reuse the “pre-trained” models weights to further train the model on downstream tasks, such as classifying if a tweet is toxic or not. Pre-trained models are also sometimes called foundation models. Training the model on downstream tasks is called fine-tuning, since the model weights have already been pre-trained to understand language, it’s just being fine-tuned to the specific task at hand. The “pre-training on a general task + fine-tuning on a specific task” strategy is called ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zjeTwlkJ8v"},{"type":"link","url":"https://en.wikipedia.org/wiki/Transfer_learning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"transfer learning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GtfXIvl5J1"}],"urlSource":"https://en.wikipedia.org/wiki/Transfer_learning","data":{"page":"Transfer_learning","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ZE27uBgMdn"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"y32JOzWAJZ"}],"key":"qjnp4Nb2GQ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"RJ79YQ7hpA"}],"key":"j1i8Ff3Vbk"},{"type":"text","value":": Although, with the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YOAgXfz5ok"},{"type":"link","url":"https://arxiv.org/pdf/2210.11416.pdf","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"InstructGPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hiStQCvG2m"}],"urlSource":"https://arxiv.org/pdf/2210.11416.pdf","key":"y5Go2usKoo"},{"type":"text","value":" and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zyKFEDyUTm"},{"type":"link","url":"https://arxiv.org/pdf/2203.15556.pdf","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Chinchilla","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hkkJutAFmY"}],"urlSource":"https://arxiv.org/pdf/2203.15556.pdf","key":"oQPTVrMbmq"},{"type":"text","value":" papers, we’ve realized that we don’t actually need to train models that big. An optimally trained and instruction fine-tuned ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WMLOfCOyaX"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AHWdQQQ2gj"}],"key":"Gga3SHNMJo"},{"type":"text","value":" at 1.3B parameters can outperform ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TOFEVPSdSE"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qG3e35UOhV"}],"key":"dXL8qS8B8M"},{"type":"text","value":"-3 at 175B parameters.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DyqyzJQyTu"}],"key":"sYeohPD1MU"}],"key":"r8nZczrn8R"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Prompting","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZmcW3lfn7Z"}],"identifier":"prompting","label":"Prompting","html_id":"prompting","implicit":true,"key":"uFZreBrVuh"}],"key":"OqplaXLSJI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In principle, the original ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wG3n6JBot1"},{"type":"link","url":"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rgymKrYFGh"}],"key":"cCbLcHFlky"}],"urlSource":"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf","key":"m5AMzg3caX"},{"type":"text","value":" paper was only about the benefits of pre-training a transformer model for transfer learning. The paper showed that pre-training a 117M ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vVRoLldH2X"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pvmOQGvFuh"}],"key":"sBqeYsYkJS"},{"type":"text","value":" achieved state-of-the-art performance on various NLP (natural language processing) tasks when fine-tuned on labelled datasets. It wasn’t until the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Cz5ZGGYSq0"},{"type":"link","url":"https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wMkPLlfnSu"}],"key":"c6QGh4Z3k0"},{"type":"text","value":"-2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gV1ZnrjQD2"}],"urlSource":"https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf","key":"rSICGxMFTe"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kjzitUEgJ9"},{"type":"link","url":"https://arxiv.org/abs/2005.14165","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aUErARxnXa"}],"key":"YznjW4EqD2"},{"type":"text","value":"-3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SXDnqqIGuR"}],"urlSource":"https://arxiv.org/abs/2005.14165","key":"tSo3SEGaah"},{"type":"text","value":" papers that we realized a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uYPvIIhelI"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fRTomJxFhN"}],"key":"dBq09xShpf"},{"type":"text","value":" model pre-trained on enough data with enough parameters was capable of performing any arbitrary task by itself, no fine-tuning needed. Just prompt the model, perform autoregressive language modeling, and voila, the model magically gives us an appropriate response. This is referred to as in-context learning, because the model is using just the context of the prompt to perform the task. In-context learning can be zero shot, one shot, or few shot:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"i7GibN28FE"}],"key":"Prj1Lec9kR"}],"key":"PHDXf3r3eH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"fig_2.1_gpt3_paper.png\"))","key":"i4QpNp1bST"},{"type":"outputs","id":"q9eu4G4YwzjFGb10CjXwV","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"601e5b77d2987b0a7552484cf5cc5925","path":"/build/601e5b77d2987b0a7552484cf5cc5925.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"DPsil1EPzd"}],"key":"CyOuXbJG38"}],"key":"ZNmdNyEPQO"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Generating text given a prompt is also sometimes referred to as conditional generation, since our model is generating some output conditioned on some input. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RqwUHUD6SN"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rDy0S4VVx5"}],"key":"Utsy4vFdJR"},{"type":"text","value":"s are not limited to NLP tasks. You can condition the model on anything you want. For example, you can turn a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Z1EQePkMwa"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VtES4gcNji"}],"key":"DvL1ubOVlp"},{"type":"text","value":" into a chatbot (i.e. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iqIfOKaTl9"},{"type":"link","url":"https://openai.com/index/chatgpt/","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Chat","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l9FxxvM2RX"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sdwyHrh5JF"}],"key":"hmZv3RXVwA"}],"urlSource":"https://openai.com/index/chatgpt/","key":"NliD2Jj8nB"},{"type":"text","value":") by conditioning it on the conversation history. You can also further condition the chatbot to behave a certain way by prepending the prompt with some kind of description (i.e. “You are a chatbot. Be polite, speak in full sentences, don’t say harmful things, etc ...”). Conditioning the model like this can even give your ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"APxBMx1AOI"},{"type":"link","url":"https://imgur.com/a/AbDFcgk","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"chatbot a persona","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iLCnk7GWav"}],"urlSource":"https://imgur.com/a/AbDFcgk","key":"NDYs2BP60k"},{"type":"text","value":". This is often referred to as a system prompt. However, this is not robust, you can still ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jjWZyOnrFy"},{"type":"link","url":"https://twitter.com/zswitten/status/1598380220943593472","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"“jailbreak” the model and make it misbehave","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e6fnU3Z99w"}],"urlSource":"https://twitter.com/zswitten/status/1598380220943593472","key":"L6NsKbTO0t"},{"type":"text","value":". With that out of the way, let’s finally get to the actual implementation.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NAgiwqHsBo"}],"key":"eothH8CQ2p"}],"key":"oSDe4KRmxn"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Setup","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VBTpTPpUKQ"}],"identifier":"setup","label":"Setup","html_id":"setup","implicit":true,"key":"chB4buGVpI"}],"key":"UEw57GKpei"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s dive right into the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aUH69kjhgH"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oZCnrSqNSu"}],"key":"ny9mKEjxQz"},{"type":"text","value":" implementation. First though, let’s define the necessary functions for downloading the model of our choice and the tokenizer files for  loading ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tl1gopqUXv"},{"type":"inlineCode","value":"encoder","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VtTowtqoCE"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nJmQc8wbrU"},{"type":"inlineCode","value":"hparams","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PS115l4d23"},{"type":"text","value":", and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bxJLUVGYTG"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LJ24n5tf0x"},{"type":"text","value":" into our code:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FHboh99EUh"}],"key":"qdefi5Q80k"}],"key":"w71u2InFid"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"\"\"\"Byte pair encoding utilities.\n\nContains the code for OpenAI's BPE Tokenizer, taken straight from their gpt-2 repo: https://github.com/openai/gpt-2/blob/master/src/encoder.py.\n\"\"\"\n\nimport json\nimport os\nfrom functools import lru_cache\nimport regex as re\n\n\n@lru_cache()\ndef bytes_to_unicode():\n    \"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a significant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"\n    bs = (\n        list(range(ord(\"!\"), ord(\"~\") + 1))\n        + list(range(ord(\"¡\"), ord(\"¬\") + 1))\n        + list(range(ord(\"®\"), ord(\"ÿ\") + 1))\n    )\n    cs = bs[:]\n    n = 0\n    for b in range(2**8):\n        if b not in bs:\n            bs.append(b)\n            cs.append(2**8 + n)\n            n += 1\n    cs = [chr(n) for n in cs]\n    return dict(zip(bs, cs))\n\n\ndef get_pairs(word):\n    \"\"\"Return set of symbol pairs in a word.\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"\n    pairs = set()\n    prev_char = word[0]\n    for char in word[1:]:\n        pairs.add((prev_char, char))\n        prev_char = char\n    return pairs\n\n\nclass Encoder:\n    def __init__(self, encoder, bpe_merges, errors=\"replace\"):\n        self.encoder = encoder\n        self.decoder = {v: k for k, v in self.encoder.items()}\n        self.errors = errors  # how to handle errors in decoding\n        self.byte_encoder = bytes_to_unicode()\n        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))\n        self.cache = {}\n\n        # Should have added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions\n        self.pat = re.compile(\n            r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n        )\n\n    def bpe(self, token):\n        if token in self.cache:\n            return self.cache[token]\n        word = tuple(token)\n        pairs = get_pairs(word)\n\n        if not pairs:\n            return token\n\n        while True:\n            bigram = min(pairs, key=lambda pair: self.bpe_ranks.get(pair, float(\"inf\")))\n            if bigram not in self.bpe_ranks:\n                break\n            first, second = bigram\n            new_word = []\n            i = 0\n            while i \u003c len(word):\n                try:\n                    j = word.index(first, i)\n                    new_word.extend(word[i:j])\n                    i = j\n                except:\n                    new_word.extend(word[i:])\n                    break\n\n                if word[i] == first and i \u003c len(word) - 1 and word[i + 1] == second:\n                    new_word.append(first + second)\n                    i += 2\n                else:\n                    new_word.append(word[i])\n                    i += 1\n            new_word = tuple(new_word)\n            word = new_word\n            if len(word) == 1:\n                break\n            else:\n                pairs = get_pairs(word)\n        word = \" \".join(word)\n        self.cache[token] = word\n        return word\n\n    def encode(self, text):\n        bpe_tokens = []\n        for token in re.findall(self.pat, text):\n            token = \"\".join(self.byte_encoder[b] for b in token.encode(\"utf-8\"))\n            bpe_tokens.extend(\n                self.encoder[bpe_token] for bpe_token in self.bpe(token).split(\" \")\n            )\n        return bpe_tokens\n\n    def decode(self, tokens):\n        text = \"\".join([self.decoder[token] for token in tokens])\n        text = bytearray([self.byte_decoder[c] for c in text]).decode(\n            \"utf-8\", errors=self.errors\n        )\n        return text\n\n\ndef get_encoder(model_name, models_dir):\n    with open(os.path.join(models_dir, model_name, \"encoder.json\"), \"r\") as f:\n        encoder = json.load(f)\n    with open(\n        os.path.join(models_dir, model_name, \"vocab.bpe\"), \"r\", encoding=\"utf-8\"\n    ) as f:\n        bpe_data = f.read()\n    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split(\"\\n\")[1:-1]]\n    return Encoder(encoder=encoder, bpe_merges=bpe_merges)","key":"XhXgOIe6ic"},{"type":"outputs","id":"5y7haKoAEkwkZtl4ELx4h","children":[],"key":"YJ44VZTd8D"}],"key":"OSMZBFc3dT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"\"\"\"GPT-2 utilities.\n\nContains the code to download and load the GPT-2 model weights, tokenizer, and hyperparameters.\n\"\"\"\n\nimport json\nimport os\nimport requests\nimport tensorflow as tf\nfrom tqdm import tqdm\n\n\ndef download_gpt2_files(model_size, model_dir):\n    assert model_size in [\"124M\", \"355M\", \"774M\", \"1558M\"]\n    for filename in [\n        \"checkpoint\",\n        \"encoder.json\",\n        \"hparams.json\",\n        \"model.ckpt.data-00000-of-00001\",\n        \"model.ckpt.index\",\n        \"model.ckpt.meta\",\n        \"vocab.bpe\",\n    ]:\n        url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n        r = requests.get(f\"{url}/{model_size}/{filename}\", stream=True)\n        r.raise_for_status()\n\n        with open(os.path.join(model_dir, filename), \"wb\") as f:\n            file_size = int(r.headers[\"content-length\"])\n            chunk_size = 1000\n            with tqdm(\n                ncols=100,\n                desc=\"Fetching \" + filename,\n                total=file_size,\n                unit_scale=True,\n            ) as pbar:\n                # 1k for chunk_size, since Ethernet packet size is around 1500 bytes\n                for chunk in r.iter_content(chunk_size=chunk_size):\n                    f.write(chunk)\n                    pbar.update(chunk_size)\n\n\ndef load_gpt2_params_from_tf_ckpt(tf_ckpt_path, hparams):\n    import re\n    import numpy as np\n\n    def set_in_nested_dict(d, keys, val):\n        if not keys:\n            return val\n        if keys[0] not in d:\n            d[keys[0]] = {}\n        d[keys[0]] = set_in_nested_dict(d[keys[0]], keys[1:], val)\n        return d\n\n    init_vars = tf.train.list_variables(tf_ckpt_path)\n    params = {\"blocks\": [{} for _ in range(hparams[\"n_layer\"])]}\n    for name, _ in init_vars:\n        array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))\n        name = name.removeprefix(\"model/\")\n        if name.startswith(\"h\"):\n            m = re.match(r\"h([0-9]+)/(.*)\", name)\n            n = int(m[1])\n            sub_name = m[2]\n            set_in_nested_dict(params[\"blocks\"][n], sub_name.split(\"/\"), array)\n        else:\n            set_in_nested_dict(params, name.split(\"/\"), array)\n\n    return params\n\n\ndef load_encoder_hparams_and_params(model_size, models_dir):\n    assert model_size in [\"124M\", \"355M\", \"774M\", \"1558M\"]\n\n    model_dir = os.path.join(models_dir, model_size)\n    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n    if not tf_ckpt_path:  # download files if necessary\n        os.makedirs(model_dir, exist_ok=True)\n        download_gpt2_files(model_size, model_dir)\n        tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n\n    encoder = get_encoder(model_size, models_dir)\n    hparams = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, hparams)\n\n    return encoder, hparams, params","key":"i9mITwOuoE"},{"type":"outputs","id":"xArouRSHotEcSwLbQKeqU","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-02-18 12:27:24.663897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1739899644.722397 1472589 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1739899644.738680 1472589 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-02-18 12:27:24.870881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"},"children":[],"key":"LQtv83OqHi"}],"key":"ixRFbmdg54"}],"key":"dCCRB3nfne"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Cool. Having defined the necessary utilities, we will now define the prompt and generation functions:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tQUmylMKAh"}],"key":"PIhZS1ql4j"}],"key":"lgsB1O4bjA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\n\n\ndef gpt2(inputs, wte, wpe, blocks, ln_f, n_head):\n    pass  # TODO: implement this\n\n\ndef generate(inputs, params, n_head, n_tokens_to_generate):\n    for _ in tqdm(\n        range(n_tokens_to_generate), \"generating\"\n    ):  # auto-regressive decode loop\n        logits = gpt2(inputs, **params, n_head=n_head)  # model forward pass\n        next_id = np.argmax(logits[-1])  # greedy sampling\n        inputs.append(int(next_id))  # append prediction to input\n\n    return inputs[len(inputs) - n_tokens_to_generate :]  # only return generated ids\n\n\ndef prompt_gpt(\n    prompt: str,\n    n_tokens_to_generate: int = 40,\n    model_size: str = \"124M\",\n    models_dir: str = \"models\",\n):\n    # load encoder, hparams, and params from the released open-ai gpt-2 files\n    encoder, hparams, params = load_encoder_hparams_and_params(model_size, models_dir)\n    # map numpy arrays to jax arrays if jax is installed (in case saved params contain numpy arrays)\n    if np.__name__ == \"jax.numpy\":\n        import jax.tree_util as jtu\n\n        params = jtu.tree_map(\n            lambda x: np.array(x) if isinstance(x, np.ndarray) else x, params\n        )\n    # encode the input string using the BPE tokenizer\n    input_ids = encoder.encode(prompt)\n    # make sure we are not surpassing the max sequence length of our model\n    assert len(input_ids) + n_tokens_to_generate \u003c hparams[\"n_ctx\"]\n    # generate output ids\n    output_ids = generate(input_ids, params, hparams[\"n_head\"], n_tokens_to_generate)\n    # decode the ids back into a string\n    output_text = encoder.decode(output_ids)\n    return output_text","key":"Je3xDEa1Rb"},{"type":"outputs","id":"q9msgVBBZUcaxMcedwY-M","children":[],"key":"weAJjYldBk"}],"key":"Mp0z10ZcnK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Breaking down each of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Zhh1rsUBUG"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F7lCE32SMz"},{"type":"text","value":" sections:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oCVbu6iqwi"}],"key":"fxf0j2Tx48"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"vjYZ8cml1l"},{"type":"inlineCode","value":"gpt2","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"VcXYz4GDut"},{"type":"text","value":" function is the actual ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"MaKgbRUNvj"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ULiVT0NZXw"}],"key":"KwHaTjBPdD"},{"type":"text","value":" code we’ll be implementing. You’ll notice that the function signature includes some extra stuff in addition to ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"kIRVxixh9R"},{"type":"inlineCode","value":"inputs","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"kbJ18CPy4F"},{"type":"text","value":":","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"siuQikWpc9"}],"key":"waIkky5jU0"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"wte","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Nd46QAo1Pw"},{"type":"text","value":", ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fYVJFKeEHr"},{"type":"inlineCode","value":"wpe","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ZAx9EXw4B8"},{"type":"text","value":", ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"bN6xDoqWE2"},{"type":"inlineCode","value":"blocks","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nm3gcIBAYB"},{"type":"text","value":", and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dv9YDim7aa"},{"type":"inlineCode","value":"ln_f","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XCOqMt1NGM"},{"type":"text","value":" are the parameters of our model.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"doDaCHwBBQ"}],"key":"cTz8aNJ2aV"}],"key":"qrc6nMJz2O"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"n_head","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"nwC57gLii4"},{"type":"text","value":" is a hyperparameter that is needed during the forward pass.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"f1WrUeY2t5"}],"key":"sHOD6fzW3V"}],"key":"QFtBBEi2WH"}],"key":"JSqDmFI1rK"}],"key":"PEjPhTV2LA"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"glVwaN05Ef"},{"type":"inlineCode","value":"generate","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"OTNarQztJq"},{"type":"text","value":" function is the autoregressive decoding algorithm we saw earlier. We use greedy sampling for simplicity. ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"SnSA0Bn8Ne"},{"type":"inlineCode","value":"tqdm","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"u1iayO1q9v"},{"type":"text","value":" is a progress bar to help us visualize the decoding process as it generates tokens one at a time.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VYgrafpV4T"}],"key":"i664DK3cMS"}],"key":"y1LEUVUO5Z"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"yNewWGnE4r"},{"type":"inlineCode","value":"prompt_gpt","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"jQj6UaceDP"},{"type":"text","value":" function handles:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"leT4EF8pCY"}],"key":"zoG34aIlIC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Loading the tokenizer (","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"sAogmVHBFs"},{"type":"inlineCode","value":"encoder","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"w8HgbeiFnu"},{"type":"text","value":"), model weights (","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"nHi5LuAG4c"},{"type":"inlineCode","value":"params","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"V4ksWAX260"},{"type":"text","value":"), and hyperparameters (","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"yvl5hY78c3"},{"type":"inlineCode","value":"hparams","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"xtBXMM0Rf9"},{"type":"text","value":")","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"T6Ej2SsMun"}],"key":"Nool9aChb9"}],"key":"J17krzbzHy"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Encoding the input prompt into token IDs using the tokenizer","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"FXAledXvAx"}],"key":"GVTmhHMjKH"}],"key":"XuPjEjl9xV"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Calling the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"GXqLwgMCds"},{"type":"inlineCode","value":"generate","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"wBfNOZAlzX"},{"type":"text","value":" function","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cJDyJYjaED"}],"key":"pNARMKrvPK"}],"key":"E8H28oVKrM"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Decoding the output IDs into a string","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"N3CrEuNxeF"}],"key":"ZubpIoM8Rq"}],"key":"TCDLEKuVpS"}],"key":"qPoCK4xYHS"}],"key":"hQTVVI0bgp"}],"key":"OxZ85AoQS2"}],"key":"OXT34dG4KB"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Encoder","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LKpv4Hvc9Z"}],"identifier":"encoder","label":"Encoder","html_id":"encoder","implicit":true,"key":"HUJxBkjp9K"}],"key":"VeK3zY8UjK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Take a closer look at the following call:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VzqE6OvAqi"}],"key":"K5jm4560em"},{"type":"code","lang":"python","value":"encoder, hparams, params = load_encoder_hparams_and_params(\"124M\", \"models\")","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"u178D7V5YQ"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"This will download the necessary model and tokenizer files into ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"zZwYDcqbYS"},{"type":"inlineCode","value":"models/124M","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"eA7IUHYrJA"},{"type":"text","value":" and load ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"uQa6Cwm5OU"},{"type":"inlineCode","value":"encoder","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HjQ1aDfOOa"},{"type":"text","value":", ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"bFh6ZjFYWk"},{"type":"inlineCode","value":"hparams","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"dCM03RYDuN"},{"type":"text","value":", and ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TwVXiiuKjO"},{"type":"inlineCode","value":"params","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"nB55djUo4z"},{"type":"text","value":" into our code. Let’s give it a try (may take some minutes, depending on your connection speed):","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rgElJLgrw5"}],"key":"H3DbwRY7tk"}],"key":"ARuYxWflrW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"encoder, hparams, params = load_encoder_hparams_and_params(\"124M\", \"models\")","key":"H9TBLoSOju"},{"type":"outputs","id":"H0t3twmbaRDulHd23R1hy","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-02-18 12:27:28.665923: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n"},"children":[],"key":"DjyYXLYesZ"}],"key":"NomvEMOEYf"}],"key":"QGAFoH1jXX"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, let’s encode a prompt and see the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OVnqKtj0O5"},{"type":"inlineCode","value":"ids","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sl18811KIR"},{"type":"text","value":" it returns. Let’s then decode and verify that we get the same prompt back:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EqHZs7FpRU"}],"key":"PkGRn1FNyx"}],"key":"zDsNS6vcjb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"prompt = \"Not all heroes wear capes.\"\nids = encoder.encode(prompt)\nprint(ids)\nprompt_decoded = encoder.decode(ids)\nprint(prompt_decoded)\nassert prompt == prompt_decoded","key":"LNQ3pWVNJg"},{"type":"outputs","id":"dsXug_mA1NNvth2B4wA7n","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"[3673, 477, 10281, 5806, 1451, 274, 13]\nNot all heroes wear capes.\n"},"children":[],"key":"a3LPrknxkq"}],"key":"j5gRg1KetU"}],"key":"dLPxZMVQ86"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We do, indeed. Cool! Using the vocabulary of the tokenizer (stored in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"keSfoz9RXZ"},{"type":"inlineCode","value":"encoder.decoder","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"S4Re048XKD"},{"type":"text","value":"), we can take a peek at what the actual tokens look like:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ad69zOqpMc"}],"key":"qkT2fMwgEN"}],"key":"WlYjjz9oly"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"[encoder.decoder[i] for i in ids]","key":"mAEzw8poBE"},{"type":"outputs","id":"j-h_eWZqsxdqi4a_uuN8r","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"['Not', 'Ġall', 'Ġheroes', 'Ġwear', 'Ġcap', 'es', '.']","content_type":"text/plain"}}},"children":[],"key":"UDY6Na4FXo"}],"key":"pm0ZnF3kYu"}],"key":"ahRly4JLRn"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Interesting. Notice how sometimes our tokens are words (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BW6DjQM2G1"},{"type":"inlineCode","value":"Not","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yxX60XBzV4"},{"type":"text","value":"), sometimes they are words but with a space in front of them (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZNCqAjo2HA"},{"type":"inlineCode","value":"Ġall","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uHyGLwHvD4"},{"type":"text","value":", the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kKOLWOVxNA"},{"type":"link","url":"https://github.com/karpathy/minGPT/blob/37baab71b9abea1b76ab957409a1cc2fbfba8a26/mingpt/bpe.py#L22-L33","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Ġ represents a space","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cCWtq2qgxt"}],"urlSource":"https://github.com/karpathy/minGPT/blob/37baab71b9abea1b76ab957409a1cc2fbfba8a26/mingpt/bpe.py#L22-L33","data":{"kind":"file","org":"karpathy","repo":"minGPT","reference":"37baab71b9abea1b76ab957409a1cc2fbfba8a26","file":"mingpt/bpe.py","from":22,"to":33,"raw":"https://raw.githubusercontent.com/karpathy/minGPT/37baab71b9abea1b76ab957409a1cc2fbfba8a26/mingpt/bpe.py"},"internal":false,"protocol":"github","key":"nNqijuNmKF"},{"type":"text","value":"), sometimes there are part of a word (e.g. capes is split into ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r7YyiPeJ0z"},{"type":"inlineCode","value":"Ġcap","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vkMaWXMahO"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wts4oCjDjb"},{"type":"inlineCode","value":"es","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"voZjDer0B2"},{"type":"text","value":"), and sometimes they are punctuation (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hCZLFIhYdA"},{"type":"inlineCode","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Jzs8GnixJB"},{"type":"text","value":"). One nice thing about BPE is that it can encode any arbitrary string. If it encounters something that is not present in the vocabulary, it just breaks it down into substrings it does understand:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CTxn6RUj5X"}],"key":"ojn1MKRl7S"}],"key":"XE061E2LoC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"[encoder.decoder[i] for i in encoder.encode(\"zjqfl\")]","key":"TyfmXdcLqg"},{"type":"outputs","id":"137fLfwHpASPm-OZysXWC","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":10,"metadata":{},"data":{"text/plain":{"content":"['z', 'j', 'q', 'fl']","content_type":"text/plain"}}},"children":[],"key":"EVQiXXmdyk"}],"key":"rOLI7GsOmV"}],"key":"yHP0VQYyTC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can also check the size of the vocabulary:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Mel5jYbhpN"}],"key":"VDbMuvUbxY"}],"key":"ok3xEWVNqZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"len(encoder.decoder)","key":"x2neb4lWnI"},{"type":"outputs","id":"AF3F38wK2oVzEXaYmt0Xo","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":11,"metadata":{},"data":{"text/plain":{"content":"50257","content_type":"text/plain"}}},"children":[],"key":"rNCD4dkQJZ"}],"key":"KS10VOSQJ3"}],"key":"UtdKFC8aII"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The vocabulary, as well as the byte-pair merges which determines how strings are broken down, is obtained by ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"znQfyLNqLb"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kyTapssp9B"}],"key":"s3mv38GHN7"},{"type":"text","value":" the tokenizer. When we load the tokenizer, we’re loading the already trained vocab and byte-pair merges from some files, which were downloaded alongside the model files when we ran ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MSGmyyJOWU"},{"type":"inlineCode","value":"load_encoder_hparams_and_params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"an8vs6iCO3"},{"type":"text","value":". See the files ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qy2rSHUYN8"},{"type":"inlineCode","value":"models/124M/encoder.json","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m9T1LnV7YF"},{"type":"text","value":" (the vocabulary) and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J0lRnO3DZ1"},{"type":"inlineCode","value":"models/124M/vocab.bpe","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Cx7TCb8jFR"},{"type":"text","value":" (byte-pair merges).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BLZTBnKOiJ"}],"key":"ofswyzjmJN"}],"key":"tm020GrP53"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Hyperparameters","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xi5ZdcCa2r"}],"identifier":"hyperparameters","label":"Hyperparameters","html_id":"hyperparameters","implicit":true,"key":"xV32ernz30"}],"key":"WNtHfDfrO9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"hparams","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bn45nHtBkS"},{"type":"text","value":" is a dictionary that contains the hyper-parameters of our model:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IAIkFS41Qf"}],"key":"FlDA7HLh8G"}],"key":"QKy9HBk7A0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"hparams","key":"b8ISPuS4ge"},{"type":"outputs","id":"UmS4NrTobuY5G1oqxkHDg","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":12,"metadata":{},"data":{"text/plain":{"content":"{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}","content_type":"text/plain"}}},"children":[],"key":"iEERWAqJq3"}],"key":"jRfqtdBbiA"}],"key":"HGRAVb7fWZ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Here’s what each key refers to:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Lqa5j1ukLV"}],"key":"FmjXODugH0"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"n_vocab","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"RtP0iz9sDD"},{"type":"text","value":": number of tokens in our vocabulary","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"fLld9kkFrj"}],"key":"nJhq0ff1Yv"}],"key":"cW9xHL3DEI"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"n_ctx","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TLnZF40N82"},{"type":"text","value":": maximum possible sequence length of the input","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KXjYUGnl7i"}],"key":"NEqEJSzNkn"}],"key":"zqEwZoRlVj"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"n_embd","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"lQ21q0ypJj"},{"type":"text","value":": embedding dimension (determines the “width” of the network)","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"jCiL53OrFK"}],"key":"t29W48N5iN"}],"key":"EmglBxqFt9"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"n_head","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"yAgvj3PB6y"},{"type":"text","value":": number of attention heads (n_embd must be divisible by n_head)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nFEdSZHVbs"}],"key":"ZNUpRsbCLP"}],"key":"zc9Ndn8v8p"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"n_layer","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"xeDV0ws91m"},{"type":"text","value":": number of layers (determines the “depth” of the network)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"GcoCYNKKBz"}],"key":"XUS0odgQNM"}],"key":"x9zxM1rSnx"}],"key":"by1Fae26wV"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"We’ll use these symbols in our code’s comments to show the underlying shape of things. We’ll also use ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Q51GpwIrxR"},{"type":"inlineCode","value":"n_seq","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"HnlHhsunH9"},{"type":"text","value":" to denote the length of our input sequence (i.e. ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"oEPyZVDsvQ"},{"type":"inlineCode","value":"n_seq = len(inputs)","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"i8rd6mXmwX"},{"type":"text","value":").","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ZrHSkKK3pB"}],"key":"eM79qftJeq"}],"key":"uArdlUFNa1"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Parameters","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yAFZBEnVPm"}],"identifier":"parameters","label":"Parameters","html_id":"parameters","implicit":true,"key":"wS9L6tqGEL"}],"key":"kbWgAAzvYR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HKrN2Txf8R"},{"type":"text","value":" is a nested json dictionary that hold the trained weights of our model. The leaf nodes of the json are NumPy arrays. If we print ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"z7qwp5xWpU"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hqNY9llWMw"},{"type":"text","value":", replacing the arrays with their shapes, we get:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"j0QZKOGUKU"}],"key":"cAcwfZnn75"}],"key":"JZc8daiZte"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\n\n\ndef shape_tree(d):\n    if isinstance(d, np.ndarray):\n        return list(d.shape)\n    elif isinstance(d, list):\n        return [shape_tree(v) for v in d]\n    elif isinstance(d, dict):\n        return {k: shape_tree(v) for k, v in d.items()}\n    else:\n        ValueError(\"uh oh\")\n\n\nshape_tree(params)","key":"KghCf00aya"},{"type":"outputs","id":"7zCS_egkZ_V5oAGYFNCni","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":13,"metadata":{},"data":{"text/plain":{"content":"{'blocks': [{'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}},\n  {'attn': {'c_attn': {'b': [2304], 'w': [768, 2304]},\n    'c_proj': {'b': [768], 'w': [768, 768]}},\n   'ln_1': {'b': [768], 'g': [768]},\n   'ln_2': {'b': [768], 'g': [768]},\n   'mlp': {'c_fc': {'b': [3072], 'w': [768, 3072]},\n    'c_proj': {'b': [768], 'w': [3072, 768]}}}],\n 'ln_f': {'b': [768], 'g': [768]},\n 'wpe': [1024, 768],\n 'wte': [50257, 768]}","content_type":"text/plain"}}},"children":[],"key":"PCQvYmPZb1"}],"key":"yWqmNOLXbn"}],"key":"IOR3rxWAJp"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"where each dictionary inside the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wjKECMaVUo"},{"type":"inlineCode","value":"'blocks'","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gx9PEixa9a"},{"type":"text","value":" list contains the weights information for each layer (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jp3tLZa0a1"},{"type":"inlineCode","value":"n_layers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G7w3q3765V"},{"type":"text","value":" total). These weights are loaded from the original OpenAI tensorflow checkpoint:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u0enBalSpP"}],"key":"nf2pHaxDeR"}],"key":"vT76NMdAit"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import tensorflow as tf\n\ntf_ckpt_path = tf.train.latest_checkpoint(\"models/124M\")\nfor name, _ in tf.train.list_variables(tf_ckpt_path):\n    arr = tf.train.load_variable(tf_ckpt_path, name).squeeze()\n    print(f\"{name}: {arr.shape}\")","key":"EKRAEn9n4j"},{"type":"outputs","id":"L73r1sPdszehmGYfnTxDp","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"model/h0/attn/c_attn/b: (2304,)\nmodel/h0/attn/c_attn/w: (768, 2304)\nmodel/h0/attn/c_proj/b: (768,)\nmodel/h0/attn/c_proj/w: (768, 768)\nmodel/h0/ln_1/b: (768,)\nmodel/h0/ln_1/g: (768,)\nmodel/h0/ln_2/b: (768,)\nmodel/h0/ln_2/g: (768,)\nmodel/h0/mlp/c_fc/b: (3072,)\nmodel/h0/mlp/c_fc/w: (768, 3072)\nmodel/h0/mlp/c_proj/b: (768,)\nmodel/h0/mlp/c_proj/w: (3072, 768)\nmodel/h1/attn/c_attn/b: (2304,)\nmodel/h1/attn/c_attn/w: (768, 2304)\nmodel/h1/attn/c_proj/b: (768,)\nmodel/h1/attn/c_proj/w: (768, 768)\nmodel/h1/ln_1/b: (768,)\nmodel/h1/ln_1/g: (768,)\nmodel/h1/ln_2/b: (768,)\nmodel/h1/ln_2/g: (768,)\nmodel/h1/mlp/c_fc/b: (3072,)\nmodel/h1/mlp/c_fc/w: (768, 3072)\nmodel/h1/mlp/c_proj/b: (768,)\nmodel/h1/mlp/c_proj/w: (3072, 768)\nmodel/h10/attn/c_attn/b: (2304,)\nmodel/h10/attn/c_attn/w: (768, 2304)\nmodel/h10/attn/c_proj/b: (768,)\nmodel/h10/attn/c_proj/w: (768, 768)\nmodel/h10/ln_1/b: (768,)\nmodel/h10/ln_1/g: (768,)\nmodel/h10/ln_2/b: (768,)\nmodel/h10/ln_2/g: (768,)\nmodel/h10/mlp/c_fc/b: (3072,)\nmodel/h10/mlp/c_fc/w: (768, 3072)\nmodel/h10/mlp/c_proj/b: (768,)\nmodel/h10/mlp/c_proj/w: (3072, 768)\nmodel/h11/attn/c_attn/b: (2304,)\nmodel/h11/attn/c_attn/w: (768, 2304)\nmodel/h11/attn/c_proj/b: (768,)\nmodel/h11/attn/c_proj/w: (768, 768)\nmodel/h11/ln_1/b: (768,)\nmodel/h11/ln_1/g: (768,)\nmodel/h11/ln_2/b: (768,)\nmodel/h11/ln_2/g: (768,)\nmodel/h11/mlp/c_fc/b: (3072,)\nmodel/h11/mlp/c_fc/w: (768, 3072)\nmodel/h11/mlp/c_proj/b: (768,)\nmodel/h11/mlp/c_proj/w: (3072, 768)\nmodel/h2/attn/c_attn/b: (2304,)\nmodel/h2/attn/c_attn/w: (768, 2304)\nmodel/h2/attn/c_proj/b: (768,)\nmodel/h2/attn/c_proj/w: (768, 768)\nmodel/h2/ln_1/b: (768,)\nmodel/h2/ln_1/g: (768,)\nmodel/h2/ln_2/b: (768,)\nmodel/h2/ln_2/g: (768,)\nmodel/h2/mlp/c_fc/b: (3072,)\nmodel/h2/mlp/c_fc/w: (768, 3072)\nmodel/h2/mlp/c_proj/b: (768,)\nmodel/h2/mlp/c_proj/w: (3072, 768)\nmodel/h3/attn/c_attn/b: (2304,)\nmodel/h3/attn/c_attn/w: (768, 2304)\nmodel/h3/attn/c_proj/b: (768,)\nmodel/h3/attn/c_proj/w: (768, 768)\nmodel/h3/ln_1/b: (768,)\nmodel/h3/ln_1/g: (768,)\nmodel/h3/ln_2/b: (768,)\nmodel/h3/ln_2/g: (768,)\nmodel/h3/mlp/c_fc/b: (3072,)\nmodel/h3/mlp/c_fc/w: (768, 3072)\nmodel/h3/mlp/c_proj/b: (768,)\nmodel/h3/mlp/c_proj/w: (3072, 768)\nmodel/h4/attn/c_attn/b: (2304,)\nmodel/h4/attn/c_attn/w: (768, 2304)\nmodel/h4/attn/c_proj/b: (768,)\nmodel/h4/attn/c_proj/w: (768, 768)\nmodel/h4/ln_1/b: (768,)\nmodel/h4/ln_1/g: (768,)\nmodel/h4/ln_2/b: (768,)\nmodel/h4/ln_2/g: (768,)\nmodel/h4/mlp/c_fc/b: (3072,)\nmodel/h4/mlp/c_fc/w: (768, 3072)\nmodel/h4/mlp/c_proj/b: (768,)\nmodel/h4/mlp/c_proj/w: (3072, 768)\nmodel/h5/attn/c_attn/b: (2304,)\nmodel/h5/attn/c_attn/w: (768, 2304)\nmodel/h5/attn/c_proj/b: (768,)\nmodel/h5/attn/c_proj/w: (768, 768)\nmodel/h5/ln_1/b: (768,)\nmodel/h5/ln_1/g: (768,)\nmodel/h5/ln_2/b: (768,)\nmodel/h5/ln_2/g: (768,)\nmodel/h5/mlp/c_fc/b: (3072,)\nmodel/h5/mlp/c_fc/w: (768, 3072)\nmodel/h5/mlp/c_proj/b: (768,)\nmodel/h5/mlp/c_proj/w: (3072, 768)\nmodel/h6/attn/c_attn/b: (2304,)\nmodel/h6/attn/c_attn/w: (768, 2304)\nmodel/h6/attn/c_proj/b: (768,)\nmodel/h6/attn/c_proj/w: (768, 768)\nmodel/h6/ln_1/b: (768,)\nmodel/h6/ln_1/g: (768,)\nmodel/h6/ln_2/b: (768,)\nmodel/h6/ln_2/g: (768,)\nmodel/h6/mlp/c_fc/b: (3072,)\nmodel/h6/mlp/c_fc/w: (768, 3072)\nmodel/h6/mlp/c_proj/b: (768,)\nmodel/h6/mlp/c_proj/w: (3072, 768)\nmodel/h7/attn/c_attn/b: (2304,)\nmodel/h7/attn/c_attn/w: (768, 2304)\nmodel/h7/attn/c_proj/b: (768,)\nmodel/h7/attn/c_proj/w: (768, 768)\nmodel/h7/ln_1/b: (768,)\nmodel/h7/ln_1/g: (768,)\nmodel/h7/ln_2/b: (768,)\nmodel/h7/ln_2/g: (768,)\nmodel/h7/mlp/c_fc/b: (3072,)\nmodel/h7/mlp/c_fc/w: (768, 3072)\nmodel/h7/mlp/c_proj/b: (768,)\nmodel/h7/mlp/c_proj/w: (3072, 768)\nmodel/h8/attn/c_attn/b: (2304,)\nmodel/h8/attn/c_attn/w: (768, 2304)\nmodel/h8/attn/c_proj/b: (768,)\nmodel/h8/attn/c_proj/w: (768, 768)\nmodel/h8/ln_1/b: (768,)\nmodel/h8/ln_1/g: (768,)\nmodel/h8/ln_2/b: (768,)\nmodel/h8/ln_2/g: (768,)\nmodel/h8/mlp/c_fc/b: (3072,)\nmodel/h8/mlp/c_fc/w: (768, 3072)\nmodel/h8/mlp/c_proj/b: (768,)\nmodel/h8/mlp/c_proj/w: (3072, 768)\nmodel/h9/attn/c_attn/b: (2304,)\nmodel/h9/attn/c_attn/w: (768, 2304)\nmodel/h9/attn/c_proj/b: (768,)\nmodel/h9/attn/c_proj/w: (768, 768)\nmodel/h9/ln_1/b: (768,)\nmodel/h9/ln_1/g: (768,)\nmodel/h9/ln_2/b: (768,)\nmodel/h9/ln_2/g: (768,)\nmodel/h9/mlp/c_fc/b: (3072,)\nmodel/h9/mlp/c_fc/w: (768, 3072)\nmodel/h9/mlp/c_proj/b: (768,)\nmodel/h9/mlp/c_proj/w: (3072, 768)\nmodel/ln_f/b: (768,)\nmodel/ln_f/g: (768,)\nmodel/wpe: (1024, 768)\nmodel/wte: (50257, 768)\n"},"children":[],"key":"nyYEXAYpoB"},{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-02-18 12:27:29.143545: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n"},"children":[],"key":"jJK12Bj1RW"}],"key":"cOffGKudWs"}],"key":"yQCTneGUSv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QpKl9VryVh"},{"type":"inlineCode","value":"load_gpt2_params_from_tf_ckpt","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VV0tSrnNOB"},{"type":"text","value":" function converts the above tensorflow variables into our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NYoWtVw6NO"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KeP3Ztpw3R"},{"type":"text","value":" dictionary. For reference, here’s the shapes of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bDwm4SwX50"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lDgL584Zzi"},{"type":"text","value":" but with the numbers replaced by the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yiZflFDquP"},{"type":"inlineCode","value":"hparams","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"p7a5iUB3Up"},{"type":"text","value":" they represent:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KH26aHYS8N"}],"key":"tpA1XeduvG"}],"key":"zZSlFizTkV"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"{\n    \"wpe\": [n_ctx, n_embd],\n    \"wte\": [n_vocab, n_embd],\n    \"ln_f\": {\"b\": [n_embd], \"g\": [n_embd]},\n    \"blocks\": [\n        {\n            \"attn\": {\n                \"c_attn\": {\"b\": [3*n_embd], \"w\": [n_embd, 3*n_embd]},\n                \"c_proj\": {\"b\": [n_embd], \"w\": [n_embd, n_embd]},\n            },\n            \"ln_1\": {\"b\": [n_embd], \"g\": [n_embd]},\n            \"ln_2\": {\"b\": [n_embd], \"g\": [n_embd]},\n            \"mlp\": {\n                \"c_fc\": {\"b\": [4*n_embd], \"w\": [n_embd, 4*n_embd]},\n                \"c_proj\": {\"b\": [n_embd], \"w\": [4*n_embd, n_embd]},\n            },\n        },\n        ... # repeat for n_layers\n    ]\n}","position":{"start":{"line":1,"column":1},"end":{"line":22,"column":1}},"key":"LU801AREQ3"}],"key":"OEI7n02rTH"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"You’ll probably want to come back to reference this dictionary to check the shape of the weights as we implement our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DdmaFfOh8F"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DUrKYGwsZN"}],"key":"DMaXGMAOP2"},{"type":"text","value":". We’ll match the variable names in our code with the keys of this dictionary for consistency.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zreMIjaHAw"}],"key":"EGMNY9NOhN"}],"key":"q4suYhi8bH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Basic Layers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Te1LExA7D1"}],"identifier":"basic-layers","label":"Basic Layers","html_id":"basic-layers","implicit":true,"key":"CmdKbHjhjA"}],"key":"j8Eyc0HF6e"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Last thing before we get into the actual ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u8y9foOvZo"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"V5H3VKXt4B"}],"key":"VYY990tcNN"},{"type":"text","value":" architecture itself, let’s implement some of the more basic ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Uo2uzaoLkE"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IVMvHUcmXZ"}],"key":"KiZ2NKuI1y"},{"type":"text","value":" layers that are non-specific to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AMlKcILran"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nxxNbzZ9O5"}],"key":"YCzRG0ZlbK"},{"type":"text","value":"s.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iEohkRlCQW"}],"key":"M8elsBCqxM"}],"key":"SCuDnmv95D"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GELU","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yRzS45hAXS"}],"identifier":"gelu","label":"GELU","html_id":"gelu","implicit":true,"key":"NCxQZrdOBn"}],"key":"GSauKBxgDm"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The non-linearity (activation function) of choice for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U41MqlVXea"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LH9mbMfK6S"}],"key":"MKb83b0meU"},{"type":"text","value":"-2 is GELU (Gaussian Error Linear Units), an alternative for ReLU:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TWTbVMNNyd"}],"key":"DCs0rIjmwu"}],"key":"yyRPlvMdSU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"fig_1_from_gelu_paper.png\"))","key":"seTJEZ92Vr"},{"type":"outputs","id":"qIRWi90DNdpksrVyyMpFO","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"bf801b993f69576d9a242672d2ba329c","path":"/build/bf801b993f69576d9a242672d2ba329c.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"yo2Qwhrvp8"}],"key":"QZe1lgydP1"}],"key":"O5g9RBOibL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"It is approximated by the following function:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Z4wRqlH2PH"}],"key":"YebPPuLKu9"}],"key":"CyuWWHCgIZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def gelu(x):\n    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))","key":"FJ6A4rdfQn"},{"type":"outputs","id":"623Ewu_RYKkI_IEVZZa53","children":[],"key":"iiTyK1MEqb"}],"key":"Zu8WFYVsyD"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Like ReLU, GELU operates element-wise on the input:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UB8PiQIykh"}],"key":"Jo27Il2H7L"}],"key":"idubH7qdSL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"gelu(np.array([[1, 2], [-2, 0.5]]))","key":"YzPFliTCJf"},{"type":"outputs","id":"kkQIFHXrLEzSFumTehJ6F","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":17,"metadata":{},"data":{"text/plain":{"content":"array([[ 0.84119199,  1.95459769],\n       [-0.04540231,  0.34571401]])","content_type":"text/plain"}}},"children":[],"key":"TBMJYsZkIU"}],"key":"GGnBbjSpqX"}],"key":"Tk3HGJGoeE"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Softmax","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Gwz78g9wbx"}],"identifier":"softmax","label":"Softmax","html_id":"softmax","implicit":true,"key":"sLrGr1PTm8"}],"key":"Qs2CEzH6Lh"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Good ole ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TUBKJAYXz7"},{"type":"link","url":"https://en.wikipedia.org/wiki/Softmax_function","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"softmax","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"c9uFTnQ2S1"}],"urlSource":"https://en.wikipedia.org/wiki/Softmax_function","data":{"page":"Softmax_function","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"T05ikwLEPP"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZLRdhJCOTo"}],"key":"cuurAoawqf"}],"key":"iq6Yk9RStg"},{"type":"block","kind":"notebook-content","children":[{"type":"math","value":"\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmfrac\u003e\u003cmsup\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003cmrow\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/munder\u003e\u003cmsup\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003c/mfrac\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.4632em;vertical-align:-1.1218em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.3414em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mop\"\u003e\u003cspan class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\"\u003e∑\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.162em;\"\u003e\u003cspan style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.4358em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.6065em;\"\u003e\u003cspan style=\"top:-3.0051em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3281em;\"\u003e\u003cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2819em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.6644em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3281em;\"\u003e\u003cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.143em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.1218em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"1","key":"mr7RjoMvrS"}],"key":"HiXLvPxtlA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def softmax(x):\n    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)","key":"xOyo9LBWaO"},{"type":"outputs","id":"RS4KbTLNEwLAp-Jdyq1uE","children":[],"key":"JxJBEMWcio"}],"key":"FeWaxoMbgR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We use the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iK27w631HL"},{"type":"link","url":"https://jaykmody.com/blog/stable-softmax/","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"max(x) trick for numerical stability","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fLRezzoVus"}],"urlSource":"https://jaykmody.com/blog/stable-softmax/","key":"afwi8NfYDz"},{"type":"text","value":". Softmax is used to a convert set of real numbers (between ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"j8uOk1FEDe"},{"type":"inlineMath","value":"-\\infty","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∞\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e-\\infty\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e∞\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"FfSVArqwkJ"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E0FSRRZMZi"},{"type":"inlineMath","value":"\\infty","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi mathvariant=\"normal\"\u003e∞\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\infty\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∞\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"NUk9Pgr1Vf"},{"type":"text","value":") to probabilities (between ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IXZSKp2BJ6"},{"type":"text","value":"0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pGLaTmPVdS"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MBWBVMmT4R"},{"type":"text","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FQo46RBipW"},{"type":"text","value":", with the numbers all summing to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cP4lZsp6Xg"},{"type":"text","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EIss6HOP5d"},{"type":"text","value":"). We apply ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZDJsOkl8W8"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pnqcSfcOTR"},{"type":"text","value":" over the last axis of the input.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l0cOsCSeRE"}],"key":"JBkynPYPPI"}],"key":"skyYwut1PP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"x = softmax(np.array([[2, 100], [-5, 0]]))\nx","key":"inNRpSFj0P"},{"type":"outputs","id":"Cd_DDa_Jw2CfeWRugv6n-","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":19,"metadata":{},"data":{"text/plain":{"content":"array([[2.74878501e-43, 1.00000000e+00],\n       [6.69285092e-03, 9.93307149e-01]])","content_type":"text/plain"}}},"children":[],"key":"ErdJaHV3Gp"}],"key":"EXk1RXwIbE"}],"key":"Algc1jWEsc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"x.sum(axis=-1)","key":"NtKgbg6r2L"},{"type":"outputs","id":"VoT1GQ7TevpFem1HgkqHP","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":20,"metadata":{},"data":{"text/plain":{"content":"array([1., 1.])","content_type":"text/plain"}}},"children":[],"key":"iVPyOUVGSN"}],"key":"LvwVzlH6sd"}],"key":"PnnqSCRZbA"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Layer Normalization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LtdlhctPrQ"}],"identifier":"layer-normalization","label":"Layer Normalization","html_id":"layer-normalization","implicit":true,"key":"Fv4L6C4WuL"}],"key":"R5t4UpZYfI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/pdf/1607.06450.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Layer normalization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E2Oq5X1NCt"}],"urlSource":"https://arxiv.org/pdf/1607.06450.pdf","key":"UCkXqBQDBn"},{"type":"text","value":" standardizes values to have a mean of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UGvYI9lMLN"},{"type":"inlineCode","value":"0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BP7K21mb9k"},{"type":"text","value":" and a variance of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dThPKSFguu"},{"type":"inlineCode","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fFuTWnaw2B"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oXBDDDtuEo"}],"key":"vBmQS2xcIr"},{"type":"math","value":"\\text{LayerNorm}(x) = \\gamma\\cdot\\frac{x - \\mu}{\\sigma} + \\beta","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eLayerNorm\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmi\u003eγ\u003c/mi\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmfrac\u003e\u003cmrow\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmi\u003eμ\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eσ\u003c/mi\u003e\u003c/mfrac\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmi\u003eβ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{LayerNorm}(x) = \\gamma\\cdot\\frac{x - \\mu}{\\sigma} + \\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eLayerNorm\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eγ\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.9463em;vertical-align:-0.686em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2603em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eμ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.686em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e+\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eβ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"2","key":"H0zh15DXSa"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"eKjhMVuc9F"},{"type":"inlineMath","value":"\\mu","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eμ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\mu\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eμ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"pEKBWPY4bp"},{"type":"text","value":" is the mean of ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Hecq63kXjT"},{"type":"inlineMath","value":"x","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ex\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ex\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"JhFoTPg9fa"},{"type":"text","value":", ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"yQMJHXyYdd"},{"type":"inlineMath","value":"\\sigma^2","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsup\u003e\u003cmi\u003eσ\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sigma^2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8141em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8141em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"kJMv2outxr"},{"type":"text","value":" is the variance of ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"E0cmom4aN2"},{"type":"inlineMath","value":"x","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ex\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ex\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"sBjKAo3vlp"},{"type":"text","value":", and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"x2hJAkT5ug"},{"type":"inlineMath","value":"\\gamma","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eγ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\gamma\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eγ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UAVt0FcOte"},{"type":"text","value":" and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"aXMSWQec3P"},{"type":"inlineMath","value":"\\beta","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eβ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eβ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Rp9wmCkhxe"},{"type":"text","value":" are learnable parameters.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"g26MVG90uj"}],"key":"KSWJemzcBZ"}],"key":"mLpL7efPbt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def layer_norm(x, g, b, eps: float = 1e-5):\n    mean = np.mean(x, axis=-1, keepdims=True)\n    variance = np.var(x, axis=-1, keepdims=True)\n    x = (x - mean) / np.sqrt(\n        variance + eps\n    )  # normalize x to have mean=0 and var=1 over last axis\n    return g * x + b  # scale and offset with gamma/beta params","key":"iH3RlKmqpB"},{"type":"outputs","id":"7QQIYH84rLwqPyV4VnyEW","children":[],"key":"NnZCDCYHwH"}],"key":"mYtZESF8we"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Layer normalization ensures that the inputs for each layer are always within a consistent range, which is supposed to speed up and stabilize the training process. Like ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tM9jbIuCaW"},{"type":"link","url":"https://arxiv.org/pdf/1502.03167.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qSfnj6RPOp"}],"key":"i830cGGHZd"}],"urlSource":"https://arxiv.org/pdf/1502.03167.pdf","key":"bNu8Vu2mvQ"},{"type":"text","value":", the normalized output is then scaled and offset with two learnable vectors ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qlz5RasamA"},{"type":"inlineMath","value":"\\gamma","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eγ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\gamma\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\"\u003eγ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ZmRNhsn0Vm"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ErAVM97uG5"},{"type":"inlineMath","value":"\\beta","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eβ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\beta\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05278em;\"\u003eβ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"YkoLOJCigw"},{"type":"text","value":". The small epsilon term in the denominator (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YlkGETQcGC"},{"type":"inlineCode","value":"eps","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PjXEpj2YCV"},{"type":"text","value":") is used to avoid a division by zero error. Layer norm is used instead of batch norm in the transformer for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZTXmzsne6C"},{"type":"link","url":"https://stats.stackexchange.com/questions/474440/why-do-transformers-use-layer-norm-instead-of-batch-norm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"various reasons","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f9WNWD5cF2"}],"urlSource":"https://stats.stackexchange.com/questions/474440/why-do-transformers-use-layer-norm-instead-of-batch-norm","key":"VwK3RU8UEg"},{"type":"text","value":". The differences between various normalization techniques is outlined in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MWShpYDygG"},{"type":"link","url":"https://tungmphung.com/deep-learning-normalization-methods/","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"this excellent blog post","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sJWWQpexAK"}],"urlSource":"https://tungmphung.com/deep-learning-normalization-methods/","key":"EX9pw60eHh"},{"type":"text","value":". We apply layer normalization over the last axis of the input:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yetV1xhpG8"}],"key":"WIt2SaRJ2R"}],"key":"Wov8ywV6Mh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"x = np.array([[2, 2, 3], [-5, 0, 1]])\nx = layer_norm(x, g=np.ones(x.shape[-1]), b=np.zeros(x.shape[-1]))\nprint(x)\nprint(\"var:\", x.var(axis=-1))  # yields floating point shenanigans\nprint(\"mean:\", x.mean(axis=-1))  # same here","key":"aQPFQ31wKl"},{"type":"outputs","id":"6AHkZTNT48Yf2G7wXNI6Q","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"[[-0.70709087 -0.70709087  1.41418174]\n [-1.39700038  0.50800014  0.88900024]]\nvar: [0.999955   0.99999855]\nmean: [-2.96059473e-16 -3.70074342e-17]\n"},"children":[],"key":"x5ZtG2f0oF"}],"key":"s6viKvyKgE"}],"key":"o3vUbU9A6w"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pXwsjJCDJP"}],"identifier":"linear","label":"Linear","html_id":"linear","implicit":true,"key":"JIS1cebhw8"}],"key":"xtt4i3h7SM"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Your standard matrix multiplication + bias:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Yv1E8QkbnO"}],"key":"tgnCgBptiD"}],"key":"NdHHJyiDBM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def linear(x, w, b):  # [m, in], [in, out], [out] -\u003e [m, out]\n    return x @ w + b","key":"BwLAr53Nd6"},{"type":"outputs","id":"7mW6n148IoE_Q7-mJFMZs","children":[],"key":"Sx7KjNUVLe"}],"key":"EHVSKdhPFS"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Linear layers are often referred to as projections (since they are projecting from one vector space to another vector space):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BiyWkgt8bI"}],"key":"W3CMlZSEjA"}],"key":"F97kikw9hP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"x = np.random.normal(size=(64, 784))  # input dim = 784, batch/sequence dim = 64\nw = np.random.normal(size=(784, 10))  # output dim = 10\nb = np.random.normal(size=(10,))\nprint(x.shape)  # shape before linear projection\nprint(linear(x, w, b).shape)  # shape after linear projection","key":"nwsfhuRSWW"},{"type":"outputs","id":"U0HmQo3MPu1Dd9JSrSBsW","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"(64, 784)\n(64, 10)\n"},"children":[],"key":"PxYFipY8Zu"}],"key":"D5XHGqCRx0"}],"key":"mgAIj2FxaH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"B72zl6ToZi"}],"key":"vPtFvBFEWh"},{"type":"text","value":" Architecture","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rsCfvjLvnv"}],"identifier":"gpt-architecture","label":"GPT Architecture","html_id":"gpt-architecture","implicit":true,"key":"MNhJAtufDe"}],"key":"GXH4cbF8et"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Nw5WV06goZ"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fg8J1Ok8kd"}],"key":"elP8UAwcfU"},{"type":"text","value":" architecture follows that of the transformer:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WqXqIQa0B1"}],"key":"lS9WGryALk"}],"key":"UTMACc3y2b"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"fig_1_from_attention_is_all_you_need_paper.png\"))","key":"gClGafVP1h"},{"type":"outputs","id":"Cs7KLlIE4tKiPy6B_yRwf","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"95a2359853165c9eef927e4a752c43f9","path":"/build/95a2359853165c9eef927e4a752c43f9.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"tNXAHH23LD"}],"key":"dgyvypR5OG"}],"key":"snvnQgZYdT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"But uses only the decoder stack (the right part of the diagram):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kaXWntMcAs"}],"key":"mxpaFAM8Va"}],"key":"WKZZIbWdp2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"transformer_decoder_stack.png\"))","key":"NSg9YOfPOE"},{"type":"outputs","id":"YWyMY4OiYLvthDCC7XTCe","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"1b391e61efa306561ab221327072a6f1","path":"/build/1b391e61efa306561ab221327072a6f1.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"P2pN5oc7WA"}],"key":"dniOlhAMKi"}],"key":"xg7pdoLVTf"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note, the middle “cross-attention” layer is also removed since we got rid of the encoder. At a high level, the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f8T1ZJN7CL"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZVjyQsbfmy"}],"key":"wlSWIwhNdU"},{"type":"text","value":" architecture has three sections:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AroICULyi3"}],"key":"gGrmXDjD14"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Text + positional embeddings","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"uEWwWNf0wz"}],"key":"Nx4XNNJUoJ"}],"key":"SD7mwUJwKd"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"A transformer decoder stack","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"goLNwgc4vi"}],"key":"y7O0yS56Lj"}],"key":"fOmGD1qvS1"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"A projection to vocab step","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Sbj7nCfxdN"}],"key":"R4gIuFR1ut"}],"key":"C6OFGexixw"}],"key":"muNUd6CGcG"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"In code, it looks like this:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"dab77l5XB0"}],"key":"HdVPwlpV5E"}],"key":"PZ1nM5KHuY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):  # [n_seq] -\u003e [n_seq, n_vocab]\n    # token + positional embeddings\n    x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -\u003e [n_seq, n_embd]\n\n    # forward pass through n_layer transformer blocks\n    for block in blocks:\n        x = transformer_block(\n            x, **block, n_head=n_head\n        )  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n\n    # projection to vocab\n    x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    return x @ wte.T  # [n_seq, n_embd] -\u003e [n_seq, n_vocab]","key":"yCY3AQShmy"},{"type":"outputs","id":"RyKaeR5frl3nhgnO3cVzg","children":[],"key":"YpR0gN28zA"}],"key":"oG9iP8jR8T"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s break down each of these three sections into more detail.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YPGh1xGrlB"}],"key":"vU6ZAXnYDG"}],"key":"piyKbCtaS2"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Embeddings","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u8TtrEIHy8"}],"identifier":"embeddings","label":"Embeddings","html_id":"embeddings","implicit":true,"key":"xjvOqMnIxV"}],"key":"hDq8WWcw8y"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Token Embeddings","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r6UOx1mI4f"}],"identifier":"token-embeddings","label":"Token Embeddings","html_id":"token-embeddings","implicit":true,"key":"ROoj1I5wLE"}],"key":"Dvzepm8QL2"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Token IDs by themselves are not very good representations for a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ILW9blZWNU"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oFFItI68up"}],"key":"jUQGYBjq8y"},{"type":"text","value":". For one, the relative magnitudes of the token IDs falsely communicate information (for example, if ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bcGDhFv0Wq"},{"type":"inlineCode","value":"Apple = 5","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wAQ9JxixWS"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JuVHbHOr4y"},{"type":"inlineCode","value":"Table = 10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YJZYLVmHQV"},{"type":"text","value":" in our vocab, then we are implying that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XHjcWDtTDZ"},{"type":"inlineCode","value":"2 * Apple = Table","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VPhwd6uRI0"},{"type":"text","value":"). Secondly, a single number is not a lot of dimensionality for a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tT2bsrDbIk"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DJv1GE2j9A"}],"key":"WIs5EPjJsS"},{"type":"text","value":" to work with. To address these limitations, we’ll take advantage of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LHw5FfoKWL"},{"type":"link","url":"https://jaykmody.com/blog/attention-intuition/#word-vectors-and-similarity","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"word vectors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iF2yQ9hyIx"}],"urlSource":"https://jaykmody.com/blog/attention-intuition/#word-vectors-and-similarity","key":"yPUVqpWixa"},{"type":"text","value":", specifically via a learned embedding matrix:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Fg9cZoohf9"}],"key":"bQBhGjPiZo"},{"type":"code","lang":"python","value":"wte[inputs]  # [n_seq] -\u003e [n_seq, n_embd]","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"FGzY3VDB5A"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Recall, ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"qXKYRTCFtE"},{"type":"inlineCode","value":"wte","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"b7xXsFGfWG"},{"type":"text","value":" is a ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"QJsZSUz7bS"},{"type":"inlineCode","value":"[n_vocab, n_embd]","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"oYxvKe8pVK"},{"type":"text","value":" matrix. It acts as a lookup table, where the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"uJVRo91CFa"},{"type":"inlineMath","value":"ith","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"YZcLikNT9F"},{"type":"text","value":" row in the matrix corresponds to the learned vector for the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fS13htfO2F"},{"type":"inlineMath","value":"ith","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"uOmtK0WKCv"},{"type":"text","value":" token in our vocabulary. ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"z4HQevGpys"},{"type":"inlineCode","value":"wte[inputs]","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ALe14f2dIR"},{"type":"text","value":" uses ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"qzJ9k38iJn"},{"type":"link","url":"https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"integer array indexing","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"VCaqaccxTt"}],"urlSource":"https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing","key":"rWSG551aKq"},{"type":"text","value":" to retrieve the vectors corresponding to each token in our input. Like any other parameter in our network, ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"DbSchfe9y4"},{"type":"inlineCode","value":"wte","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"VadQVE1H25"},{"type":"text","value":" is learned. That is, it is randomly initialized at the start of training and then updated via gradient descent.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"yQ8EJbR0IK"}],"key":"lD4xjGHuI2"}],"key":"bRVThg558k"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Positional Embeddings","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dzFAkWXjkK"}],"identifier":"positional-embeddings","label":"Positional Embeddings","html_id":"positional-embeddings","implicit":true,"key":"s8EHqI5WFj"}],"key":"GoYZeTKgt0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"One quirk of the transformer architecture is that it doesn’t take into account position. That is, if we randomly shuffled our input and then accordingly unshuffled the output, the output would be the same as if we never shuffled the input in the first place (the ordering of inputs doesn’t have any effect on the output). Of course, the ordering of words is a crucial part of language (duh), so we need some way to encode positional information into our inputs. For this, we can just use another learned embedding matrix:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HZa2vRpS08"}],"key":"RXqaULEHD5"},{"type":"code","lang":"python","value":"wpe[range(len(inputs))]  # [n_seq] -\u003e [n_seq, n_embd]","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"KxdAK0pyTp"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Recall, ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"vNJck8BPpi"},{"type":"inlineCode","value":"wpe","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Kg7t9x4rCR"},{"type":"text","value":" is a ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"VnCXqefIWJ"},{"type":"inlineCode","value":"[n_ctx, n_embd]","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"kjz5KBJRvR"},{"type":"text","value":" matrix. The ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"r4zQAkNq3l"},{"type":"inlineMath","value":"ith","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"qsZKvoTCYl"},{"type":"text","value":" row of the matrix contains a vector that encodes information about the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AhqQdNkk1f"},{"type":"inlineMath","value":"ith","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"fklmCQAPsO"},{"type":"text","value":" position in the input. Similar to ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"wS8y4Jfcod"},{"type":"inlineMath","value":"wte","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ew\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ewte\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ewt\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ar3XoAeTb0"},{"type":"text","value":", this matrix is learned during gradient descent. Notice, this restricts our model to a maximum sequence length of ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"b9J9Qe5DqM"},{"type":"inlineCode","value":"n_ctx","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"PRzbcX0hNL"},{"type":"text","value":". That is, ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"RQU9mbDgnw"},{"type":"inlineCode","value":"len(inputs) \u003c= n_ctx","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"oAfoPy49ob"},{"type":"text","value":" must hold.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"jov2FYffQ0"}],"key":"AJ01ZuS5n7"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"WNx2GKjANv"}],"key":"vQBu3SdJWh"},{"type":"text","value":": The original transformer paper used a ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Cv27fqdKsr"},{"type":"link","url":"https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"calculated positional embedding","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Pr6jVwemcu"}],"urlSource":"https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding","key":"d8iD4CoWC7"},{"type":"text","value":" which they found performed just as well as learned positional embeddings, but has the distinct advantage that you can input any arbitrarily long sequence (you are not restricted by a maximum sequence length). However, in practice, your model is only going to be as the good sequence lengths that it was trained on. You can’t just train a ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Oiy0n9qpil"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"LO9YJUcVAy"}],"key":"acZ39JOa5b"},{"type":"text","value":" on sequences that are ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"xXZkk4jNiP"},{"type":"text","value":"1024","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"lZSSZuo8CV"},{"type":"text","value":" long and then expect it to perform well at 16k tokens long. Recently however, there has been some success with relative positional embeddings, such as ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"OlJo9LNLcW"},{"type":"link","url":"https://arxiv.org/pdf/2108.12409.pdf","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Alibi","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"xKaqItbiWt"}],"urlSource":"https://arxiv.org/pdf/2108.12409.pdf","key":"imegEjGMQR"},{"type":"text","value":" and ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"wxPz6O03Bi"},{"type":"link","url":"https://arxiv.org/pdf/2104.09864v4.pdf","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"RoPE","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"hnliH9cQm3"}],"urlSource":"https://arxiv.org/pdf/2104.09864v4.pdf","key":"d67k3yRLPh"},{"type":"text","value":".","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Nf1tF0pbMV"}],"key":"efpP3v6LfX"}],"key":"v7aMwbaBnC"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Combined","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dVrOvgtr6P"}],"identifier":"combined","label":"Combined","html_id":"combined","implicit":true,"key":"UYe7zhTc6y"}],"key":"tU9zdDg1JR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can add our token and positional embeddings to get a combined embedding that encodes both token and positional information:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dWqqDztlyA"}],"key":"T4NM2mpF2L"},{"type":"code","lang":"python","value":"# token + positional embeddings\nx = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -\u003e [n_seq, n_embd]\n\n# x[i] represents the word embedding for the ith word + the positional\n# embedding for the ith position","position":{"start":{"line":3,"column":1},"end":{"line":9,"column":1}},"key":"nJKyYk6fL2"}],"key":"UPqdlOq358"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Decoder Stack","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gB3KpzARzq"}],"identifier":"decoder-stack","label":"Decoder Stack","html_id":"decoder-stack","implicit":true,"key":"hPb4om1BDr"}],"key":"lfExYkMHGp"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This is where all the magic happens and the “deep” in deep learning comes in. We pass our embedding through a stack of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DqIBavaC8S"},{"type":"inlineCode","value":"n_layer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bfMBFtdOCf"},{"type":"text","value":" transformer decoder blocks:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q5z3kWn20V"}],"key":"nSQ1Uk0f5L"},{"type":"code","lang":"python","value":"# forward pass through n_layer transformer blocks\nfor block in blocks:\n    x = transformer_block(\n        x, **block, n_head=n_head\n    )  # [n_seq, n_embd] -\u003e [n_seq, n_embd]","position":{"start":{"line":3,"column":1},"end":{"line":9,"column":1}},"key":"XtGNMH9ItE"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Stacking more layers is what allows us to control how deep our network is. ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"l7Fc30a7HK"},{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"bO1RCuTpJX"}],"key":"t236nIG86m"},{"type":"text","value":"-3 for example, has a whopping ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"vTWtkXxVUW"},{"type":"text","value":"96","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ukeGQCdqlm"},{"type":"text","value":" layers. On the other hand, choosing a larger ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"NDcokAsS8U"},{"type":"inlineCode","value":"n_embd","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"FdyVyVchh1"},{"type":"text","value":" value allows us to control how ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"RmhWbNIRQs"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"wide","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ClYgQEfqof"}],"key":"RmIrSwKd4s"},{"type":"text","value":" our network is (for example, ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"uLrF7rbOyw"},{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"umrV3MU3KK"}],"key":"jnX7AVuaJq"},{"type":"text","value":"-3 uses an embedding size of ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"TKdLncLtQP"},{"type":"text","value":"12288","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"aomQLL7zTr"},{"type":"text","value":").","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ge6kp6NFaR"}],"key":"hjp8s3iQ8v"}],"key":"aejACvZfve"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Projection to Vocab","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UieVMUpQ11"}],"identifier":"projection-to-vocab","label":"Projection to Vocab","html_id":"projection-to-vocab","implicit":true,"key":"YcERVEZab2"}],"key":"R1mK5gQcpm"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In our final step, we project the output of the final transformer block to a probability distribution over our vocab:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E5h1GBCjLW"}],"key":"rNdc0dJxS1"},{"type":"code","lang":"python","value":"# projection to vocab\nx = layer_norm(x, **ln_f)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\nreturn x @ wte.T  # [n_seq, n_embd] -\u003e [n_seq, n_vocab]","position":{"start":{"line":3,"column":1},"end":{"line":7,"column":1}},"key":"DRYUSAZ6X3"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Couple things to note here:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Yd06FraP4b"}],"key":"d3fKPQvu9X"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":11,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We first pass ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"H2i2ykqMgV"},{"type":"inlineCode","value":"x","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"btQPUEhvTi"},{"type":"text","value":" through a final layer normalization layer before doing the projection to vocab. This is specific to the ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"uKKsYHfso3"},{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ypQxYjezY4"}],"key":"lpwvebQhuE"},{"type":"text","value":"-2 architecture (this is not present in the original ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"zUe9G9K3gu"},{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"iFojVDcJKj"}],"key":"V7rE5dNFoP"},{"type":"text","value":" and Transformer papers).","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"DA35G8Rf95"}],"key":"VtlOC7DPP2"}],"key":"PhLqvcJuoV"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We are reusing the embedding matrix ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"WMnrzfJzk1"},{"type":"inlineCode","value":"wte","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Zxjlp5nBQF"},{"type":"text","value":" for the projection.  Other ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"xJ5KQclzvN"},{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"J6fWcO8i8U"}],"key":"Lnst2epscq"},{"type":"text","value":" implementations may choose to use a separate learned weight matrix for the projection, however sharing the embedding matrix has a couple of advantages:","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"KAS9QyiZNY"}],"key":"f1gXt5wNbI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"You save some parameters (although at ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"nCoAwxmTek"},{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pfVliXsgsL"}],"key":"oQrT1y89An"},{"type":"text","value":"-3 scale, this is negligible).","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"gAgtZlzCDj"}],"key":"K4FWm9UB0Y"}],"key":"kofG9e4DGi"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Since the matrix is both responsible for mapping both ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"u5wi6QZZ2j"},{"type":"emphasis","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"to","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"zqOxFTtiyV"}],"key":"Z73EL1Cyf4"},{"type":"text","value":" words and ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"qa0wAQVQFs"},{"type":"emphasis","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"from","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"AYNJnr6hXb"}],"key":"gXL0SXB9hW"},{"type":"text","value":" words, in theory, it ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"DJLMmWgl6A"},{"type":"emphasis","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"may","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Q8fKAW9SVb"}],"key":"NOE1KqInWb"},{"type":"text","value":" learn a richer representation compared to having two separate matrixes.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"i18Hev6A7U"}],"key":"JIdpkGspGB"}],"key":"bYnAjAVSMd"}],"key":"kPqlAfSjFU"}],"key":"v8Wr9VALeh"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We don’t apply ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"vZjtRDpfes"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"atfnbyhyi2"},{"type":"text","value":" at the end, so our outputs will be logits instead of probabilities between ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"rTawUK7jd0"},{"type":"text","value":"0","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ezTazJtb2K"},{"type":"text","value":" and ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"HU6D924pLN"},{"type":"text","value":"1","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"OGWb6wDHsv"},{"type":"text","value":". This is done for several reasons:","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"gFFeCOfzWy"}],"key":"eWWMFY7y98"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":16,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"softmax","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"nQPKVenbsi"},{"type":"text","value":" is ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"bJMHZR9Grw"},{"type":"link","url":"https://en.wikipedia.org/wiki/Monotonic_function","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"monotonic","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"STMJ6ZVyXq"}],"urlSource":"https://en.wikipedia.org/wiki/Monotonic_function","data":{"page":"Monotonic_function","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"AkNbtWHhfE"},{"type":"text","value":", so for greedy sampling ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"GKKrGaEia2"},{"type":"inlineCode","value":"np.argmax(logits)","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"cWkDajo2Ir"},{"type":"text","value":" is equivalent to ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"DWv3ANKwgA"},{"type":"inlineCode","value":"np.argmax(softmax(logits))","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"xv6IIagN3p"},{"type":"text","value":" making ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"vqF7snGphL"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"INMPXTJejq"},{"type":"text","value":" redundant","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"jKhfT4FnIz"}],"key":"Rl1ceA6F2u"}],"key":"bs7xJSbvjm"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"softmax","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"zOfV5SK0IT"},{"type":"text","value":" is irreversible, meaning we can always go from logits to probabilities by applying ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Wh69B4B3ZT"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"QY638a6qI5"},{"type":"text","value":", but we can’t go back to logits from probabilities, so for maximum flexibility, we output the logits","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"fzlGFlIFPr"}],"key":"PUKhWcpqr9"}],"key":"u4WM068htf"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Numerically stability (for example, to compute cross entropy ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"pxVUnHnSLl"},{"type":"strong","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"AFdGycJOvk"}],"key":"ELsz4EUs4p"},{"type":"text","value":", taking ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"iKR4gXBnj8"},{"type":"inlineCode","value":"log(softmax(logits))","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"KHa6pxmvJ7"},{"type":"text","value":" is numerically unstable compared to ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"zzxTK3UyzE"},{"type":"inlineCode","value":"log_softmax(logits)","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"psH9eRq2ef"}],"key":"DgJf0BdOdp"}],"key":"dEuBo49xmq"}],"key":"GCldwZzLCQ"}],"key":"ky5urkwYLu"}],"key":"lwFF5uiU3g"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"The projection to vocab step is also sometimes called the language modeling head. What does “head” mean? Once your ","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"tFxStB99Cn"},{"type":"strong","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"eyChCLgP2f"}],"key":"LzW8KqFDcg"},{"type":"text","value":" is pre-trained, you can swap out the language modeling head with some other kind of projection, like a classification head for fine-tuning the model on some classification task. So your model can have multiple heads, kind of like a ","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"vGUeD78CLi"},{"type":"link","url":"https://en.wikipedia.org/wiki/Lernaean_Hydra","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"hydra","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"kpBzPfwaCk"}],"urlSource":"https://en.wikipedia.org/wiki/Lernaean_Hydra","data":{"page":"Lernaean_Hydra","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"RiS04zhOg1"},{"type":"text","value":". So that’s the ","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"MBb47yEN66"},{"type":"strong","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"NCALzSMvQn"}],"key":"bevp6g40xm"},{"type":"text","value":" architecture at a high level, let’s actually dig a bit deeper into what the decoder blocks are doing.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"HnuFln9yNa"}],"key":"rVW7QR3qSp"}],"key":"XTgKhCfHxh"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Decoder Block","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N9hR0MBuv5"}],"identifier":"decoder-block","label":"Decoder Block","html_id":"decoder-block","implicit":true,"key":"Q8Yn8DMpPj"}],"key":"nz382V4Lor"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The transformer decoder block consists of two sublayers:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"X3awQMS7C6"}],"key":"VrpfGtZhDt"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Multi-head causal self attention","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"kbA7KExmuz"}],"key":"ThdQLBn7rA"}],"key":"dKNQ3MwHd7"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Position-wise feed forward ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KiT5z8sLpf"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"EqgZpbWH72"}],"key":"sCo4T57KeU"}],"key":"Yf1alMimsy"}],"key":"XxnNBcwaMh"}],"key":"oCqIisRgVM"}],"key":"XWJvmlrIjR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def transformer_block(\n    x, mlp, attn, ln_1, ln_2, n_head\n):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # multi-head causal self attention\n    x = x + mha(\n        layer_norm(x, **ln_1), **attn, n_head=n_head\n    )  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # position-wise feed forward network\n    x = x + ffn(layer_norm(x, **ln_2), **mlp)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    return x","key":"eMUtuy3S01"},{"type":"outputs","id":"TandimmC9ZWvACigbrVq2","children":[],"key":"t7OFKTLC3l"}],"key":"fzFyZBtTlG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Each sublayer utilizes layer normalization on their inputs as well as a residual connection (i.e. add the input of the sublayer to the output of the sublayer). Some things to note:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xt1D5p62Ob"}],"key":"zQ7VlS2cdh"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Multi-head causal self attention is what facilitates the communication between the inputs. Nowhere else in the network does the model allow inputs to “see” each other. The embeddings, position-wise feed forward network, layer norms, and projection to vocab all operate on our inputs position-wise. Modeling relationships between inputs is tasked solely to attention.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KI1RhZV2zR"}],"key":"tm8MGdSFNX"}],"key":"WsM3V1Re6d"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The Position-wise feed forward ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"mURsi5nZ5W"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"A6qsa4xi3I"}],"key":"TkErKHpd7j"},{"type":"text","value":" is just a regular 2 layer fully connected ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"PHEk4WhgGk"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"KGUBkR9xWZ"}],"key":"Py6SiK44gZ"},{"type":"text","value":". This just adds a bunch of learnable parameters for our model to work with to facilitate learning.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"bzlZMj4BJ2"}],"key":"KcrflTXogE"}],"key":"KYhPmhZgpH"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"In the original transformer paper, layer norm is placed on the output ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WRn9V8lZqd"},{"type":"inlineCode","value":"layer_norm(x + sublayer(x))","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"wDD5NEFNh7"},{"type":"text","value":" while we place layer norm on the input ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IFpkkd55Lb"},{"type":"inlineCode","value":"x + sublayer(layer_norm(x))","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"AtJHFlRLv6"},{"type":"text","value":" to match ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dzihOAScdF"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"R8y840KrG2"}],"key":"qVrr5jJCus"},{"type":"text","value":"-2. This is referred to as pre-norm and has been shown to be ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YDUcEJHFMi"},{"type":"link","url":"https://arxiv.org/pdf/2002.04745.pdf","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"important in improving the performance of the transformer","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"k7VxgaAg56"}],"urlSource":"https://arxiv.org/pdf/2002.04745.pdf","key":"cNsiucnxUq"},{"type":"text","value":".","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"sG4lxdyVap"}],"key":"XZTUML3ptG"}],"key":"ptX4uTuzZ5"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Residual connections (popularized by ResNet) serve a couple of different purposes:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"U1er1HxrV1"}],"key":"Z8NvX41dUC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Makes it easier to optimize ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"aeiRlnvDqb"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Hf7lkIOqwQ"}],"key":"deQJM71iT2"},{"type":"text","value":"s that are deep (i.e. networks that have lots of layers). The idea here is that we are providing “shortcuts” for the gradients to flow back through the network, making it easier to optimize the earlier layers in the network.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"KcqzEgNQGp"}],"key":"U4ZhK84YYU"}],"key":"acb2VTJSrR"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Without residual connections, deeper models see a degradation in performance when adding more layers (possibly because it’s hard for the gradients to flow all the way back through a deep network without losing information). Residual connections seem to give a bit of an accuracy boost for deeper networks.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"j4MtWtNDwO"}],"key":"TuKX0iytbY"}],"key":"ClvazaXDQl"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Can help with the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"y8dEFcftcY"},{"type":"link","url":"https://programmathically.com/understanding-the-exploding-and-vanishing-gradients-problem/","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"vanishing/exploding gradients problem","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"rx5305dxEl"}],"urlSource":"https://programmathically.com/understanding-the-exploding-and-vanishing-gradients-problem/","key":"omDlUcwRnA"},{"type":"text","value":".","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"tCCjGae2ws"}],"key":"laBfZK7ZtI"}],"key":"TrttlIyitl"}],"key":"kBQLhNDFGi"}],"key":"DKSFsvQ1aS"}],"key":"yuBDipziEA"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Let’s dig a little deeper into the 2 sublayers.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"IFxyMvFqwo"}],"key":"NxI1Qd5h5a"}],"key":"zc9kAvuI9u"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Position-wise Feed Forward Network","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"L5fxnEiVlZ"}],"identifier":"position-wise-feed-forward-network","label":"Position-wise Feed Forward Network","html_id":"position-wise-feed-forward-network","implicit":true,"key":"hMyZgI8cfN"}],"key":"tXxRj1cUYM"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This is just a simple multi-layer perceptron with 2 layers:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"haNnXNDoXK"}],"key":"rybApQqTH4"}],"key":"Q0tGOzYCik"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def ffn(x, c_fc, c_proj):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # project up\n    a = gelu(linear(x, **c_fc))  # [n_seq, n_embd] -\u003e [n_seq, 4*n_embd]\n\n    # project back down\n    x = linear(a, **c_proj)  # [n_seq, 4*n_embd] -\u003e [n_seq, n_embd]\n\n    return x","key":"Al94l024nc"},{"type":"outputs","id":"8mo9PDot-Yt3XQ3HqGjsW","children":[],"key":"ZCIaDWDXEs"}],"key":"VFeWgOkhvi"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Nothing super fancy here, we just project from ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"srpq93Iyno"},{"type":"inlineCode","value":"n_embd","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FuGsQcA52k"},{"type":"text","value":" up to a higher dimension ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h2qL6josop"},{"type":"inlineCode","value":"4*n_embd","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EUz0Gud7Ja"},{"type":"text","value":" and then back down to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vGWCt7YdpN"},{"type":"inlineCode","value":"n_embd[4]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"z9o83IVaoO"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZSr5yc2pDk"}],"key":"YYY2BHqID8"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NF9O5Yk9Gg"}],"key":"umsp3P70lj"},{"type":"text","value":": Different ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cXjpI3Rfiw"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pn1Yy3vkDw"}],"key":"Ae6onU8W2R"},{"type":"text","value":" models may choose a different hidden width that is not ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"GQzLmctH0C"},{"type":"inlineCode","value":"4*n_embd","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SOtSE2Dzt3"},{"type":"text","value":", however this is the common practice for ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HaVlSx5YHf"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qNsWjrLtMs"}],"key":"BvV8NPkZ1e"},{"type":"text","value":" models. Also, we give the multi-head attention layer a lot of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"H4CPpRbYPE"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"attention","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HAMxDqj81q"}],"key":"HI1yfyE4L9"},{"type":"text","value":" (pun intended) for driving the success of the transformer, but at the scale of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BEuPxuaD35"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CoHlX9VF9C"}],"key":"Bgpdjj8Hk1"},{"type":"text","value":"-3, ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tqHY5q2JwM"},{"type":"inlineMath","value":"80\\%","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e80\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e%\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e80\\%\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80%\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"AP9cQIoqeV"},{"type":"text","value":" of the model parameters are contained in the feed forward layer. Just something to think about.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gCRjiW9GFG"}],"key":"diZjsDRySU"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Recall, from our params dictionary, that our mlp params look like this:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"oiqXQQWfhB"}],"key":"qgprkUJT3E"},{"type":"code","lang":"python","value":"\"mlp\": {\n    \"c_fc\": {\"b\": [4*n_embd], \"w\": [n_embd, 4*n_embd]},\n    \"c_proj\": {\"b\": [n_embd], \"w\": [4*n_embd, n_embd]},\n},","position":{"start":{"line":7,"column":1},"end":{"line":12,"column":1}},"key":"iS4Bp33s0w"}],"key":"ZRe1GNwi8P"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multi-Head Causal Self Attention","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MOykarV5sN"}],"identifier":"multi-head-causal-self-attention","label":"Multi-Head Causal Self Attention","html_id":"multi-head-causal-self-attention","implicit":true,"key":"BgsitvDsZ9"}],"key":"ZTLtdZxkz3"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This layer is probably the most difficult part of the transformer to understand. So let’s work our way up to “Multi-Head Causal Self Attention” by breaking each word down into its own section:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PnjdbeFRZT"}],"key":"nLjGgDEWye"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Attention","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CaRLVycNtV"}],"key":"Sho4I4z2iw"}],"key":"z7IndCyfND"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Self","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"wb5MsIekHn"}],"key":"ylL7vfkTJ7"}],"key":"DKPjbf1h1M"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Causal","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"k7LETCkhEH"}],"key":"uj9FouoFE3"}],"key":"xB7LAkGo8p"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Multi-Head","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"rhtGL3OODg"}],"key":"YrhwDkChru"}],"key":"bSE7hwCC8T"}],"key":"jPjEQKlHxU"}],"key":"oDpiNyuXSa"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Attention","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OVbC2q7r0e"}],"identifier":"attention","label":"Attention","html_id":"attention","implicit":true,"key":"iqqeKGcA2E"}],"key":"Paue8rgW0Q"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"ChatGPT and other large language models use a special type of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ei83YtnqeC"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GJ86xOuL9D"}],"key":"UTsMWNC0Lf"},{"type":"text","value":" called the transformer. The transformer defining feature is the attention mechanism. Attention is defined by the equation:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a5fuofrkHj"}],"key":"CpqUxP5XnA"},{"type":"math","value":"\\text{attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmfrac\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cmsqrt\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msqrt\u003e\u003c/mfrac\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.4483em;vertical-align:-0.93em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.5183em;\"\u003e\u003cspan style=\"top:-2.2528em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8572em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8172em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1828em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8413em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.93em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"3","key":"NoWRY3Utwa"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Attention can come in different forms, but this version of attention (known as scaled dot product attention) was first proposed in the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"je279BLDfa"},{"type":"link","url":"https://arxiv.org/pdf/1706.03762.pdf","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"original transformer paper","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"wRFN8Lqv5k"}],"urlSource":"https://arxiv.org/pdf/1706.03762.pdf","key":"QtbrDw8rmw"},{"type":"text","value":". In this post, we’ll build an intuition for the above equation by deriving it from the ground up.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"tjQ3lISels"}],"key":"Nvvf1Z7Wye"}],"key":"PZk5j0oNmL"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":5,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Key-Value Lookups","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"o3tAVW2Z6o"}],"identifier":"key-value-lookups","label":"Key-Value Lookups","html_id":"key-value-lookups","implicit":true,"key":"Yzm79gSFQM"}],"key":"yMwBkt4Qwu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"A key-value (kv) lookup involves three components:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lBIp9wazEL"}],"key":"Edw1lGt5VX"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"A list of ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Whn02pmnHw"},{"type":"inlineMath","value":"n_k","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"M7pcIpNQpV"},{"type":"text","value":" ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"xRanBFO1wz"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"keys","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"R0lZy47mM5"}],"key":"TB9CnXmWhN"}],"key":"VigUpjIWlu"}],"key":"kXGEzuPKbR"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"A list of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jg50m21UIe"},{"type":"inlineMath","value":"n_k","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"oZA4nY0o1a"},{"type":"text","value":" ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gVmsaiKNIJ"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"values","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"baT2sb0FUX"}],"key":"b9RuRIAkrh"},{"type":"text","value":" (that map 1-to-1 with the keys, forming key-value pairs)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gsW8vMGCft"}],"key":"VCSAq5S0Fu"}],"key":"drkjy9GSzF"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"A ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"W8H3mHJ2X7"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"query","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"r4YPqRxAPq"}],"key":"YthudK1ytQ"},{"type":"text","value":", for which we want to ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"C389H6bBbi"},{"type":"emphasis","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"match","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"jbR2gS3WuJ"}],"key":"K9TFLpFb5x"},{"type":"text","value":" with the keys and get some value based on the match","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"rywPXtJEGG"}],"key":"bgC4mkEkcO"}],"key":"Zxu0zeSlJh"}],"key":"PrS6NIDdXo"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"You’re probably familiar with this concept as a dictionary or hash map:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"W49x97BPbY"}],"key":"aZnHIsYWPi"}],"key":"jFyiHOBL4p"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"d = {\n    \"apple\": 10,\n    \"banana\": 5,\n    \"chair\": 2,\n}\nprint(d.keys())\nprint(d.values())\nquery = \"apple\"\nd[query]","key":"FWMefI9Xut"},{"type":"outputs","id":"27wq0zmtLlOaTGX6_E7ly","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"dict_keys(['apple', 'banana', 'chair'])\ndict_values([10, 5, 2])\n"},"children":[],"key":"uEMODqDQEQ"},{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":30,"metadata":{},"data":{"text/plain":{"content":"10","content_type":"text/plain"}}},"children":[],"key":"UCFgOwG9R0"}],"key":"UU1bBKpq5J"}],"key":"wN3bMNauZG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Dictionaries let us perform lookups based on an exact string match. What if instead we wanted to do a lookup based on the meaning of a word?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fGIhmxxs7p"}],"key":"rX2q8zVsbO"}],"key":"Rrt71I3SWl"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":5,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Key-Value Lookups based on Meaning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nQWGYna40P"}],"identifier":"key-value-lookups-based-on-meaning","label":"Key-Value Lookups based on Meaning","html_id":"key-value-lookups-based-on-meaning","implicit":true,"key":"tu267SON6y"}],"key":"dKjVZHMY3D"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Say we wanted to look up the word “fruit” in our previous example, how do we choose which key is the best match? It’s obviously not “chair”, but both “apple” and “banana” seem like a good match. It’s hard to choose one or the other, fruit feels more like a combination of apple and banana rather than a strict match for either. So, let’s not choose. Instead, we’ll do exactly that, take a combination of apple and banana. For example, say we assign a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TioDqmJw1j"},{"type":"inlineMath","value":"60\\%","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e60\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e%\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e60\\%\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e60%\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"SpeRFC4PLB"},{"type":"text","value":" meaning based match for apple, a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DmBh908ejy"},{"type":"inlineMath","value":"40\\%","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e40\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e%\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e40\\%\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e40%\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"vBBRP2Ehyb"},{"type":"text","value":" match for banana, and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uPdk7OvN27"},{"type":"inlineMath","value":"0\\%","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e%\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0\\%\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0%\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"DtiyCSV7Kb"},{"type":"text","value":" match for chair. We compute our final output value as the weighted sum of the values with the percentages:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ahbpQXu3RN"}],"key":"HPjOhfI83l"}],"key":"bBvYeQVSdJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"query = \"fruit\"\nd = {\"apple\": 10, \"banana\": 5, \"chair\": 2}\n0.6 * d[\"apple\"] + 0.4 * d[\"banana\"] + 0.0 * d[\"chair\"]","key":"pdXJN9Rtmf"},{"type":"outputs","id":"_q2MkssLpBgVMWu25UZHN","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":31,"metadata":{},"data":{"text/plain":{"content":"8.0","content_type":"text/plain"}}},"children":[],"key":"aLNn7mPOck"}],"key":"c1VOPSXqen"}],"key":"Xwek5QaLnQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In a sense, we are determining how much attention our query should be paying to each key-value pair based on ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Dc7WC7WjaQ"},{"type":"inlineCode","value":"meaning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"beU4LO341X"},{"type":"text","value":". The amount of “attention” is represented as a decimal percentage, called an attention score. Mathematically, we can define our output as a simple weighted sum:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TMgTnf7fep"}],"key":"RyHxhncllJ"},{"type":"math","value":"\\sum_{i} \\alpha_i v_i","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/munder\u003e\u003cmsub\u003e\u003cmi\u003eα\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sum_{i} \\alpha_i v_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.3277em;vertical-align:-1.2777em;\"\u003e\u003c/span\u003e\u003cspan class=\"mop op-limits\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.05em;\"\u003e\u003cspan style=\"top:-1.8723em;margin-left:0em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan class=\"mop op-symbol large-op\"\u003e∑\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2777em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.0037em;\"\u003eα\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"4","key":"mvTaL6gq9z"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ONPwbWXKjC"},{"type":"inlineMath","value":"\\alpha_i","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eα\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\alpha_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.0037em;\"\u003eα\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iYh3dyuypt"},{"type":"text","value":" is our attention score for the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"i05RSxsMmc"},{"type":"inlineMath","value":"ith","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"HNl2bORDOf"},{"type":"text","value":" kv pair and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"sEF3C1uLVh"},{"type":"inlineMath","value":"v_i","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"B5rEXIg1j9"},{"type":"text","value":" is the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"pZoFAqbhsi"},{"type":"inlineMath","value":"ith","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"xnbq0gpvBW"},{"type":"text","value":" value. Remember, the attention scores are decimal percentages, that is they must be between ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Baw4Znozhv"},{"type":"text","value":"0","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Ab1J9T8jQr"},{"type":"text","value":" and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"U0bz8HsBY9"},{"type":"text","value":"1","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YZHM4zlsfi"},{"type":"text","value":" inclusive (","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"v8qOuBjPMi"},{"type":"inlineMath","value":"0 \\leq \\alpha_i \\leq 1","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo\u003e≤\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eα\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e≤\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0 \\leq \\alpha_i \\leq 1\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7804em;vertical-align:-0.136em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e≤\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.786em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.0037em;\"\u003eα\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e≤\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"S4OyqmM9Da"},{"type":"text","value":") and their sum must be ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"PAmenyDaZA"},{"type":"text","value":"1","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"uqsMkxWuRq"},{"type":"text","value":" (","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"v7XyH4uCjz"},{"type":"inlineMath","value":"\\sum_{i} \\alpha_i = 1","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmi\u003eα\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sum_{i} \\alpha_i = 1\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.0497em;vertical-align:-0.2997em;\"\u003e\u003c/span\u003e\u003cspan class=\"mop\"\u003e\u003cspan class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\"\u003e∑\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.162em;\"\u003e\u003cspan style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2997em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.0037em;\"\u003eα\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UYy2k5maFu"},{"type":"text","value":"). Okay, but where did we get these attention scores from? In our example, we kind of chose them based on what we felt. While we did a pretty good job, this approach doesn’t seem sustainable. Instead, let’s take a look at how word vectors can help solve our problem of determining attention scores.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VIQOxsiQkY"}],"key":"emzPXSgIVX"}],"key":"n9IUPh74YA"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":5,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Word Vectors and Similarity","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ruXc0n7Y4Y"}],"identifier":"word-vectors-and-similarity","label":"Word Vectors and Similarity","html_id":"word-vectors-and-similarity","implicit":true,"key":"ZcnDeF4Gg9"}],"key":"v3siOpy7Hk"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Imagine we represent a word with a vector of numbers. Ideally, the values in the vector should in some way capture the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OcX7jc7PHp"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"meaning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BcoxIIyrjQ"}],"key":"a4WE2XqcOP"},{"type":"text","value":" of the word it represents. For example, imagine we have the following word vectors (visualized in 2D space):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eO4sKUtjKX"}],"key":"jQqOnQ7DG0"}],"key":"DEU0DUtVgZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"2d_word_vectors_example.png\"))","key":"lucSFj7blQ"},{"type":"outputs","id":"RydmcrSkuQfGsquzd6Bp1","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"62ff8935ab01a5371f3de4e1af37f529","path":"/build/62ff8935ab01a5371f3de4e1af37f529.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"hIt13zFG34"}],"key":"y9zoqQZpI4"}],"key":"HmoPLP5Wn7"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"You can see that words that are ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dzDc9hxcsr"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"similar","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C4sbvqycC4"}],"key":"fpqXZ2AVoz"},{"type":"text","value":" are clustered together. Fruits are clustered at the top right, vegetables are clustered at the top left, and furniture is clustered at the bottom. In fact, you can even see that the vegetable and fruit clusters are closer to each other than they are to the furniture cluster, since they are more closely related things. You can even imagine doing arithmetic on word vectors. For example, given the words “king”, “queen”, “man”, and “woman” and their respective vector representations ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Rz9TVXhJ72"},{"type":"inlineMath","value":"v_{king}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003eg\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev_{king}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7167em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ekin\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"o4d5N76Iq3"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r4WYaLDkKy"},{"type":"inlineMath","value":"v_{queen}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eq\u003c/mi\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev_{queen}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7167em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003eq\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eu\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eee\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"rssFhf7TjH"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"o3yHIyiOlg"},{"type":"inlineMath","value":"v_{man}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev_{man}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eman\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"T7olqwSuTK"},{"type":"text","value":", and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J4fOxFVqeo"},{"type":"inlineMath","value":"v_{woman}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ew\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev_{woman}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\"\u003ew\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eman\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"TBEox5H8ZI"},{"type":"text","value":", we can imagine that:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Z0AaHdSc0a"}],"key":"YotBEgV0ml"},{"type":"math","value":"v_{queen} - v_{woman} + v_{man} \\sim v_{king}","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003eq\u003c/mi\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ew\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003em\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e∼\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003eg\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev_{queen} - v_{woman} + v_{man} \\sim v_{king}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003eq\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eu\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eee\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e−\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\"\u003ew\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eman\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e+\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eman\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e∼\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7167em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ekin\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"5","key":"rUNTu7bsyl"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"That is, the vector for “queen” minus “woman” plus “man” should result in a vector that is ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EbYRnewRkj"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"similar","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"RDboGl0ipW"}],"key":"Xv3YLsz8Ss"},{"type":"text","value":" to the vector for “king”. But what does it exactly mean for two vectors to be ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Fk5aNWxI68"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"similar","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"epZbwG1wb3"}],"key":"X1q0Bq1ZzB"},{"type":"text","value":"? In the fruits/vegetables example, we were using distance as a measure of similarity (in particular, ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EKiUzvbWTk"},{"type":"link","url":"https://en.wikipedia.org/wiki/Euclidean_distance","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"euclidean distance","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"trxRImdhrR"}],"urlSource":"https://en.wikipedia.org/wiki/Euclidean_distance","data":{"page":"Euclidean_distance","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"tOtf67ZUHW"},{"type":"text","value":"). There are also ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"QCwMQMVJ6y"},{"type":"link","url":"https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"other ways to measure similarity between two vectors","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ntkpZpCt3C"}],"urlSource":"https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa","key":"LZiUr31utz"},{"type":"text","value":", each with its own advantages and disadvantages. Possibly the simplest measure of similarity between two vectors is their dot product:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"B7H0rU7dEm"}],"key":"PEAWAnSqnW"},{"type":"math","value":"\\textbf{v} \\cdot \\textbf{w} = \\sum_{i} v_i w_i","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003ew\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/munder\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmi\u003ew\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{v} \\cdot \\textbf{w} = \\sum_{i} v_i w_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4445em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ew\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.3277em;vertical-align:-1.2777em;\"\u003e\u003c/span\u003e\u003cspan class=\"mop op-limits\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.05em;\"\u003e\u003cspan style=\"top:-1.8723em;margin-left:0em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan class=\"mop op-symbol large-op\"\u003e∑\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2777em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02691em;\"\u003ew\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"6","key":"HKveVItGEv"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://www.youtube.com/watch?v=LyGKycYT2v0","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"3blue1brown has a great video on the intuition behind dot product","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"bcVNsQ5EIc"}],"urlSource":"https://www.youtube.com/watch?v=LyGKycYT2v0","key":"XA8J1EKA0j"},{"type":"text","value":", but for our purposes all we need to know is:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"wgTXf5jYyo"}],"key":"sveZpFqJGg"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":11,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"If two vectors are pointing in the same direction, the dot product will be ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"YuZxPGCBRW"},{"type":"inlineMath","value":"\u003e 0","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo\u003e\u0026gt;\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\u0026gt; 0\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"nqpkXlcnEj"},{"type":"text","value":" (i.e. ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"cBX8nJXYYf"},{"type":"emphasis","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"similar","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"tfRaxEe71G"}],"key":"hsjIBC8ppp"},{"type":"text","value":")","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"wavIYkyRT3"}],"key":"vYMet9YufX"}],"key":"fHStjVjj9y"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"If they are pointing in opposing directions, the dot product will be ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"iPsb9X92Hi"},{"type":"inlineMath","value":"\u003c 0","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo\u003e\u0026lt;\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\u0026lt; 0\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"j93l7P9kNL"},{"type":"text","value":" (i.e. ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"vUNCbF43x3"},{"type":"emphasis","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"dissimilar","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"MpeiBwJVV9"}],"key":"KSGHLPCaNq"},{"type":"text","value":")","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"zYT26l1YMH"}],"key":"Oa8pvHyY5M"}],"key":"IZdOi1cJ0G"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"If they are exactly perpendicular, the dot product will be ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"SRaJm9MfQl"},{"type":"text","value":"0","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"m7kHlbVquO"},{"type":"text","value":" (i.e. ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"NXmBYjqkh5"},{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"neutral","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"I7KII3g8IE"}],"key":"QAJdNWHApS"},{"type":"text","value":")","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pvvprIWZaG"}],"key":"VvMvPxATFZ"}],"key":"JicdpJNKl1"}],"key":"vRsGkps4jB"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Using this information, we can define a simple heuristic to determine the similarity between two word vectors: The greater the dot product, the more similar two words are in ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"UWXLnVGk6r"},{"type":"emphasis","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"meaning","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"lY9dhBx0wx"}],"key":"RVWOknQzfB"},{"type":"text","value":".","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"njCaHcOM54"}],"key":"KpkLxY2Z0N"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"nbDlpVsafB"}],"key":"aZEdnAePKE"},{"type":"text","value":": You’ll note that the magnitude of the vectors have an influence on the output of dot product. For example, given 3 vectors, ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Flo99DNoZU"},{"type":"inlineMath","value":"a = [1, 1, 1]","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea = [1, 1, 1]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"VvhxzyXHkA"},{"type":"text","value":", ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"vRUpdwHdy5"},{"type":"inlineMath","value":"b = [1000, 0, 0]","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eb\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e1000\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eb = [1000, 0, 0]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eb\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e1000\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"A34TS6zhdi"},{"type":"text","value":", ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Y1b1LZssqp"},{"type":"inlineMath","value":"c = [2, 2, 2]","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ec\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ec = [2, 2, 2]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ec\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"fl2kTE6bKw"},{"type":"text","value":", our dot product heuristic would tell us that because ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"vhkEo5wsvQ"},{"type":"inlineMath","value":"a \\cdot b \u003e a \\cdot c","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmi\u003eb\u003c/mi\u003e\u003cmo\u003e\u0026gt;\u003c/mo\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmi\u003ec\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea \\cdot b \u0026gt; a \\cdot c\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4445em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7335em;vertical-align:-0.0391em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eb\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4445em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"dZKwtfNhlv"},{"type":"text","value":", that ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"RrlCnwsPm9"},{"type":"inlineMath","value":"a","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"MaTy79pPYQ"},{"type":"text","value":" is more similar to ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"iTRbQu4CFz"},{"type":"inlineMath","value":"c","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ec\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ec\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"kgfeRjJTfA"},{"type":"text","value":" than ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"RO6NWbDRhF"},{"type":"inlineMath","value":"a","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"SbVUu3h79R"},{"type":"text","value":" is to ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"scT2tgs6OE"},{"type":"inlineMath","value":"b","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eb\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eb\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eb\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ybBvyAWxc0"},{"type":"text","value":". This doesn’t seem right, since ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"TbFiiLx4T9"},{"type":"inlineMath","value":"a","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"V5AvTG5QP1"},{"type":"text","value":" and ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"sA8b2MzELK"},{"type":"inlineMath","value":"b","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eb\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eb\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eb\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"uGo5JMLQ8q"},{"type":"text","value":" are pointing in the exact same direction, while ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"vJODFUF1VY"},{"type":"inlineMath","value":"a","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"rnPlpHq3l8"},{"type":"text","value":" and ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"jcoRBrfOT0"},{"type":"inlineMath","value":"c","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ec\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ec\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ec\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"a1I4oXvfVy"},{"type":"text","value":" are not. ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"LYiTKVvi5J"},{"type":"link","url":"https://en.wikipedia.org/wiki/Cosine_similarity","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Cosine similarity","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"uu4hhbDaO2"}],"urlSource":"https://en.wikipedia.org/wiki/Cosine_similarity","data":{"page":"Cosine_similarity","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"vg6YzVU7W6"},{"type":"text","value":" accounts for this normalizing the vectors to unit vectors before taking the dot product, essentially ignoring the magnitudes and only caring about the direction. So why don’t we take the cosine similarity? In a deep learning setting, the magnitude of a vector might actually contain information we care about (and we shouldn’t get rid of it). Also, if we regularize our networks properly, outlier examples like the above should not occur.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"wDV24vnSrs"}],"key":"qyGttOGJER"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Okay cool, but where do these word vectors actually come from? They usually come from some kind of learned embedding or latent representation. That is, initially the word vectors are just random numbers, but as the ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"W0cX10onR1"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"DYvxoqxtcH"}],"key":"sFWUI5I7Dg"},{"type":"text","value":" is trained, their values are adjusted to become better and better representations for words.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"FahcmHBDf3"}],"key":"nrRofy8vab"}],"key":"mrkrSFBRZO"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":5,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Attention Scores using the Dot Product","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fYucGKUlC5"}],"identifier":"attention-scores-using-the-dot-product","label":"Attention Scores using the Dot Product","html_id":"attention-scores-using-the-dot-product","implicit":true,"key":"S8zJ7NYoDL"}],"key":"mH4rbuATaK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s return to our example of fruits, but this time around using word vectors to represent our words. That is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mzMY7PFH1j"},{"type":"inlineMath","value":"\\textbf{q} = \\textbf{v}_{fruit}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmrow\u003e\u003cmi\u003ef\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{q} = \\textbf{v}_{fruit}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7305em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\"\u003er\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003eu\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"kqE5ToW4I9"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"q9BiBjT1Fv"},{"type":"inlineMath","value":"\\textbf{k} = [\\textbf{v}_{apple} \\textbf{v}_{banana} \\textbf{v}_{chair}]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ek\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmrow\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003ep\u003c/mi\u003e\u003cmi\u003el\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmrow\u003e\u003cmi\u003eb\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmrow\u003e\u003cmi\u003ec\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{k} = [\\textbf{v}_{apple} \\textbf{v}_{banana} \\textbf{v}_{chair}]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ea\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\"\u003eppl\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ee\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ebanana\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ec\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ehai\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\"\u003er\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"uOHW4XSNnY"},{"type":"text","value":", such that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gpQRWkAaHk"},{"type":"inlineMath","value":"\\textbf{v} \\in \\mathbb{R}^{d_k}","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmo\u003e∈\u003c/mo\u003e\u003cmsup\u003e\u003cmi mathvariant=\"double-struck\"\u003eR\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{v} \\in \\mathbb{R}^{d_k}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e∈\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8491em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathbb\"\u003eR\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8491em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1512em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"DYFri7q5Xl"},{"type":"text","value":" (that is each vector has the same dimensionality of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PdhTjX03m8"},{"type":"inlineMath","value":"d_k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ed_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"JCJd7uiHET"},{"type":"text","value":", which is a value we choose when training a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KUFLy5lWU3"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wSLZ8AN4Wd"}],"key":"Y4ZKnUJAOD"},{"type":"text","value":"). Using our new dot product similarity measure, we can compute the similarity between the query and the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d999Exw6zE"},{"type":"inlineMath","value":"ith","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ZPZ2tpboai"},{"type":"text","value":" key as:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jcioVKQLvC"}],"key":"ISTukyRw9y"},{"type":"math","value":"\\textbf{x}_i = \\textbf{q} \\cdot \\textbf{k}_i","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ex\u003c/mtext\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ek\u003c/mtext\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{x}_i = \\textbf{q} \\cdot \\textbf{k}_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5944em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"7","key":"taFJXh575D"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"eiZoyCN6CW"},{"type":"inlineMath","value":"\\textbf{a}_i","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ea\u003c/mtext\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{a}_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5944em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ea\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"s3FqEWLy8u"},{"type":"text","value":" is the attention score for the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"TVv0NLkz7j"},{"type":"inlineMath","value":"ith","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"QpFK97K6qw"},{"type":"text","value":" key-value pair.  Generalizing this further, we can compute the dot product for all ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"g89ZMhfIV1"},{"type":"inlineMath","value":"n_k","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"hmbHItDOJZ"},{"type":"text","value":" keys with:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"wPSNwwwRw8"}],"key":"kaWTEDYcBd"},{"type":"math","value":"\\textbf{x} = \\textbf{q} \\cdot \\textbf{K}^T","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ex\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{x} = \\textbf{q} \\cdot \\textbf{K}^T\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9173em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"8","key":"jvpZNS4mNE"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"vaWnUg0iu7"},{"type":"inlineMath","value":"\\textbf{x}","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ex\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{x}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"qxoGgckMI2"},{"type":"text","value":" is our vector of dot products ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"sB10KvUQE0"},{"type":"inlineMath","value":"\\textbf{x} = [x_1, x_2, ..., x_{n_k - 1}, x_{n_k}]","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ex\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{x} = [x_1, x_2, ..., x_{n_k - 1}, x_{n_k}]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.0059em;vertical-align:-0.2559em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e...\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1512em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2559em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1512em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2559em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"T4bK4Ev87n"},{"type":"text","value":" and ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"iCQtFiNWr7"},{"type":"inlineMath","value":"K","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eK\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eK\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iDIzLtpm9I"},{"type":"text","value":" is a row-wise matrix of our key vectors (i.e. our key vectors stacked on-top of each-other to form a ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"GTw96aOJL4"},{"type":"inlineMath","value":"n_k \\times d_k","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en_k \\times d_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"nJu2JWruZP"},{"type":"text","value":" matrix such that ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"hhr7YCchio"},{"type":"inlineMath","value":"k_i","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ek\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ek_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"FHlMZ3Cida"},{"type":"text","value":" is the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"i8R1RRom8I"},{"type":"inlineMath","value":"ith","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"CajiCW1IJd"},{"type":"text","value":" row of ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"vJaiLYLJ11"},{"type":"inlineMath","value":"K","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eK\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eK\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"VTAdjYW75g"},{"type":"text","value":"). If you’re having trouble understanding this, here’s an explanation:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"yKd8ZwiuvK"}],"key":"zVYrAFpTeQ"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Basically, instead of computing each dot product separately:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Sm3Zf9SZZ0"}],"key":"pBDALQfTjO"},{"type":"math","value":"x_1 = \\textbf{q} \\cdot \\textbf{k}_1 = [2, 1, 3] \\cdot [-1, 2, -1] = -3","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ek\u003c/mtext\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ex_1 = \\textbf{q} \\cdot \\textbf{k}_1 = [2, 1, 3] \\cdot [-1, 2, -1] = -3\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"9","key":"sMujkMWxiV"},{"type":"math","value":"x_2 = \\textbf{q} \\cdot \\textbf{k}_2 = [2, 1, 3] \\cdot [1.5, 0, -1] = 0","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ek\u003c/mtext\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e1.5\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ex_2 = \\textbf{q} \\cdot \\textbf{k}_2 = [2, 1, 3] \\cdot [1.5, 0, -1] = 0\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e1.5\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"10","key":"ibBu2mloAE"},{"type":"math","value":"x_3 = \\textbf{q} \\cdot \\textbf{k}_3 = [2, 1, 3] \\cdot [4, -2, -1] = 3","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsub\u003e\u003cmtext mathvariant=\"bold\"\u003ek\u003c/mtext\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ex_3 = \\textbf{q} \\cdot \\textbf{k}_3 = [2, 1, 3] \\cdot [4, -2, -1] = 3\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e3\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e3\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"11","key":"k9Zqd67Dfy"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"You compute it all at once:","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"lM69tT46Mn"}],"key":"dq3iZm2Yjj"},{"type":"math","value":"\\textbf{x} = \\textbf{q} \\cdot \\textbf{K}^T = [2, 1, 3] \\cdot \\begin{bmatrix} -1 \u0026 2 \u0026 -1 \\\\ 1.5 \u0026 0 \u0026 -1 \\\\ 4 \u0026 -2 \u0026 -1 \\end{bmatrix}^T = [2, 1, 3] \\cdot \\begin{bmatrix} -1 \u0026 1.5 \u0026 4 \\\\ 2 \u0026 0 \u0026 -2 \\\\ -1 \u0026 -1 \u0026 -1 \\end{bmatrix} = [-3, 0, 3] = [x_1, x_2, x_3]","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ex\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmsup\u003e\u003cmrow\u003e\u003cmo fence=\"true\"\u003e[\u003c/mo\u003e\u003cmtable rowspacing=\"0.16em\" columnalign=\"center center center\" columnspacing=\"1em\"\u003e\u003cmtr\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003c/mtr\u003e\u003cmtr\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e1.5\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003c/mtr\u003e\u003cmtr\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e4\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003c/mtr\u003e\u003c/mtable\u003e\u003cmo fence=\"true\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmrow\u003e\u003cmo fence=\"true\"\u003e[\u003c/mo\u003e\u003cmtable rowspacing=\"0.16em\" columnalign=\"center center center\" columnspacing=\"1em\"\u003e\u003cmtr\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e1.5\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e4\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003c/mtr\u003e\u003cmtr\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003c/mtr\u003e\u003cmtr\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003cmtd\u003e\u003cmstyle scriptlevel=\"0\" displaystyle=\"false\"\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/mstyle\u003e\u003c/mtd\u003e\u003c/mtr\u003e\u003c/mtable\u003e\u003cmo fence=\"true\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{x} = \\textbf{q} \\cdot \\textbf{K}^T = [2, 1, 3] \\cdot \\begin{bmatrix} -1 \u0026amp; 2 \u0026amp; -1 \\\\ 1.5 \u0026amp; 0 \u0026amp; -1 \\\\ 4 \u0026amp; -2 \u0026amp; -1 \\end{bmatrix}^T = [2, 1, 3] \\cdot \\begin{bmatrix} -1 \u0026amp; 1.5 \u0026amp; 4 \\\\ 2 \u0026amp; 0 \u0026amp; -2 \\\\ -1 \u0026amp; -1 \u0026amp; -1 \\end{bmatrix} = [-3, 0, 3] = [x_1, x_2, x_3]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9173em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:3.8313em;vertical-align:-1.55em;\"\u003e\u003c/span\u003e\u003cspan class=\"minner\"\u003e\u003cspan class=\"minner\"\u003e\u003cspan class=\"mopen\"\u003e\u003cspan class=\"delimsizing mult\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-2.25em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.397em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan style=\"height:0.016em;width:0.6667em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M319 0 H403 V16 H319z M319 0 H403 V16 H319z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-4.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎡\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mtable\"\u003e\u003cspan class=\"col-align-c\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-4.21em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.01em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e1.5\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-1.81em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"col-align-c\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-4.21em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.01em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-1.81em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"col-align-c\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-4.21em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.01em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-1.81em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"delimsizing mult\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-2.25em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎦\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.397em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan style=\"height:0.016em;width:0.6667em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M263 0 H347 V16 H263z M263 0 H347 V16 H263z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-4.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎤\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.2813em;\"\u003e\u003cspan style=\"top:-4.5029em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:3.6em;vertical-align:-1.55em;\"\u003e\u003c/span\u003e\u003cspan class=\"minner\"\u003e\u003cspan class=\"mopen\"\u003e\u003cspan class=\"delimsizing mult\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-2.25em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.397em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan style=\"height:0.016em;width:0.6667em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M319 0 H403 V16 H319z M319 0 H403 V16 H319z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-4.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎡\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mtable\"\u003e\u003cspan class=\"col-align-c\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-4.21em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.01em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-1.81em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"col-align-c\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-4.21em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e1.5\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.01em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-1.81em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"arraycolsep\" style=\"width:0.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"col-align-c\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-4.21em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.01em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-1.81em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"delimsizing mult\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:2.05em;\"\u003e\u003cspan style=\"top:-2.25em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎦\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.397em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan style=\"height:0.016em;width:0.6667em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.6667em' height='0.016em' style='width:0.6667em' viewBox='0 0 666.67 16' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M263 0 H347 V16 H263z M263 0 H347 V16 H263z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-4.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.155em;\"\u003e\u003c/span\u003e\u003cspan class=\"delimsizinginner delim-size4\"\u003e\u003cspan\u003e⎤\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.55em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e3\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"12","key":"TQ3VTh81bu"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Now, recall that our attention scores need to be decimal percentages (between ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"YzxUJTb0XV"},{"type":"text","value":"0","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"knBIQZ40vT"},{"type":"text","value":" and ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"RRaxCnpnIs"},{"type":"text","value":"1","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ON7hyrWSHF"},{"type":"text","value":" and sum to ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"lm8Wi4XuUk"},{"type":"text","value":"1","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"wPh2NHnHzv"},{"type":"text","value":"). Our dot product values however can be any real number (i.e. between ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"VX4f0KG3HG"},{"type":"inlineMath","value":"-\\infty","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∞\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e-\\infty\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e∞\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"CTplrAsD57"},{"type":"text","value":" and ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"xUEdFD5Me1"},{"type":"inlineMath","value":"\\infty","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi mathvariant=\"normal\"\u003e∞\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\infty\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∞\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"nuvN0fD4qz"},{"type":"text","value":"). To transform our dot product values to decimal percentages, we’ll use the softmax function:","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ErFWVWyL7b"}],"key":"S1kFiOEaX3"},{"type":"math","value":"\\text{softmax}(x) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmfrac\u003e\u003cmsup\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003cmrow\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/munder\u003e\u003cmsup\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003c/mfrac\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{softmax}(x) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.4632em;vertical-align:-1.1218em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.3414em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mop\"\u003e\u003cspan class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\"\u003e∑\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.162em;\"\u003e\u003cspan style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.4358em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.6065em;\"\u003e\u003cspan style=\"top:-3.0051em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3281em;\"\u003e\u003cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2819em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.6644em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3281em;\"\u003e\u003cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.143em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.1218em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"13","key":"dqZB56E8OA"},{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"e.g.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"NCOfdZWp1H"}],"key":"wG2gXswIbg"}],"key":"zWlYMpi65h"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"softmax(np.array([4.0, -1.0, 2.1]))","key":"KhpstF040m"},{"type":"outputs","id":"YPuyXmtfaswlc37HCHZdr","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":33,"metadata":{},"data":{"text/plain":{"content":"array([0.86482256, 0.00582713, 0.12935032])","content_type":"text/plain"}}},"children":[],"key":"hKNuiXltb6"}],"key":"p0U3K9reHu"}],"key":"U1tLE9iThF"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Notice:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"s3Ovxtz2ok"}],"key":"E4t2hI2Z3o"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"✅ Each number is between ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"EONotywX9P"},{"type":"text","value":"0","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"uptqysX4zh"},{"type":"text","value":" and ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"qsHz1D2Ssm"},{"type":"text","value":"1","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"bIjtNnO3F2"}],"key":"dvJXAWaRIs"}],"key":"ScEWZzOHcO"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"✅ The numbers sum to ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UKOwfWZ6l1"},{"type":"text","value":"1","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BYSyxksKX2"}],"key":"GNSg6a3jfr"}],"key":"DEVRKDU8pI"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"✅ The larger valued inputs get more “weight”","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"iUCA8YqpWH"}],"key":"ZeVSrJqgsW"}],"key":"tKxaiyAZMT"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"✅ The sorted order is preserved (i.e. the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VeahTOIRQD"},{"type":"text","value":"4.0","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MgINrrkh1r"},{"type":"text","value":" is still the largest after softmax, and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"TzwNyWe6td"},{"type":"text","value":"-1.0","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"T65nEo89gR"},{"type":"text","value":" is still the lowest), this is because softmax is a ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Shjt6uH2Au"},{"type":"link","url":"https://en.wikipedia.org/wiki/Monotonic_function","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"monotonic function","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zTgDUd22Uz"}],"urlSource":"https://en.wikipedia.org/wiki/Monotonic_function","data":{"page":"Monotonic_function","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"rXHPFBUQt1"}],"key":"CCh1o8FUip"}],"key":"xlJCWax008"}],"key":"hLQNxarddw"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"This satisfies all the desired properties of an attention scores. Thus, we can compute the attention score for the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"x5oe6PyN4Y"},{"type":"inlineMath","value":"ith","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"v8FdfiBT1x"},{"type":"text","value":" key-value pair with:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"lmRu92pfqo"}],"key":"XS8L2uAP7D"},{"type":"math","value":"a_i = \\text{softmax}(x)_i = \\text{softmax}(\\textbf{q} \\textbf{K}^T)_i","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmsub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmsub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ea_i = \\text{softmax}(x)_i = \\text{softmax}(\\textbf{q} \\textbf{K}^T)_i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.1673em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"14","key":"WBxi1pGO7P"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Plugging this into our weighted sum we get:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"c8icznmERP"}],"key":"Jm66clLLah"},{"type":"math","value":"\\sum_{i} a_i v_i = \\sum_{i} \\text{softmax}(\\textbf{x})_i v_i = \\sum_{i} \\text{softmax}(\\textbf{q} \\textbf{K}^T)_i v_i = \\text{softmax}(\\textbf{q} \\textbf{K}^T) \\textbf{v}","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/munder\u003e\u003cmsub\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/munder\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003ex\u003c/mtext\u003e\u003cmsub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/munder\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmsub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sum_{i} a_i v_i = \\sum_{i} \\text{softmax}(\\textbf{x})_i v_i = \\sum_{i} \\text{softmax}(\\textbf{q} \\textbf{K}^T)_i v_i = \\text{softmax}(\\textbf{q} \\textbf{K}^T) \\textbf{v}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.3277em;vertical-align:-1.2777em;\"\u003e\u003c/span\u003e\u003cspan class=\"mop op-limits\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.05em;\"\u003e\u003cspan style=\"top:-1.8723em;margin-left:0em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan class=\"mop op-symbol large-op\"\u003e∑\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2777em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.3277em;vertical-align:-1.2777em;\"\u003e\u003c/span\u003e\u003cspan class=\"mop op-limits\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.05em;\"\u003e\u003cspan style=\"top:-1.8723em;margin-left:0em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan class=\"mop op-symbol large-op\"\u003e∑\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2777em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.3277em;vertical-align:-1.2777em;\"\u003e\u003c/span\u003e\u003cspan class=\"mop op-limits\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.05em;\"\u003e\u003cspan style=\"top:-1.8723em;margin-left:0em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3.05em;\"\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan class=\"mop op-symbol large-op\"\u003e∑\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.2777em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.1673em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"15","key":"MJyPihiFBG"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Note: In the last step, we pack our values into a vector ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"aG3yaw4wqs"},{"type":"inlineMath","value":"\\textbf{v} = [v_1, v_2, ..., v_{n_k - 1}, v_{n_k}]","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e[\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e.\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msub\u003e\u003cmo stretchy=\"false\"\u003e]\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\textbf{v} = [v_1, v_2, ..., v_{n_k - 1}, v_{n_k}]\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.0059em;vertical-align:-0.2559em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e...\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1512em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2559em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1512em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2559em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"NDvlOY8S1G"},{"type":"text","value":", which allows us to get rid of the summation notation in favor of a dot product. And that’s it, we have a full working definition for attention:","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"MzZIYBacYF"}],"key":"gPcg3bHGFM"},{"type":"math","value":"\\text{attention}(\\textbf{q}, K, \\textbf{v}) = \\text{softmax}(\\textbf{qK}^T)\\textbf{v}","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eqK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003ev\u003c/mtext\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(\\textbf{q}, K, \\textbf{v}) = \\text{softmax}(\\textbf{qK}^T)\\textbf{v}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.1673em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eqK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"16","key":"t6aClwhUaK"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"In code:","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"At0HkTKeU5"}],"key":"SmVGQy2wfo"}],"key":"CoKB3yiE1b"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def get_word_vector(word, d_k=8):\n    \"\"\"Hypothetical mapping that returns a word vector of size\n    d_k for the given word. For demonstrative purposes, we initialize\n    this vector randomly, but in practice this would come from a learned\n    embedding or some kind of latent representation.\"\"\"\n    return np.random.normal(size=(d_k,))\n\n\ndef attention(q, K, v):\n    # assumes q is a vector of shape (d_k)\n    # assumes K is a matrix of shape (n_k, d_k)\n    # assumes v is a vector of shape (n_k)\n    return softmax(q @ K.T) @ v\n\n\ndef kv_lookup(query, keys, values):\n    return attention(\n        q=get_word_vector(query),\n        K=np.array([get_word_vector(key) for key in keys]),\n        v=values,\n    )\n\n\n# returns some float number\nprint(kv_lookup(\"fruit\", [\"apple\", \"banana\", \"chair\"], [10, 5, 2]))","key":"yutuSxjMkv"},{"type":"outputs","id":"p7thC6R3qzu8PNvaU4zbi","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"6.589311199486881\n"},"children":[],"key":"PcOOVeKtwR"}],"key":"qooFCSb28F"}],"key":"oNGQyEbNKy"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":5,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Scaled Dot Product Attention","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dfa0djtjlf"}],"identifier":"scaled-dot-product-attention","label":"Scaled Dot Product Attention","html_id":"scaled-dot-product-attention","implicit":true,"key":"JQuwbGds7Q"}],"key":"MtdIkR5qXo"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In principle, the attention equation we derived in the last section is complete. However, we’ll need to make a couple of changes to match the version in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Czog5grkze"},{"type":"link","url":"https://arxiv.org/pdf/1706.03762.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Attention is All You Need","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eaPrO8PJYn"}],"urlSource":"https://arxiv.org/pdf/1706.03762.pdf","key":"AQnODW6eyG"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h9blceISN0"}],"key":"LNWS1Lis41"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Values as Vectors","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"l9z15TxrRI"}],"key":"V0VQAGXsa4"}],"key":"FSyjp68Tf4"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Currently, our values in the key-value pairs are just numbers. However, we could also instead replace them with vectors of some size ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YJa9WdsMq5"},{"type":"inlineMath","value":"d_v","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ed_v\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"yqrHH19ieb"},{"type":"text","value":". For example, with ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"TZ8A2AMZPH"},{"type":"inlineMath","value":"d_v = 4","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ed_v = 4\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"e6MCtYIpEA"},{"type":"text","value":", you might have:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"l87zUVUUva"}],"key":"BULam0HZcQ"},{"type":"code","lang":"python","value":"d = {\n    \"apple\": [0.9, 0.2, -0.5, 1.0]\n    \"banana\": [1.2, 2.0, 0.1, 0.2]\n    \"chair\": [-1.2, -2.0, 1.0, -0.2]\n}","position":{"start":{"line":7,"column":1},"end":{"line":13,"column":1}},"key":"AJz0lPvkye"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"When we compute our output via a weighted sum, we’d be doing a weighted sum over vectors instead of numbers (i.e. scalar-vector multiplication instead of scalar-scalar multiplication). This is desirable because vectors let us hold/convey more information than just a single number. To adjust for this change in our equation, instead of multiplying our attention scores by a vector ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"C9WChLyGBo"},{"type":"inlineMath","value":"v","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ev\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"CNaXeId0KV"},{"type":"text","value":", we multiply it by the row-wise matrix of our value vectors ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"nowhFPPivn"},{"type":"inlineMath","value":"V","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eV\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"GygtmUpMjw"},{"type":"text","value":" (similar to how we stacked our keys to form ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Co3kYH54q3"},{"type":"inlineMath","value":"K","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eK\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eK\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"isndmMeTp2"},{"type":"text","value":"):","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"cy5jQfcz2d"}],"key":"k8jK7mn7BK"},{"type":"math","value":"\\text{attention}(\\textbf{q}, K, V) = \\text{softmax}(\\textbf{qK}^T)V","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eqK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(\\textbf{q}, K, V) = \\text{softmax}(\\textbf{qK}^T)V\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.1673em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eqK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"17","key":"n4CPFDBnBo"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Of course, our output is no longer a scalar, instead it would be a vector of dimensionality ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"xCY29A0Hj1"},{"type":"inlineMath","value":"d_v","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ed_v\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"oro1RCrQka"},{"type":"text","value":".","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"JFAA4XUxUy"}],"key":"PTyWpUWFVT"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"strong","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Scaling","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"be9FZc7Mk0"}],"key":"yQtNTLbkcK"}],"key":"E7ItmcIDkb"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"The dot product between our query and keys can get really large in magnitude if ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"l0HlVzuWeQ"},{"type":"inlineMath","value":"d_k","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ed_k\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"YzzZ3inuAD"},{"type":"text","value":" is large. This makes the output of softmax more ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"LFxPScGqsO"},{"type":"emphasis","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"extreme","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"NaBrqGCB04"}],"key":"EwRY0vwfzg"},{"type":"text","value":". For example, ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"SNs8BgZfpg"},{"type":"inlineCode","value":"softmax([3, 2, 1]) = [0.665, 0.244, 0.090]","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"bn1tPsNHfJ"},{"type":"text","value":", but with larger values ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"DClllyuQOF"},{"type":"inlineCode","value":"softmax([30, 20, 10]) = [9.99954600e-01, 4.53978686e-05, 2.06106005e-09]","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"Iqq146qI1M"},{"type":"text","value":". When training a ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"Kf9en4T53B"},{"type":"strong","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"m3excaBqZA"}],"key":"xKFz8nZoDy"},{"type":"text","value":", this would mean the gradients would become really small which is undesirable. As a solution, we scale our pre-softmax scores by ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"PxsjLIh2cI"},{"type":"inlineMath","value":"\\frac{1}{\\sqrt{d_k}}","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmfrac\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmsqrt\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msqrt\u003e\u003c/mfrac\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\frac{1}{\\sqrt{d_k}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1.3831em;vertical-align:-0.538em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8451em;\"\u003e\u003cspan style=\"top:-2.5864em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord sqrt mtight\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8622em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mtight\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3448em;\"\u003e\u003cspan style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1512em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8222em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1778em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.394em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.538em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"nCZFtVrR9H"},{"type":"text","value":":","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"LGPqzAIwJH"}],"key":"mYAc6d7GhC"},{"type":"math","value":"\\text{attention}(\\textbf{q}, K, V) = \\text{softmax}(\\frac{\\textbf{qK}^T}{\\sqrt{d_k}})V","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmtext mathvariant=\"bold\"\u003eq\u003c/mtext\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmfrac\u003e\u003cmsup\u003e\u003cmtext mathvariant=\"bold\"\u003eqK\u003c/mtext\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003cmsqrt\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msqrt\u003e\u003c/mfrac\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(\\textbf{q}, K, V) = \\text{softmax}(\\frac{\\textbf{qK}^T}{\\sqrt{d_k}})V\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.5243em;vertical-align:-0.93em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.5943em;\"\u003e\u003cspan style=\"top:-2.2528em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8572em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8172em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1828em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord textbf\"\u003eqK\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9173em;\"\u003e\u003cspan style=\"top:-3.139em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.93em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"18","key":"mL5fnsXTNU"},{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Multiple Queries","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"NZ9AQnJRr6"}],"key":"p65pdsTVm9"}],"key":"GkmnLjfmO8"},{"type":"paragraph","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"In practice, we often want to perform multiple lookups for ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"XV03rLACDU"},{"type":"inlineMath","value":"n_q","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003eq\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en_q\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7167em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"vUO6Az4rgs"},{"type":"text","value":" different queries rather than just a single query. Of course, we could always do this one at a time, plugging each query individually into the above equation. However, if we stack of query vectors row-wise as a matrix ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"G0lVlnuqq7"},{"type":"inlineMath","value":"Q","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eQ\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"BdiTXINqC8"},{"type":"text","value":" (in the same way we did for ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"fAllrEJoqn"},{"type":"inlineMath","value":"K","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eK\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eK\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"F77DDdf5at"},{"type":"text","value":" and ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"NuSS3i2j2d"},{"type":"inlineMath","value":"V","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eV\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ruKlrcgwMh"},{"type":"text","value":"), we can compute our output as an ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"yqt62YUKZk"},{"type":"inlineMath","value":"n_q \\times d_v","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003en\u003c/mi\u003e\u003cmi\u003eq\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ev\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003en_q \\times d_v\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8694em;vertical-align:-0.2861em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003en\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003eq\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2861em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1514em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"zKfvE5Ntdr"},{"type":"text","value":" matrix where row ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"CN9qca23zX"},{"type":"inlineMath","value":"i","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ei\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6595em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"NhxnizDERy"},{"type":"text","value":" is the output vector for the attention on the ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"PMyLcFmkdW"},{"type":"inlineMath","value":"ith","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eith\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"sx90G8WJCh"},{"type":"text","value":" query:","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"QBChrwpvPP"}],"key":"M8X1GrDfSr"},{"type":"math","value":"\\text{attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmfrac\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cmsqrt\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msqrt\u003e\u003c/mfrac\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.4483em;vertical-align:-0.93em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.5183em;\"\u003e\u003cspan style=\"top:-2.2528em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8572em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8172em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1828em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8413em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.93em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"19","key":"pSFuybg4ZD"},{"type":"paragraph","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"that is, ","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"UG7gd5jZyy"}],"key":"Ng8bEoTobx"},{"type":"math","value":"\\text{attention}(Q, K, V)_i = \\text{attention}(q_i, K, V)","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"tight":"before","html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmsub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003eq\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(Q, K, V)_i = \\text{attention}(q_i, K, V)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eq\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"20","key":"okM0bOQYef"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"This makes computation faster than if we ran attention for each query sequentially (say, in a for loop) since we can parallelize calculations (particularly when using a GPU). Note, our input to softmax becomes a matrix instead of a vector. When we write softmax here, we mean that we are taking the softmax along each row of the matrix independently, as if we were doing things sequentially.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"ny1RJqht8x"}],"key":"NwuAT6SxJo"},{"type":"paragraph","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Result","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"DYhb7euQlA"}],"key":"w9uJlaptfF"}],"key":"aUGumh0v2I"},{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"With that, we have our final equation for scaled dot product attention as it’s written in the ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"KoqQiShxgh"},{"type":"link","url":"https://arxiv.org/pdf/1706.03762.pdf","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"original transformer paper","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"nGDnz5P4za"}],"urlSource":"https://arxiv.org/pdf/1706.03762.pdf","key":"qqhm5Aco8a"},{"type":"text","value":":","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"e4BTeilUdf"}],"key":"K9TDGtCMiv"},{"type":"math","value":"\\text{attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003eattention\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmfrac\u003e\u003cmrow\u003e\u003cmi\u003eQ\u003c/mi\u003e\u003cmsup\u003e\u003cmi\u003eK\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cmsqrt\u003e\u003cmsub\u003e\u003cmi\u003ed\u003c/mi\u003e\u003cmi\u003ek\u003c/mi\u003e\u003c/msub\u003e\u003c/msqrt\u003e\u003c/mfrac\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eV\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003eattention\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.4483em;vertical-align:-0.93em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.5183em;\"\u003e\u003cspan style=\"top:-2.2528em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord sqrt\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8572em;\"\u003e\u003cspan class=\"svg-align\" style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\" style=\"padding-left:0.833em;\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ed\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3361em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\"\u003ek\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-2.8172em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'\u003e\u003cpath d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.1828em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eQ\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eK\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.8413em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.93em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"21","key":"QXuz4wWBzt"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"In code:","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"T6VIvaQ7tP"}],"key":"NRvrZlAxgf"}],"key":"StB90l1HO4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def attention(q, k, v):  # [n_q, d_k], [n_k, d_k], [n_k, d_v] -\u003e [n_q, d_v]\n    # assumes q is a matrix of shape [n_q, d_k]\n    # assumes k is a matrix of shape [n_k, d_k]\n    # assumes v is a matrix of shape [n_k, d_v]\n    # output is a matrix of shape [n_q, d_v]\n    d_k = k.shape[-1]\n    return softmax(q @ k.T / np.sqrt(d_k)) @ v","key":"xEG1OP0M5d"},{"type":"outputs","id":"pwnHRNLY0vDuIfXmQPn31","children":[],"key":"lA2LNuJCIQ"}],"key":"FAnNXJT6wH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Self","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zoFal5m9pK"}],"identifier":"self","label":"Self","html_id":"self","implicit":true,"key":"TP9GIAr6sR"}],"key":"AFlOTWmDz5"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"When ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mjXH7Krqjw"},{"type":"inlineCode","value":"q","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N0aBcPHvKy"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qE26pMi8Gi"},{"type":"inlineCode","value":"k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sqHdXoHCGA"},{"type":"text","value":", and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h5B6eC8D2Z"},{"type":"inlineCode","value":"v","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"btB0hE3NXp"},{"type":"text","value":" all come from the same source, we are performing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Hwsw1scxq9"},{"type":"link","url":"https://lilianweng.github.io/posts/2018-06-24-attention/#self-attention","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"self-attention","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"S4u9WKLTNU"}],"urlSource":"https://lilianweng.github.io/posts/2018-06-24-attention/#self-attention","key":"zmd0Md8HpH"},{"type":"text","value":" (i.e. letting our input sequence attend to itself):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MmE2sKMNWM"}],"key":"jK8uyCcdJx"}],"key":"iWa1aJUpBt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def self_attention(x):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    return attention(q=x, k=x, v=x)","key":"llxWUgiVac"},{"type":"outputs","id":"iDy8hN4yczsRTlJOhq12b","children":[],"key":"ii7Eh6jySu"}],"key":"FNEXtaoYxA"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For example, if our input is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rWDL6EAmkM"},{"type":"inlineCode","value":"Jay went to the store, he bought 10 apples.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yDBog38F82"},{"type":"text","value":", we would be letting the word ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EaSFm92mNq"},{"type":"inlineCode","value":"he","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Deu344J4uc"},{"type":"text","value":" attend to all the other words, including ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pRb50q6uOa"},{"type":"inlineCode","value":"Jay","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cPnAycgilt"},{"type":"text","value":", meaning the model can learn to recognize that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EJsBRhxyg8"},{"type":"inlineCode","value":"he","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IDrFyib7Ik"},{"type":"text","value":" is referring to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hoTNuCLtW3"},{"type":"inlineCode","value":"Jay","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IJoNEP5dmu"},{"type":"text","value":". We can enhance self attention by introducing projections for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"la4DTxLDpG"},{"type":"inlineCode","value":"q","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k5wWoeZrNG"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YGGaeM7JKY"},{"type":"inlineCode","value":"k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KRACgVXvOa"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GO13GpnfQm"},{"type":"inlineCode","value":"v","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PoixfiD5Ri"},{"type":"text","value":" and the attention output:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QkwSgdR9PB"}],"key":"eoWBcmL8mr"}],"key":"uNKZOy2xYw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def self_attention(x, w_k, w_q, w_v, w_proj):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # qkv projections\n    q = x @ w_q  # [n_seq, n_embd] @ [n_embd, n_embd] -\u003e [n_seq, n_embd]\n    k = x @ w_k  # [n_seq, n_embd] @ [n_embd, n_embd] -\u003e [n_seq, n_embd]\n    v = x @ w_v  # [n_seq, n_embd] @ [n_embd, n_embd] -\u003e [n_seq, n_embd]\n\n    # perform self attention\n    x = attention(q, k, v)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n\n    # out projection\n    x = x @ w_proj  # [n_seq, n_embd] @ [n_embd, n_embd] -\u003e [n_seq, n_embd]\n\n    return x","key":"fvhP0DxAlZ"},{"type":"outputs","id":"eAie5PZbsUxWzHSuF4MI5","children":[],"key":"cOVNpyD4oS"}],"key":"ANjlfxmLNr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This enables our model to learn a mapping for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gTkdiX93Or"},{"type":"inlineCode","value":"q","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kvMn6CVUaa"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xVmAiL7XL1"},{"type":"inlineCode","value":"k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IiU2TjysHe"},{"type":"text","value":", and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aPmG4A7q6l"},{"type":"inlineCode","value":"v","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u4kTxJP2wa"},{"type":"text","value":" that best helps attention distinguish relationships between inputs. We can reduce the number of matrix multiplication from ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xk3BQOVPlS"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MiSzWkFSzP"},{"type":"text","value":" to just ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m42tgKtBf4"},{"type":"text","value":"2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dixk1peQ1r"},{"type":"text","value":" if we combine ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U8mzwUELIQ"},{"type":"inlineCode","value":"w_q","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xe8LIufaaG"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KGTKbx82Mz"},{"type":"inlineCode","value":"w_k","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"A2O2UB5APU"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nHMI83iV7E"},{"type":"inlineCode","value":"w_v","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GcjWfLBI6A"},{"type":"text","value":" into a single matrix ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hM2rNycZDk"},{"type":"inlineCode","value":"w_fc","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kgAYPJyHpG"},{"type":"text","value":", perform the projection, and then split the result:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"W9kqGsMi5H"}],"key":"NMPyWHq0I0"}],"key":"PXIxvGnvnT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def self_attention(x, w_fc, w_proj):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # qkv projections\n    x = x @ w_fc  # [n_seq, n_embd] @ [n_embd, 3*n_embd] -\u003e [n_seq, 3*n_embd]\n\n    # split into qkv\n    q, k, v = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -\u003e 3 of [n_seq, n_embd]\n\n    # perform self attention\n    x = attention(q, k, v)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n\n    # out projection\n    x = x @ w_proj  # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]\n\n    return x","key":"YNZ0ZpW98K"},{"type":"outputs","id":"-hFzuioPTK_IJvJ9MAgeY","children":[],"key":"jzt2BQ6iXc"}],"key":"pC5mDozbRW"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This is a bit more efficient as modern accelerators (GPUs) can take better advantage of one large matrix multiplication rather than ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TrU8f709g7"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dltFZwUSvi"},{"type":"text","value":" separate small ones happening sequentially. Finally, we add bias vectors to match the implementation of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jM4WIgj0Xz"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kPb0IqgIhj"}],"key":"iBxP5rd49K"},{"type":"text","value":"-2, use our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mpLUPaeMqM"},{"type":"inlineCode","value":"linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C1zTGpPNoc"},{"type":"text","value":" function, and rename our parameters to match our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"imO7FdG0SY"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wwSKukXBNg"},{"type":"text","value":" dictionary:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IC8WfY2Tve"}],"key":"KbEw3GqFBo"}],"key":"TQMpRcHBRx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def self_attention(x, c_attn, c_proj):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # qkv projections\n    x = linear(x, **c_attn)  # [n_seq, n_embd] -\u003e [n_seq, 3*n_embd]\n\n    # split into qkv\n    q, k, v = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -\u003e 3 of [n_seq, n_embd]\n\n    # perform self attention\n    x = attention(q, k, v)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n\n    # out projection\n    x = linear(x, **c_proj)  # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]\n\n    return x","key":"fagzC5i0qj"},{"type":"outputs","id":"Eu9_Cq_S3sZiA0UMjUAZj","children":[],"key":"nhmGDGHU3l"}],"key":"c2Pa321b96"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Recall, from our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bj1mNfkarE"},{"type":"inlineCode","value":"params","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HKuNCdOt8l"},{"type":"text","value":" dictionary, our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TXv6ZbDrAh"},{"type":"inlineCode","value":"attn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ShJxMupXNv"},{"type":"text","value":" params look like this:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HvQZvvrjc9"}],"key":"Kz2XWi2RGk"},{"type":"code","lang":"python","value":"\"attn\": {\n    \"c_attn\": {\"b\": [3*n_embd], \"w\": [n_embd, 3*n_embd]},\n    \"c_proj\": {\"b\": [n_embd], \"w\": [n_embd, n_embd]},\n},","position":{"start":{"line":3,"column":1},"end":{"line":8,"column":1}},"key":"B83xXZA382"}],"key":"QNSd3kEau7"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Causal","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ptVD0WNAZn"}],"identifier":"causal","label":"Causal","html_id":"causal","implicit":true,"key":"P9vISfa8EB"}],"key":"oHoHslKAEO"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"There is a bit of an issue with our current self-attention setup, our inputs can see into the future! For example, if our input is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U2zAapgICP"},{"type":"inlineCode","value":"[\"not\", \"all\", \"heroes\", \"wear\", \"capes\"]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wIQwzmDyRN"},{"type":"text","value":", during self attention we are allowing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZBENGfhtFq"},{"type":"inlineCode","value":"\"wear\"","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZavF4uhzuX"},{"type":"text","value":" to see ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ssbVyzWzyL"},{"type":"inlineCode","value":"\"capes\"","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cvr3pQDgsD"},{"type":"text","value":". This means our output probabilities for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DYl45vriCE"},{"type":"inlineCode","value":"\"wear\"","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WbYr7EXblY"},{"type":"text","value":" will be biased since the model already knows the correct answer is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WLjRHtWoRQ"},{"type":"inlineCode","value":"\"capes\"","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IEHZ70MUy4"},{"type":"text","value":". This is no good since our model will just learn that the correct answer for input ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SLyFgsj43q"},{"type":"inlineMath","value":"i","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ei\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6595em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Nc4iFFqK1V"},{"type":"text","value":" can be taken from input ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UvqL1UWuOH"},{"type":"inlineMath","value":"i+1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo\u003e+\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ei+1\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7429em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e+\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"PX2QI9y06J"},{"type":"text","value":". To prevent this, we need to somehow modify our attention matrix to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LOOjdOStO8"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"hide","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OUQ4F3PiUb"}],"key":"A54R1vtW32"},{"type":"text","value":" or ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pgK2Rf2Rjz"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"mask","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cyIN6MWId4"}],"key":"ookWl9kRvu"},{"type":"text","value":" our inputs from being able to see into the future. For example, let’s pretend our attention matrix looks like this:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IzvVn5jn4s"}],"key":"aAAeJA0eGm"},{"type":"code","lang":"js","value":"       not    all    heroes wear   capes\n   not 0.116  0.159  0.055  0.226  0.443\n   all 0.180  0.397  0.142  0.106  0.175\nheroes 0.156  0.453  0.028  0.129  0.234\n  wear 0.499  0.055  0.133  0.017  0.295\n capes 0.089  0.290  0.240  0.228  0.153","position":{"start":{"line":3,"column":1},"end":{"line":10,"column":1}},"key":"YZLmL2qyWu"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Each row corresponds to a query and the columns to a key. In this case, looking at the row for ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"ASOWqsFNCx"},{"type":"inlineCode","value":"wear","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"dT88STW2QN"},{"type":"text","value":", you can see that it is attending to ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"k0QLZkijY3"},{"type":"inlineCode","value":"capes","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"hOlVzCPmjG"},{"type":"text","value":" in the last column with a weight of ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"LTPoMqoLoq"},{"type":"text","value":"0.295","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"vImknH9Cav"},{"type":"text","value":". To prevent this, we want to set that entry to ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Obscdnsule"},{"type":"text","value":"0.000","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Qq6l9bzrL7"},{"type":"text","value":":","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"R0pXiOfIBS"}],"key":"ukjwQUCZ3z"},{"type":"code","lang":"js","value":"        not    all    heroes wear   capes\n   not 0.116  0.159  0.055  0.226  0.443\n   all 0.180  0.397  0.142  0.106  0.175\nheroes 0.156  0.453  0.028  0.129  0.234\n  wear 0.499  0.055  0.133  0.017  0.000\n capes 0.089  0.290  0.240  0.228  0.153","position":{"start":{"line":14,"column":1},"end":{"line":21,"column":1}},"key":"XpGujjrncq"},{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"In general, to prevent all the queries in our input from looking into the future, we set all positions ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"LwWqaDYxlq"},{"type":"inlineMath","value":"i, j","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ei, j\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.854em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"IsWHsyPFhf"},{"type":"text","value":" where ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"qoFcBU7ngY"},{"type":"inlineMath","value":"j \u003e i","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo\u003e\u0026gt;\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ej \u0026gt; i\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.854em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e\u0026gt;\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6595em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"NZbmlIHF1J"},{"type":"text","value":" to ","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"yrkJIui4ca"},{"type":"text","value":"0.000","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"ksmJl7Da2g"},{"type":"text","value":":","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"ASrLZonJlD"}],"key":"j6oRIUQSIr"},{"type":"code","lang":"js","value":"        not    all    heroes wear   capes\n   not 0.116  0.000  0.000  0.000  0.000\n   all 0.180  0.397  0.000  0.000  0.000\nheroes 0.156  0.453  0.028  0.000  0.000\n  wear 0.499  0.055  0.133  0.017  0.000\n capes 0.089  0.290  0.240  0.228  0.153","position":{"start":{"line":25,"column":1},"end":{"line":32,"column":1}},"key":"igcNk3XVle"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"We call this ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"YrPLQeiHtg"},{"type":"strong","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"masking","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"lgmRQtR5Lr"}],"key":"RzLCCXG9Rt"},{"type":"text","value":". One issue with our above ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"YxfUf71huq"},{"type":"strong","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"masking","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"jiPxoT8zsc"}],"key":"LIVJ8c947E"},{"type":"text","value":" approach is our rows no longer sum to ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"RGK6WznQ7m"},{"type":"text","value":"1","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"FKidUrQcXv"},{"type":"text","value":" (since we are setting them to ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"H96A3Qh89N"},{"type":"text","value":"0","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"iiW5uPkXB1"},{"type":"text","value":" after the ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"Xm4jggHVS2"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"WAIpBDtd41"},{"type":"text","value":" has been applied). To make sure our rows still sum to ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"F0gSJCQyL4"},{"type":"text","value":"1","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"WAtltTylod"},{"type":"text","value":", we need to modify our attention matrix before the ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"LY6PtkjO2i"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"jCQwnVhX8k"},{"type":"text","value":" is applied. This can be achieved by setting entries that are to be masked to ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"IYei3r1v9x"},{"type":"inlineMath","value":"-\\infty","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmi mathvariant=\"normal\"\u003e∞\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e-\\infty\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e−\u003c/span\u003e\u003cspan class=\"mord\"\u003e∞\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"VxfJLUWYhI"},{"type":"text","value":" prior to the ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"jAw3NjEJuY"},{"type":"inlineCode","value":"softmax","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"DHIcYBl76N"},{"type":"text","value":".","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"UhY1bkxend"}],"key":"lvtAvEFINM"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"LZ3q0ZKEpP"}],"key":"nfEZ1Nljfx"},{"type":"text","value":": If you’re not convinced, stare at the softmax equation and convince yourself this is true (maybe even pull out a pen and paper):","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"Wp5i4wunVf"}],"key":"gsBmDHXAdj"},{"type":"math","value":"\\text{softmax}(\\vec{x})_{i} = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"html":"\u003cspan class=\"katex-display\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmtext\u003esoftmax\u003c/mtext\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmover accent=\"true\"\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmo\u003e⃗\u003c/mo\u003e\u003c/mover\u003e\u003cmsub\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmfrac\u003e\u003cmsup\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ei\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003cmrow\u003e\u003cmunder\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/munder\u003e\u003cmsup\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/msub\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003c/mfrac\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\text{softmax}(\\vec{x})_{i} = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord text\"\u003e\u003cspan class=\"mord\"\u003esoftmax\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.714em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body\" style=\"left:-0.2077em;\"\u003e\u003cspan class=\"overlay\" style=\"height:0.714em;width:0.471em;\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'\u003e\u003cpath d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z'/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose\"\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3117em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:2.4632em;vertical-align:-1.1218em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mopen nulldelimiter\"\u003e\u003c/span\u003e\u003cspan class=\"mfrac\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.3414em;\"\u003e\u003cspan style=\"top:-2.314em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mop\"\u003e\u003cspan class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\"\u003e∑\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.162em;\"\u003e\u003cspan style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.4358em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.6065em;\"\u003e\u003cspan style=\"top:-3.0051em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3281em;\"\u003e\u003cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\"\u003ej\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2819em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.23em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"frac-line\" style=\"border-bottom-width:0.04em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.677em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.6644em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ex\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3281em;\"\u003e\u003cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.5em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size3 size1 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003ei\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.143em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:1.1218em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mclose nulldelimiter\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","enumerator":"22","key":"R3SNMJeZiY"}],"key":"GQ8RoBbY50"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def attention(\n    q, k, v, mask\n):  # [n_q, d_k], [n_k, d_k], [n_k, d_v], [n_q, n_k] -\u003e [n_q, d_v]\n    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v","key":"A2zMXhBUwF"},{"type":"outputs","id":"bygcNm4FNDX3E7jgY6TMw","children":[],"key":"EXOwQTuUIS"}],"key":"UhtOdjE2r3"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G34xTprKbd"},{"type":"inlineCode","value":"mask","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UALeZLMA4X"},{"type":"text","value":" is the matrix (for ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vcvcjzDPGG"},{"type":"inlineCode","value":"n_seq=5","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fUzt9YaAKY"},{"type":"text","value":"):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wOzFIaCOnU"}],"key":"cautdcKVD4"},{"type":"code","lang":"python","value":"0 -1e10 -1e10 -1e10 -1e10\n0   0   -1e10 -1e10 -1e10\n0   0     0   -1e10 -1e10\n0   0     0     0   -1e10\n0   0     0     0     0","position":{"start":{"line":3,"column":1},"end":{"line":9,"column":1}},"key":"WKLYBM45zT"}],"key":"BCM9QA9sE7"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We use ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e1fWyfmAvq"},{"type":"inlineCode","value":"-1e10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NQuRNKPeBX"},{"type":"text","value":" instead of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mGNlonei8d"},{"type":"inlineCode","value":"-np.inf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iDITshfTRy"},{"type":"text","value":" as ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Beb7cM8maK"},{"type":"inlineCode","value":"-np.inf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AQltCfYHYT"},{"type":"text","value":" can cause ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ieJIwPgfDa"},{"type":"inlineCode","value":"nan","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wHwEVEdlgU"},{"type":"text","value":"s. Adding ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AY5dg1wmxR"},{"type":"inlineCode","value":"mask","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ADSaLHLHqR"},{"type":"text","value":" to our attention matrix instead of just explicitly setting the values to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Sbn8cPrZn8"},{"type":"inlineCode","value":"-1e10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SER4Uo5i5C"},{"type":"text","value":" works because practically, any number plus ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uAyrFDs6am"},{"type":"inlineCode","value":"-inf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Pswnsk4m7L"},{"type":"text","value":" is just ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r9L2ZlN9iA"},{"type":"inlineCode","value":"-inf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"x4dR9p3QQy"},{"type":"text","value":". We can compute the mask matrix in NumPy with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CDWxVgLLG4"},{"type":"inlineCode","value":"(1 - np.tri(n_seq)) * -1e10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h9MkHx3Zmi"},{"type":"text","value":". Putting it all together, we get:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Iu12wcnmCP"}],"key":"EjKa38i0On"}],"key":"GLdsA4Ubmn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def attention(\n    q, k, v, mask\n):  # [n_q, d_k], [n_k, d_k], [n_k, d_v], [n_q, n_k] -\u003e [n_q, d_v]\n    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v\n\n\ndef causal_self_attention(x, c_attn, c_proj):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # qkv projections\n    x = linear(x, **c_attn)  # [n_seq, n_embd] -\u003e [n_seq, 3*n_embd]\n\n    # split into qkv\n    q, k, v = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -\u003e 3 of [n_seq, n_embd]\n\n    # causal mask to hide future inputs from being attended to\n    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]\n\n    # perform causal self attention\n    x = attention(q, k, v, causal_mask)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n\n    # out projection\n    x = linear(x, **c_proj)  # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]\n\n    return x","key":"Al0Dn3CR0v"},{"type":"outputs","id":"2vmbwLcq_cNjN_b56f_Ls","children":[],"key":"f8zKOcNmzy"}],"key":"zPW7aJ1Ue8"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multi-Head","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lJu7nGxSTj"}],"identifier":"multi-head","label":"Multi-Head","html_id":"multi-head","implicit":true,"key":"dt1ihakYxf"}],"key":"jiFasNvRVw"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can further improve our implementation by performing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fMnwPvY8xE"},{"type":"inlineCode","value":"n_head","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Mk7UnD5iMw"},{"type":"text","value":" separate attention computations, splitting our queries, keys, and values into heads:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xaCanGDY9E"}],"key":"SII93DTagi"}],"key":"eulR3RaXwj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def mha(x, c_attn, c_proj, n_head):  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n    # qkv projection\n    x = linear(x, **c_attn)  # [n_seq, n_embd] -\u003e [n_seq, 3*n_embd]\n\n    # split into qkv\n    qkv = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -\u003e [3, n_seq, n_embd]\n\n    # split into heads\n    qkv_heads = list(\n        map(lambda x: np.split(x, n_head, axis=-1), qkv)\n    )  # [3, n_seq, n_embd] -\u003e [3, n_head, n_seq, n_embd/n_head]\n\n    # causal mask to hide future inputs from being attended to\n    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]\n\n    # perform attention over each head\n    out_heads = [\n        attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)\n    ]  # [3, n_head, n_seq, n_embd/n_head] -\u003e [n_head, n_seq, n_embd/n_head]\n\n    # merge heads\n    x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -\u003e [n_seq, n_embd]\n\n    # out projection\n    x = linear(x, **c_proj)  # [n_seq, n_embd] -\u003e [n_seq, n_embd]\n\n    return x","key":"Un6arhLY11"},{"type":"outputs","id":"FLWQZfyEQVEhw6adVkzFe","children":[],"key":"C4UTFKbbrH"}],"key":"keXnPhKPzq"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"There are three steps added here:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ph1NsxEauc"}],"key":"V5utBFSIAx"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Split ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"M02aeitev3"},{"type":"inlineCode","value":"q","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"CBdFmG9X7E"},{"type":"text","value":", ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"lDgeOCXOiZ"},{"type":"inlineCode","value":"k","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"KGfbHFtqbH"},{"type":"text","value":", ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"hz2fOVZCoq"},{"type":"inlineCode","value":"v","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"GnTmr7HKXW"},{"type":"text","value":" into ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"G14MR0OLXR"},{"type":"inlineCode","value":"n_head","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"LlLiAydFeM"},{"type":"text","value":" heads:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"iFYhxaPzOu"}],"key":"GxSkFLk5Gp"}],"key":"aySlAuTYvh"}],"key":"v5fwazyhfD"},{"type":"code","lang":"python","value":"# split into heads\nqkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), qkv))  # [3, n_seq, n_embd] -\u003e [n_head, 3, n_seq, n_embd/n_head]","position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"key":"fo0teTrWBD"},{"type":"list","ordered":true,"start":2,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Compute attention for each head:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"DMJpEqiu2O"}],"key":"W4XWTe2oBY"}],"key":"keLsQHaRW1"}],"key":"xLTDalwxyc"},{"type":"code","lang":"python","value":"# perform attention over each head\nout_heads = [attention(q, k, v) for q, k, v in zip(*qkv_heads)]  # [n_head, 3, n_seq, n_embd/n_head] -\u003e [n_head, n_seq, n_embd/n_head]","position":{"start":{"line":11,"column":1},"end":{"line":14,"column":1}},"key":"EK4XPREehk"},{"type":"list","ordered":true,"start":3,"spread":false,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Merge the outputs of each head:","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"uQLAtWu4yn"}],"key":"cHM0ykMxnc"}],"key":"ahWC7A4ag4"}],"key":"VMqFkjj5gG"},{"type":"code","lang":"python","value":"# merge heads\nx = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -\u003e [n_seq, n_embd]","position":{"start":{"line":17,"column":1},"end":{"line":20,"column":1}},"key":"o0smwsqUAg"}],"key":"JQYr48PNmq"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Notice, this reduces the dimension from ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yqtPzqyXKs"},{"type":"inlineCode","value":"n_embd","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gSSWlzTBqh"},{"type":"text","value":" to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mScFTUrOI8"},{"type":"inlineCode","value":"n_embd/n_head","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Jxud7hFY9U"},{"type":"text","value":" for each attention computation. This is a tradeoff. For reduced dimensionality, our model gets additional subspaces to work when modeling relationships via attention. For example, maybe one attention head is responsible for connecting pronouns to the person the pronoun is referencing. Maybe another might be responsible for grouping sentences by periods. Another could simply be identifying which words are entities, and which are not. Although, it’s probably just another ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"P2vnHv41rN"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PwPlGT6dh1"}],"key":"pOCxJuZEfp"},{"type":"text","value":" black box. The code we wrote performs the attention computations over each head sequentially in a loop (one at a time), which is not very efficient. In practice, you’d want to do these in parallel. For simplicity, we’ll just leave this sequential. With that, we’re finally done our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CBC8UoleNq"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ah3KW4KmqO"}],"key":"yFTADZpdxG"},{"type":"text","value":" implementation! Now, all that’s left to do is put it all together and run our code.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EH788C2f8V"}],"key":"EqUONn4CKm"}],"key":"SzWA0OHZ48"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Putting it All Together","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l6AOtWUqMf"}],"identifier":"putting-it-all-together","label":"Putting it All Together","html_id":"putting-it-all-together","implicit":true,"key":"izR00zgyBU"}],"key":"LOXvwasyNM"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Having put everything together, we get the equivalent of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yoPWGVz1R0"},{"type":"link","url":"https://github.com/jaymody/picoGPT/blob/main/gpt2.py","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"gpt2.py","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TVhzfbzU4S"}],"urlSource":"https://github.com/jaymody/picoGPT/blob/main/gpt2.py","data":{"kind":"file","org":"jaymody","repo":"picoGPT","reference":"main","file":"gpt2.py","raw":"https://raw.githubusercontent.com/jaymody/picoGPT/main/gpt2.py"},"internal":false,"protocol":"github","key":"otf1Nhioe3"},{"type":"text","value":", which in its entirety is a mere ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ufYsSHn6sz"},{"type":"text","value":"120","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bjYkAjEd7D"},{"type":"text","value":" lines of code (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nNX9ipzST5"},{"type":"link","url":"https://github.com/jaymody/picoGPT/blob/a750c145ba4d09d5764806a6c78c71ffaff88e64/gpt2_pico.py#L3-L58","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"60","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gu3WQuKlHN"},{"type":"text","value":" lines if you remove comments and whitespace!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"A1h5D5v8Ax"}],"urlSource":"https://github.com/jaymody/picoGPT/blob/a750c145ba4d09d5764806a6c78c71ffaff88e64/gpt2_pico.py#L3-L58","data":{"kind":"file","org":"jaymody","repo":"picoGPT","reference":"a750c145ba4d09d5764806a6c78c71ffaff88e64","file":"gpt2_pico.py","from":3,"to":58,"raw":"https://raw.githubusercontent.com/jaymody/picoGPT/a750c145ba4d09d5764806a6c78c71ffaff88e64/gpt2_pico.py"},"internal":false,"protocol":"github","key":"wfjj6Ycw1t"},{"type":"text","value":"). All that remains, it to test our implementation by prompting our tiny ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PSY6wmIl0e"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"V1Iz3X2qgX"}],"key":"a78WvIslfI"},{"type":"text","value":"-2 model:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"i41lgIVFos"}],"key":"c7cvVraJqW"}],"key":"BKZ3A8G28b"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"output = prompt_gpt(\"Alan Turing theorized that computers would one day become\", n_tokens_to_generate=8)\nassert output == \" the most powerful machines on the planet.\"\nprint(output)","key":"W2ags3Ydy4"},{"type":"outputs","id":"gbwLNCzYZ4jFQ7SvVCWHq","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-02-18 12:27:30.196142: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\ngenerating: 100%|██████████| 8/8 [00:07\u003c00:00,  1.03it/s]"},"children":[],"key":"O9JEW3sqyw"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":" the most powerful machines on the planet.\n"},"children":[],"key":"jP990IP9kC"},{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"\n"},"children":[],"key":"AzARjAplZQ"}],"key":"BmFGQTnDm9"}],"key":"P4YHxysMEC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"It works! We can also test that our implementation gives identical results to OpenAI’s official ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Or0PbsAWkR"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"c1tggWJPDK"}],"key":"uqvVd2hwf2"},{"type":"text","value":"-2 repo by building and executing the Docker container as follows:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UG1eUTcTTL"}],"key":"g5X81JbqiX"},{"type":"code","lang":"bash","value":"docker build -t \"openai-gpt-2\" - \u003c\u003cEOF\nFROM tensorflow/tensorflow:1.13.2-py3\n\nENV DEBIAN_FRONTEND=noninteractive\nRUN apt update -y \u0026\u0026 apt upgrade -y \u0026\u0026 apt install git -y\n\nRUN git clone https://github.com/openai/gpt-2 /gpt-2\nWORKDIR /gpt-2\n\nRUN python3 -m pip install --upgrade pip \u0026\u0026 python3 -m pip install -r requirements.txt\nRUN python3 download_model.py 124M\nRUN python3 download_model.py 355M\nRUN python3 download_model.py 774M\nRUN python3 download_model.py 1558M\nEOF\n\ndocker run -dt --name \"openai-gpt-2-app\" openai-gpt-2\ndocker exec -it \"openai-gpt-2-app\" /bin/bash -c 'python3 src/interactive_conditional_samples.py --length 8 --model_type 124M --top_k 1'","position":{"start":{"line":3,"column":1},"end":{"line":22,"column":1}},"key":"e3WoCgeCnQ"},{"type":"paragraph","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"and then pasting the following when prompted:","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"baqetzv2Mc"}],"key":"lbXqKCtLhA"},{"type":"code","lang":"bash","value":"\"Alan Turing theorized that computers would one day become\"","position":{"start":{"line":26,"column":1},"end":{"line":28,"column":1}},"key":"L4CKunL9Py"}],"key":"c4QwSVPiha"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This should yield an identical result:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wIApfw12CF"}],"key":"zcAFyGcW4Z"},{"type":"code","lang":"","value":" the most powerful machines on the planet.","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"R9SRYVWesg"}],"key":"xuNwPghks3"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What Next?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JECN296zWM"}],"identifier":"what-next","label":"What Next?","html_id":"what-next","implicit":true,"key":"VErDQzMe6R"}],"key":"PgKuwbGKrE"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This implementation is cool and all, but it’s missing a ton of bells and whistles:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ENsIbwaJT8"}],"key":"cwWirkHmQD"}],"key":"VaNRlCSW1h"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPU/TPU Support","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sYXatWL2OA"}],"identifier":"gpu-tpu-support","label":"GPU/TPU Support","html_id":"gpu-tpu-support","implicit":true,"key":"iMqLMZwUJf"}],"key":"QWTYMZMBLh"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Replace NumPy with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YdKbQbT8AJ"},{"type":"link","url":"https://github.com/google/jax","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"JAX","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jjkzsvrild"}],"urlSource":"https://github.com/google/jax","error":true,"key":"ztal7tkU8L"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t2FW2bcJQf"}],"key":"srnIw9Davb"},{"type":"code","lang":"python","value":"import jax.numpy as np","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"UZoPSEXmfg"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"That’s it. You can now use the code with GPUs and even ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rlbZswr63V"},{"type":"link","url":"https://cloud.google.com/tpu/docs/system-architecture-tpu-vm","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"TPUs","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YBK7Ew711Y"}],"urlSource":"https://cloud.google.com/tpu/docs/system-architecture-tpu-vm","key":"DENo63B97E"},{"type":"text","value":"! Just make sure you ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"FdZAkVBiIZ"},{"type":"link","url":"https://github.com/google/jax#installation","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"install JAX correctly","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"m5v9m3lTeR"}],"urlSource":"https://github.com/google/jax#installation","error":true,"key":"Ed8Pa6qy3R"},{"type":"text","value":".","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Wqz7KNaDIj"}],"key":"mhWPMdEEuO"}],"key":"O0XrKr9OrG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Backprop","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bzWoVVHcvP"}],"key":"caa4VrpOSS"}],"identifier":"backprop","label":"Backprop","html_id":"backprop","implicit":true,"key":"mwI6LTLEfG"}],"key":"iSeS8htlJB"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Again, if we replace NumPy with JAX:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BK22X9zBCT"}],"key":"OS3DCQY623"},{"type":"code","lang":"python","value":"import jax.numpy as np","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"H1NZy7sF46"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Then computing the gradients is as easy as:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rRXSuOlIg2"}],"key":"iIjYi6rdiI"},{"type":"code","lang":"python","value":"def lm_loss(params, inputs, n_head) -\u003e float:\n    x, y = inputs[:-1], inputs[1:]\n    logits = gpt2(x, **params, n_head=n_head)\n    loss = np.mean(-log_softmax(logits)[y])\n    return loss\n\ngrads = jax.grad(lm_loss)(params, inputs, n_head)","position":{"start":{"line":9,"column":1},"end":{"line":17,"column":1}},"key":"XvN1FX6dsS"}],"key":"XOW5r9obmK"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Batching","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Sxo8JevnjL"}],"identifier":"batching","label":"Batching","html_id":"batching","implicit":true,"key":"uDy5mCvyWm"}],"key":"yEKzcK2yku"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Once again, if we replace NumPy with JAX:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sXdlq3R884"}],"key":"JXxH3UsHTC"},{"type":"code","lang":"python","value":"import jax.numpy as np","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"SMuI7vrG9x"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Then, making our ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Svq9HrO6hg"},{"type":"inlineCode","value":"gpt2","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"CIpuET7Z9D"},{"type":"text","value":" function batched is as easy as:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HweGVkkY49"}],"key":"UB8FZJn5Gg"},{"type":"code","lang":"python","value":"gpt2_batched = jax.vmap(gpt2, in_axes=[0, None, None, None, None, None])\ngpt2_batched(batched_inputs)  # [batch, seq_len] -\u003e [batch, seq_len, vocab]","position":{"start":{"line":9,"column":1},"end":{"line":12,"column":1}},"key":"pnx8rivl7d"}],"key":"PNYO3qu8WO"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"JAX test","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"s2VG8Yv6mw"}],"identifier":"jax-test","label":"JAX test","html_id":"jax-test","implicit":true,"key":"YqsQyzHWF4"}],"key":"gZjYsoU9wJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s verify that switching to JAX is indeed as easy as described:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D6vCpAcgW9"}],"key":"kNd8NjsaWo"}],"key":"llbexYhwaZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import jax.numpy as np\n\n# all references to np are now references to jax.numpy\noutput = prompt_gpt(\"Alan Turing theorized that computers would one day become\", n_tokens_to_generate=8)\nassert output == \" the most powerful machines on the planet.\"\nprint(output)","key":"EcQMXHZ1vo"},{"type":"outputs","id":"jHjjPi9AgMIDOyY6OhDV5","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-02-18 12:27:38.750777: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\ngenerating: 100%|██████████| 8/8 [00:10\u003c00:00,  1.30s/it]"},"children":[],"key":"gpcFKZU0zT"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":" the most powerful machines on the planet.\n"},"children":[],"key":"hX0OE5Uatr"},{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"\n"},"children":[],"key":"GN8CzujOp7"}],"key":"TBUiu1QL6l"}],"key":"d1GkPJWJbS"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Inference Optimization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"trwHPrqRBQ"}],"identifier":"inference-optimization","label":"Inference Optimization","html_id":"inference-optimization","implicit":true,"key":"A9qR4tfjOH"}],"key":"wQHjOMAaZx"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Our implementation is quite inefficient. The quickest and most impactful optimization you can make (outside of GPU + batching support) would be to implement a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GtyNQ1HyLw"},{"type":"link","url":"https://kipp.ly/blog/transformer-inference-arithmetic/#kv-cache","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"kv cache","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Nf5XUpuI0P"}],"urlSource":"https://kipp.ly/blog/transformer-inference-arithmetic/#kv-cache","key":"RYAWHvtuIn"},{"type":"text","value":". Also, we implemented our attention head computations sequentially, when we should really be doing it in parallel. Using JAX, this is as simple as","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xjIR0WnZn2"}],"key":"F0Mh16qvnd"},{"type":"code","lang":"python","value":"heads = jax.vmap(attention, in_axes=(0, 0, 0, None))(q, k, v, causal_mask)","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"iTZIpYGQMT"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"There’s many many more inference optimizations. Here’s two recommendations as a starting point:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"VWr9sQMMO2"}],"key":"MCAWcoOLNJ"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://lilianweng.github.io/posts/2023-01-10-inference-optimization/","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Lillian Weng’s Large Transformer Model Inference Optimization","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"OHZRmYnryr"}],"urlSource":"https://lilianweng.github.io/posts/2023-01-10-inference-optimization/","key":"fnxOXe1LVf"}],"key":"LBGRPnLTol"}],"key":"mskOseneXk"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://kipp.ly/blog/transformer-inference-arithmetic/","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Kipply’s Transformer Inference Arithmetic","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"QIxPxBNUP1"}],"urlSource":"https://kipp.ly/blog/transformer-inference-arithmetic/","key":"pzflfNr5C2"}],"key":"JvfgBca09a"}],"key":"pOhGQUVZKu"}],"key":"aRYRH9jwHZ"}],"key":"OcxvpAn0Aw"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bLgDqAC7O1"}],"identifier":"training","label":"Training","html_id":"training-1","implicit":true,"key":"sY4ZlVlOFg"}],"key":"I5IwrflLKo"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gbL24TxSbf"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DmtHYrv84l"}],"key":"WA7iubqBe9"},{"type":"text","value":" is pretty standard for a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WElTAMcGrl"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IVJfriQmHI"}],"key":"C8TvqrNBzJ"},{"type":"text","value":" (gradient descent ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d5w5GKYqOY"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"w.r.t","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IiOgQ8fe13"}],"key":"rx7QJSdhZu"},{"type":"text","value":" a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zH2nrin0tM"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vBQ0nKaBQV"}],"key":"IH9yuUywUv"},{"type":"text","value":" function). Of course, you also need to use the standard bag of tricks when training a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MZVEKM77AP"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TzhTYNIOPj"}],"key":"cy6b2bCB26"},{"type":"text","value":" (i.e. use the Adam optimizer, find the optimal learning rate, regularization via dropout and/or weight decay, use a learning rate scheduler, use the correct weight initialization, batching, etc ...). Though the real challenge to training a good ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BwWjHfNsv9"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vp1uLdjfek"}],"key":"ddiQlvtyCU"},{"type":"text","value":" model is the ability to scale the data and the model. For scaling data, you’ll want a corpus of text that is big, high quality, and diverse.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fO7EBo7xhz"}],"key":"Z6FnPCkD52"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Big means billions of tokens (terabytes of data). For example, check out ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"l9S9AvsHen"},{"type":"link","url":"https://pile.eleuther.ai/","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The Pile","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AqxQvbKzgQ"}],"urlSource":"https://pile.eleuther.ai/","key":"DkE2AmWFD9"},{"type":"text","value":", which is an open source pre-training dataset for large language models.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"bAJaJ1L4OF"}],"key":"sqcLIwiUrm"}],"key":"hjS9bHmoQG"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"High quality means you want to filter out duplicate examples, unformatted text, incoherent text, garbage text, etc ...","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"vp0fPtMnnO"}],"key":"OVU0Ab9vam"}],"key":"BF3SeMx8Sd"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Diverse means varying sequence lengths, about lots of different topics, from different sources, with differing perspectives, etc ... Of course, if there are any biases in the data, it will reflect in the model, so you need to be careful of that as well.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WYsvf6Wjis"}],"key":"NmvC9UiyM1"}],"key":"IwwwFUHUjP"}],"key":"WWa5n8Vttj"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Scaling the model to billions of parameters involves a cr*p ton of engineering (and money lol). Training frameworks can get ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fQdjsNQ2Bh"},{"type":"link","url":"https://github.com/NVIDIA/Megatron-LM","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"absurdly long and complex","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tUmonv8Z3T"}],"urlSource":"https://github.com/NVIDIA/Megatron-LM","error":true,"key":"htr5IdAP2o"},{"type":"text","value":". A good place to start would be ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"wjPlJj0uPc"},{"type":"link","url":"https://lilianweng.github.io/posts/2021-09-25-train-large/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Lillian Weng’s How to Train Really Large Models on Many GPUs","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"X8JsnQ9SZW"}],"urlSource":"https://lilianweng.github.io/posts/2021-09-25-train-large/","key":"SQOhDpO9M7"},{"type":"text","value":". On the topic there’s also the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HAR7A0lsDm"},{"type":"link","url":"https://arxiv.org/pdf/1909.08053.pdf","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"NVIDIA’s Megatron Framework","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"P6icCqf8yu"}],"urlSource":"https://arxiv.org/pdf/1909.08053.pdf","key":"onED8sBqHx"},{"type":"text","value":", ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fds1p9xR2y"},{"type":"link","url":"https://arxiv.org/pdf/2204.06514.pdf","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Cohere’s Training Framework","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"a4mvB0SRGg"}],"urlSource":"https://arxiv.org/pdf/2204.06514.pdf","key":"OoPtHHs5fn"},{"type":"text","value":", ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"T0Bw8jzs76"},{"type":"link","url":"https://arxiv.org/pdf/2204.02311.pdf","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Google’s PALM","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"A93JqViMwx"}],"urlSource":"https://arxiv.org/pdf/2204.02311.pdf","key":"JEVASgRnZj"},{"type":"text","value":", the open source ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"iDEjZbdE5Z"},{"type":"link","url":"https://github.com/kingoflolz/mesh-transformer-jax","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"mesh​-transformer​-jax","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"i48CdXo7fT"}],"urlSource":"https://github.com/kingoflolz/mesh-transformer-jax","error":true,"key":"KmtKoKBRAO"},{"type":"text","value":" (used to train EleutherAI’s open source models), and ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"VmTzWPQmXg"},{"type":"link","url":"https://arxiv.org/pdf/2203.15556.pdf","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"many","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"lpRind2ivE"}],"urlSource":"https://arxiv.org/pdf/2203.15556.pdf","key":"pkh7Ndlo1h"},{"type":"text","value":" ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TbjEvGHh6b"},{"type":"link","url":"https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"many","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"I2g5ZNrfHi"}],"urlSource":"https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/","key":"kiTOReBfIo"},{"type":"text","value":" ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"dMvl3KyZwk"},{"type":"link","url":"https://arxiv.org/pdf/2005.14165.pdf","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"more","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"sjdI4D4FnR"}],"urlSource":"https://arxiv.org/pdf/2005.14165.pdf","key":"HL91gPOaEt"},{"type":"text","value":".","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"vtyHlX66mZ"}],"key":"tgc0QkOvIZ"}],"key":"xi9CLKTOru"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Evaluation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WfHyzcqT8O"}],"identifier":"evaluation","label":"Evaluation","html_id":"evaluation","implicit":true,"key":"ZPc3Vx9zsx"}],"key":"KOl56nNwiu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Oh boy, how does one even evaluate LLMs? Honestly, it’s really hard problem. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NbxB9LVkQh"},{"type":"link","url":"https://arxiv.org/abs/2211.09110","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"HELM","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J9LqSIXQMy"}],"urlSource":"https://arxiv.org/abs/2211.09110","key":"F6Zq9vjX0j"},{"type":"text","value":" is pretty comprehensive and a good place to start, but you should always be skeptical of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Bj8CvJeIng"},{"type":"link","url":"https://en.wikipedia.org/wiki/Goodhart%27s_law","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"benchmarks and evaluation metrics","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rEnt1inJ1q"}],"urlSource":"https://en.wikipedia.org/wiki/Goodhart%27s_law","data":{"page":"Goodhart%27s_law","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"JZW18XG42E"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XyYof95Fqf"}],"key":"Fx7gmTwTnM"}],"key":"GcsHt5oIKN"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Architecture Improvements","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"B77FuOar7D"}],"identifier":"architecture-improvements","label":"Architecture Improvements","html_id":"architecture-improvements","implicit":true,"key":"ZFRSdhRdh1"}],"key":"qTgShGXrWu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"You can also take a look at ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZZLAgRs9Yj"},{"type":"link","url":"https://github.com/lucidrains/x-transformers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Phil Wang’s X-Transformer’s","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TZWZu7XTcw"}],"urlSource":"https://github.com/lucidrains/x-transformers","error":true,"key":"hoBDWvyHgE"},{"type":"text","value":". ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PJfz6AyF50"},{"type":"link","url":"https://arxiv.org/pdf/2102.11972.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This paper","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Wz8yYrzEmm"}],"urlSource":"https://arxiv.org/pdf/2102.11972.pdf","key":"yzVXjlLejJ"},{"type":"text","value":" is also a pretty good summary (see Table 1). Facebook’s ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uFMG6tnObB"},{"type":"link","url":"https://arxiv.org/pdf/2302.13971.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"LLaMA paper","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FihzmG8lBO"}],"urlSource":"https://arxiv.org/pdf/2302.13971.pdf","key":"s8aMoLKiQo"},{"type":"text","value":" is also probably a good reference for standard architecture improvements (at least as of February 2023 it was).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KCPgb8xlds"}],"key":"cdW3iOtiVp"}],"key":"w062cFotl6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Stopping Generation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gCSfAY7Jln"}],"identifier":"stopping-generation","label":"Stopping Generation","html_id":"stopping-generation","implicit":true,"key":"s3z6WJj23j"}],"key":"UgN5qm7Z8P"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Our current implementation requires us to specify the exact number of tokens we’d like to generate ahead of time. This is not a very good approach as our generations end up being too long, too short, or cutoff mid-sentence. To resolve this, we can introduce a special end of sentence (EOS) token. During pre-training, we append the EOS token to the end of our input (i.e. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LiXa0lA2Th"},{"type":"inlineCode","value":"tokens = [\"not\", \"all\", \"heroes\", \"wear\", \"capes\", \".\", \"\u003c|EOS|\u003e\"]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yrHYbDNu2Z"},{"type":"text","value":"). During generation, we simply stop whenever we encounter the EOS token (or if we hit some maximum sequence length):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BeAGu1pyL0"}],"key":"nnSy4BkRm7"},{"type":"code","lang":"python","value":"def generate(inputs, eos_id, max_seq_len):\n\tprompt_len = len(inputs)\n\twhile inputs[-1] != eos_id and len(inputs) \u003c max_seq_len:\n        output = gpt(inputs)\n        next_id = np.argmax(output[-1])\n        inputs.append(int(next_id))\n    return inputs[prompt_len:]","position":{"start":{"line":3,"column":1},"end":{"line":11,"column":1}},"key":"rAM5ICO2O1"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"zBboBYWz1B"}],"key":"f5VdS7o6Hc"},{"type":"text","value":"-2 was not pre-trained with an EOS token, so we can’t use this approach in our code, but most LLMs nowadays use an EOS token.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"OX1oVWB4Na"}],"key":"CNOmawI3I6"}],"key":"nR1tIvymZT"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fine-tuning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YHkmQaH6Xp"}],"identifier":"fine-tuning","label":"Fine-tuning","html_id":"fine-tuning","implicit":true,"key":"IrQEX5gxbA"}],"key":"iLqwgDLsll"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We briefly touched on fine-tuning in the training section. Recall, fine-tuning is when we re-use the pre-trained weights to train the model on some downstream task. We call this process transfer-learning. In theory, we could use zero-shot or few-shot prompting to get the model to complete our task, however, if you have access to a labelled dataset, fine-tuning a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XbUGL4YULl"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rauz7wWA6G"}],"key":"b2IgFqLHLH"},{"type":"text","value":" is going to yield better results (results that can scale given additional data and higher quality data). There are a couple different topics related to fine-tuning, as described below:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gpv3XKkr16"}],"key":"XOuqc0SQzp"}],"key":"XmJ2umBuEe"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Classification Fine-tuning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pFgipjqLc2"}],"identifier":"classification-fine-tuning","label":"Classification Fine-tuning","html_id":"classification-fine-tuning","implicit":true,"key":"RKLGG54pVV"}],"key":"l7LBGqW2jf"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In classification fine-tuning, we give the model some text and we ask it to predict which class it belongs to. For example, consider the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"poUNm6V3ld"},{"type":"link","url":"https://huggingface.co/datasets/imdb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"IMDB dataset","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QbIagDUY5S"}],"urlSource":"https://huggingface.co/datasets/imdb","key":"TKY5Tv5C07"},{"type":"text","value":", which contains movie reviews that rate the movie as either good, or bad:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"W949rTp8mz"}],"key":"x8e3ANwFHk"},{"type":"code","lang":"text","value":"--- Example 1 ---\nText: I wouldn't rent this one even on dollar rental night.\nLabel: Bad\n--- Example 2 ---\nText: I don't know why I like this movie so well, but I never get tired of watching it.\nLabel: Good\n--- Example 3 ---\n...","position":{"start":{"line":3,"column":1},"end":{"line":12,"column":1}},"key":"yyFD0nFSxx"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"To fine-tune our model, we replace the language modeling head with a classification head, which we apply to the last token output:","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Gu0jCgQNFc"}],"key":"dCXXWINAuv"},{"type":"code","lang":"python","value":"def gpt2(inputs, wte, wpe, blocks, ln_f, cls_head, n_head):\n    x = wte[inputs] + wpe[range(len(inputs))]\n    for block in blocks:\n        x = transformer_block(x, **block, n_head=n_head)\n    x = layer_norm(x, **ln_f)\n\n\t# project to n_classes\n\t# [n_embd] @ [n_embd, n_classes] -\u003e [n_classes]\n    return x[-1] @ cls_head","position":{"start":{"line":16,"column":1},"end":{"line":26,"column":1}},"key":"SsKHhRSSP0"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"We only use the last token output ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"souAUQ4UtH"},{"type":"inlineCode","value":"x[-1]","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"I41sJWqYBS"},{"type":"text","value":" because we only need to produce a single probability distribution for the entire input instead of ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"LwziMj6cVo"},{"type":"inlineCode","value":"n_seq","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"C0I44oJafr"},{"type":"text","value":" distributions as in the case of language modeling. We take the last token in particular (instead of say the first token or a combination of all the tokens) because the last token is the only token that is allowed to attend to the entire sequence and thus has information about the input text as a whole. As per usual, we optimize ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"zIl49MpJmj"},{"type":"strong","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"w.r.t.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"FoMTXI2nDx"}],"key":"xvHDVLLDnO"},{"type":"text","value":" the cross entropy ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"Dq8ydQD0lt"},{"type":"strong","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"Un17MrDnva"}],"key":"SkiKGvOk8G"},{"type":"text","value":":","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"YPEWFEG3JE"}],"key":"JdhDeRbSKR"},{"type":"code","lang":"python","value":"def singe_example_loss_fn(inputs: list[int], label: int, params) -\u003e float:\n    logits = gpt(inputs, **params)\n    probs = softmax(logits)\n    loss = -np.log(probs[label]) # cross entropy loss\n    return loss","position":{"start":{"line":30,"column":1},"end":{"line":36,"column":1}},"key":"JVrUpAxbaR"}],"key":"vWcFxU5b0S"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Generative Fine-tuning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MVdjpQ2fg3"}],"identifier":"generative-fine-tuning","label":"Generative Fine-tuning","html_id":"generative-fine-tuning","implicit":true,"key":"wauU7Pt1UZ"}],"key":"a123AkV3kP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Some tasks can’t be neatly categorized into classes. For example, consider the task of summarization. We can fine-tune these types of task by simply performing language modeling on the input concatenated with the label. For example, here’s what a single summarization training sample might look like:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UkPDM0IRya"}],"key":"E6wqeImDzn"},{"type":"code","lang":"text","value":"--- Article ---\nThis is an article I would like to summarize.\n--- Summary ---\nThis is the summary.","position":{"start":{"line":3,"column":1},"end":{"line":8,"column":1}},"key":"lk9lrbte7I"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"We train the model as we do during pre-training (optimize ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"AVxvq8amwk"},{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"w.r.t","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"MOuPSZY1hZ"}],"key":"nczKOZ0Imk"},{"type":"text","value":" language modeling ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"ZkL6KiAgHa"},{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"XVNOpdUcMV"}],"key":"JpRM0Q0onP"},{"type":"text","value":"). At predict time, we feed the model the everything up to ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"IBTcXXMJyO"},{"type":"inlineCode","value":"--- Summary ---","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"jQLR3rrJ7b"},{"type":"text","value":" and then perform auto-regressive language modeling to generate the summary. The choice of the delimiters ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"nfPTWcosXa"},{"type":"inlineCode","value":"--- Article ---","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"HQArY4is1T"},{"type":"text","value":" and ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"MIt5Xydqws"},{"type":"inlineCode","value":"--- Summary ---","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"qMDcqo34uM"},{"type":"text","value":" are arbitrary. How you choose to format the text is up to you, as long as it is consistent between training and inference. Notice, we can also formulate classification tasks as generative tasks (for example with IMDB):","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"ydvEVLp61Z"}],"key":"A5T8S0vBhX"},{"type":"code","lang":"text","value":"--- Text ---\nI wouldn't rent this one even on dollar rental night.\n--- Label ---\nBad","position":{"start":{"line":12,"column":1},"end":{"line":17,"column":1}},"key":"R1GR13nEEq"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"However, this will probably perform worse than doing classification fine-tuning directly (","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"lAwRe6LpWx"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"KA6755NHZO"}],"key":"ePIBS6XsPi"},{"type":"text","value":" includes language modeling on the entire sequence, not just the final prediction, so the ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"pCGUwqteKw"},{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"wiRYDpg9oF"}],"key":"jOrLhGTvyf"},{"type":"text","value":" specific to the prediction will get diluted)","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"IV4uYOKHg8"}],"key":"HrYrdVkPhp"}],"key":"IxyrKzACI9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Instruction Fine-tuning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dz9M1WDnhM"}],"identifier":"instruction-fine-tuning","label":"Instruction Fine-tuning","html_id":"instruction-fine-tuning","implicit":true,"key":"SDcbBl3bj7"}],"key":"RKkNbmqLJn"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Most state-of-the-art large language models these days also undergo an additional instruction fine-tuning step after being pre-trained. In this step, the model is fine-tuned (generative) on thousands of instruction prompt + completion pairs that were human labeled. Instruction fine-tuning can also be referred to as supervised fine-tuning, since the data is human labelled (i.e. supervised). So what’s the benefit of instruction fine-tuning? While predicting the next word in a wikipedia article makes the model is good at continuing sentences, it doesn’t make it particularly good at following instructions, or having a conversation, or summarizing a document (all the things we would like a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iMHYLLSUyf"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jNb3Aw0m4Q"}],"key":"X6yshmLT0b"},{"type":"text","value":" to do). Fine-tuning them on human labelled instruction + completion pairs is a way to teach the model how it can be more useful, and make them easier to interact with. This call this AI alignment, as we are aligning the model to do and behave as we want it to. Alignment is an active area of research, and includes more than just following instructions (bias, safety, intent, etc ...). What does this instruction data look like exactly? Google’s ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WAPsA6Z9lE"},{"type":"link","url":"https://arxiv.org/pdf/2109.01652.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"FLAN","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YLUd1tvoIo"}],"urlSource":"https://arxiv.org/pdf/2109.01652.pdf","key":"Y495ZosfW7"},{"type":"text","value":" models were trained on various academic NLP datasets (which are already human labelled):","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DOl4scwfj9"}],"key":"jdLIdVRKai"}],"key":"KINxzRFLP2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"fig_3_from_flan_paper.png\"))","key":"BzpVUWcmtj"},{"type":"outputs","id":"TZhcQ5OrY-dKn472BtC2-","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"269015026799f69183904e1e2efa752b","path":"/build/269015026799f69183904e1e2efa752b.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"KeVJeTDphY"}],"key":"DaHCoZ4Ae2"}],"key":"ZpwpHlz9fQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"OpenAI’s ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ohpvxu4aAy"},{"type":"link","url":"https://arxiv.org/pdf/2203.02155.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"InstructGPT","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bS25tbHoOy"}],"urlSource":"https://arxiv.org/pdf/2203.02155.pdf","key":"zRfjLw4BW8"},{"type":"text","value":" on the other hand was trained on prompts collected from their own API. They then paid workers to write completions for those prompts. Here’s a breakdown of the data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VfyivL6Gjt"}],"key":"bQ3zrTX0DB"}],"key":"uPALvdtonO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"table_1_and_2_from_instructgpt_paper.png\"))","key":"GoAy5Xejg8"},{"type":"outputs","id":"VC3nqeCY9PGPfBa2GFC3R","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0ac97a4b8b67347c6ccd5b68b7057f03","path":"/build/0ac97a4b8b67347c6ccd5b68b7057f03.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"zVe3sScy4M"}],"key":"khSJCgEhps"}],"key":"s8p4dVa3ir"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Parameter Efficient Fine-tuning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xs85KSDErI"}],"identifier":"parameter-efficient-fine-tuning","label":"Parameter Efficient Fine-tuning","html_id":"parameter-efficient-fine-tuning","implicit":true,"key":"bJOQxS6Qv3"}],"key":"UrCvkZRSJ9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"When we talk about fine-tuning in the above sections, it is assumed that we are updating all of the model parameters. While this yields the best performance, it is costly both in terms of compute (need to back propagate over the entire model) and in terms of storage (for each fine-tuned model, you need to store a completely new copy of the parameters). For instruction fine-tuning, this is fine, we want maximum performance, but if you then wanted to fine-tune 100 different models for various downstream tasks, then you’d have a problem. The most simple approach to this problem is to only update the head and freeze (i.e. make untrainable) the rest of the model. This would speed up training and greatly reduce the number of new parameters, however it would not perform nearly as well as a full fine-tune (we are lacking the deep in deep learning). We could instead selectively freeze specific layers (i.e. freeze all layers except the last 4, or freeze every other layer, or freeze all parameters except multi-head attention parameters), which would help restore some of the depth. This will perform a lot better, but we become a lot less parameter efficient and reduce our training speed ups. Instead, we can utilize parameter-efficient fine-tuning (PEFT) methods. PEFT is active area of research, and there are ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UoLauSJqMo"},{"type":"link","url":"https://aclanthology.org/2021.emnlp-main.243.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"lots","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SVhJQT4ToP"}],"urlSource":"https://aclanthology.org/2021.emnlp-main.243.pdf","key":"MRkjjZWhyY"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XbbJBVj9k1"},{"type":"link","url":"https://arxiv.org/pdf/2110.07602.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"of","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UVorWpRAAw"}],"urlSource":"https://arxiv.org/pdf/2110.07602.pdf","key":"tYQGgrAX5S"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WT411ynqmx"},{"type":"link","url":"https://arxiv.org/pdf/2101.00190.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"different","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k3l6Zmr77Z"}],"urlSource":"https://arxiv.org/pdf/2101.00190.pdf","key":"iyLiBDiut5"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rlJG3BxSkC"},{"type":"link","url":"https://arxiv.org/pdf/2103.10385.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"methods","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jEiQBnnmlC"}],"urlSource":"https://arxiv.org/pdf/2103.10385.pdf","key":"zfvpV4i8WI"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"z0GWSeqNnf"},{"type":"link","url":"https://arxiv.org/pdf/2106.09685.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"to","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"W8wka5wJAj"}],"urlSource":"https://arxiv.org/pdf/2106.09685.pdf","key":"rbgsp0zrtj"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YdPB2LTWYw"},{"type":"link","url":"https://arxiv.org/pdf/1902.00751.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"choose","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zXFoFE6bhj"}],"urlSource":"https://arxiv.org/pdf/1902.00751.pdf","key":"edB2J6oUti"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bdIRdldZLd"},{"type":"link","url":"https://arxiv.org/abs/2205.05638","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"from","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LslB5EGkT5"}],"urlSource":"https://arxiv.org/abs/2205.05638","key":"LsGSn7TCEZ"},{"type":"text","value":". As an example, take the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yuLUW4c1rB"},{"type":"link","url":"https://arxiv.org/pdf/1902.00751.pdf","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Adapters paper","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UBD7tSyVvH"}],"urlSource":"https://arxiv.org/pdf/1902.00751.pdf","key":"X0cHJJnwET"},{"type":"text","value":". In this approach, we add an additional “adapter” layer after the FFN and MHA layers in the transformer block. The adapter layer is just a simple 2 layer fully connected ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d1v7LebS0D"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E0aKV2oLtu"}],"key":"Fc50mzhved"},{"type":"text","value":", where the input and output dimensions are ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Li4lL751q5"},{"type":"inlineCode","value":"n_embd","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wIlYpOYLb5"},{"type":"text","value":", and the hidden dimension is smaller than ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C89mA5s6EW"},{"type":"inlineCode","value":"n_embd","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qyiWWc26lv"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Fa5zVbsNFY"}],"key":"LbdDb9lKGR"}],"key":"MBkpSOMQMW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"fig_2_from_the_adapters_paper.png\"))","key":"Z40jMOiMZh"},{"type":"outputs","id":"oI0sq3jaXegfPn2PUfeuW","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"8a2b43381f7a8309dc25f86c906c8d7f","path":"/build/8a2b43381f7a8309dc25f86c906c8d7f.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"V7YJlDfhFf"}],"key":"OeGiVzdY9U"}],"key":"msYULsVHEF"}],"key":"IuUl8BpHJB"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"6. makemore (part 5): building a WaveNet","url":"/micrograduate/makemore5","group":"microgra∇uate"}}},"domain":"http://localhost:3000"},"project":{"title":"microgra∇uate","github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","toc":[{"file":"index.md"},{"file":"micrograduate/micrograd.ipynb"},{"file":"micrograduate/makemore1.ipynb"},{"file":"micrograduate/makemore2.ipynb"},{"file":"micrograduate/makemore3.ipynb"},{"file":"micrograduate/makemore4.ipynb"},{"file":"micrograduate/makemore5.ipynb"},{"file":"micrograduate/picogpt.ipynb"}],"thumbnail":"/build/heading-5136875723662cf20389e350ea1e81d6.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"micrograduate.micrograd","title":"1. micrograd: implementing an autograd engine","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore1","title":"2. makemore (part 1): implementing a bigram character-level language model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore2","title":"3. makemore (part 2): mlp","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore3","title":"4. makemore (part 3): activations \u0026 gradients, batchnorm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore4","title":"5. makemore (part 4): becoming a backprop ninja","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore5","title":"6. makemore (part 5): building a WaveNet","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.picogpt","title":"7. picoGPT: implementing a tiny GPT from scratch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-7B0967AD.js";
import * as route0 from "/build/root-EDJFWIEV.js";
import * as route1 from "/build/routes/$-AD65NCUT.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-PCJPW7TK.js");</script></body></html>