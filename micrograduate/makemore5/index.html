<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>6. makemore (part 5): building a WaveNet - microgra∇uate</title><meta property="og:title" content="6. makemore (part 5): building a WaveNet - microgra∇uate"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/heading-673a2e43fc80ba15305ee790558fe91d.png"/><meta property="og:image" content="/build/heading-673a2e43fc80ba15305ee790558fe91d.png"/><link rel="stylesheet" href="/build/_assets/app-OIHP3NGU.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100vw;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="myst-home-link-logo mr-3 flex items-center dark:bg-white dark:rounded px-1"><img src="/build/book_logo-70662400b994afa052636dd09f97f5e1.png" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="microgra∇uate" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">microgra∇uate</a><a title="1. micrograd: implementing an autograd engine" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/micrograd">1. micrograd: implementing an autograd engine</a><a title="2. makemore (part 1): implementing a bigram character-level language model" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore1">2. makemore (part 1): implementing a bigram character-level language model</a><a title="3. makemore (part 2): mlp" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore2">3. makemore (part 2): mlp</a><a title="4. makemore (part 3): activations &amp; gradients, batchnorm" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore3">4. makemore (part 3): activations &amp; gradients, batchnorm</a><a title="5. makemore (part 4): becoming a backprop ninja" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/makemore4">5. makemore (part 4): becoming a backprop ninja</a><a title="6. makemore (part 5): building a WaveNet" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg myst-toc-item-exact bg-blue-300/30 active" href="/micrograduate/makemore5">6. makemore (part 5): building a WaveNet</a><a title="7. picoGPT: implementing a tiny GPT from scratch" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/micrograduate/picogpt">7. picoGPT: implementing a tiny GPT from scratch</a></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="myst-made-with-myst flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"><a href="https://github.com/ckaraneen/micrograduate" title="GitHub Repository: ckaraneen/micrograduate" target="_blank" rel="noopener noreferrer" class="myst-fm-github-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-github-icon inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div><a href="https://github.com/ckaraneen/micrograduate/edit/main/micrograduate/makemore5.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="myst-fm-edit-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-edit-icon inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">6. makemore (part 5): building a WaveNet</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="eHKbYuZEDA" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import sys

IN_COLAB = &quot;google.colab&quot; in sys.modules
if IN_COLAB:
    print(&quot;Cloning repo...&quot;)
    !git clone --quiet https://github.com/ckaraneen/micrograduate.git &gt; /dev/null
    %cd micrograduate
    print(&quot;Installing requirements...&quot;)
    !pip install --quiet uv
    !uv pip install --system --quiet -r requirements.txt</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="z4VAzFqZlcOYTTTCH2gzU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="au1PwzWHbr" class="myst-jp-nb-block relative group/block"><h2 id="intro" class="relative group"><span class="heading-text">Intro</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#intro" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="ZiOJ0xcylA" class="myst-jp-nb-block relative group/block"><p>Hi, everyone! Today we are continuing our implementation of <strong>makemore</strong>, our favorite character-level language model. Now, over the last few lectures, we’ve built up an architecture that is a <strong>mlp</strong> character-level language model. So we see that it receives <!-- -->3<!-- --> previous characters and tries to predict the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">4th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">4</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> character in a sequence using one hidden layer of neurons with <code>tanh</code> nonlinearities:</p></div><div id="Y3sS4eT7Pg" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;bengio2003nn.jpeg&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="LHI5dfmPV0Ue3oTV2dMPs" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/a21abcc7498c74c85d4a3cd5f51b3817.jpeg" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="niG9Dr8ayw" class="myst-jp-nb-block relative group/block"><p>So what we’d like to do now in this lecture is to complexify this architecture. In particular, we would like to take more characters in a sequence as an input, not just <!-- -->3<!-- -->. In addition to that, we don’t just want to feed them all into a single hidden layer, because that squashes too much information too quickly. Instead, we would like to make a deeper model that progressively fuses this information to make its guess about the next character in a sequence. We’re actually going to arrive at something that looks very much like <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/1609.03499" class="link"><strong>WaveNet</strong>, a paper published by DeepMind in 2016<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. Which is a language model basically, but it tries to predict audio sequences instead of character-level sequences or word-level sequences:</p></div><div id="haUXp00kbq" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig1.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="C5IS8CR1iw_HkHwtUzn_I" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/3f9530b394e99dfd6655c51628e3e70c.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="ZxUetjrHrv" class="myst-jp-nb-block relative group/block"><p>But fundamentally, the modeling setup is identical. It is an autoregressive model and it tries to predict the next character in a sequence:</p></div><div id="tHVrLvt5I6" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_eq1.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="iCfI8zUDEWarCxhWur0ON" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/45fa30aa01de3ef1b6dadc47c8cfd86f.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="PrI5vQb4QU" class="myst-jp-nb-block relative group/block"><p>And the architecture actually takes this interesting hierarchical sort of approach to predicting the next character in a sequence with this tree-like structure:</p></div><div id="rsg07a0MYy" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig3.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="XsQ8MpC7CywZjTGSr9Kpq" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/198c39366ff68e8b03ccb06df349f47a.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="TojUG82wrL" class="myst-jp-nb-block relative group/block"><p>And this is the architecture:</p></div><div id="wkE5m9EHLg" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig4.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="xpmYDj0Dh1CIQOmV2RPAe" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/54272b3d206b11fb693990a90d767eee.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="Ad8l84N7DL" class="myst-jp-nb-block relative group/block"><p>And we’re going to implement it in this lesson. So let’s get started!</p></div><div id="CzbgLK75Ps" class="myst-jp-nb-block relative group/block"><h2 id="starter-code-walkthrough" class="relative group"><span class="heading-text">Starter code walkthrough</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#starter-code-walkthrough" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="W0zwKHEh9W" class="myst-jp-nb-block relative group/block"><p>The starter code for this part is very similar to where we ended up in <strong>makemore</strong> (part 3). So very briefly, we are doing imports:</p></div><div id="DTXdXWpgEi" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import random
random.seed(42)
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt # for making figures
if IN_COLAB:
    %matplotlib inline
else:
    %matplotlib ipympl
SEED = 2147483647</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YoEb5PIPdN7IrVa6Sepsc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="i5c255hMW0" class="myst-jp-nb-block relative group/block"><p>We are reading our data set of words:</p></div><div id="ApC8XllmDv" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># read in all the words
words = open(&quot;names.txt&quot;, &quot;r&quot;).read().splitlines()
print(len(words))
print(max(len(w) for w in words))
print(words[:8])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="xO10k7-qnI0gzLiqp6Xbn" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>32033
15
[&#x27;emma&#x27;, &#x27;olivia&#x27;, &#x27;ava&#x27;, &#x27;isabella&#x27;, &#x27;sophia&#x27;, &#x27;charlotte&#x27;, &#x27;mia&#x27;, &#x27;amelia&#x27;]
</span></code></pre></div></div></div></div><div id="DtnhRU3fJ3" class="myst-jp-nb-block relative group/block"><p>And we are processing the dataset of words into lots and lots of individual examples:</p></div><div id="BUqH4iBwqW" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># build the vocabulary of characters and mappings to/from integers
chars = sorted(list(set(&quot;&quot;.join(words))))
ctoi = {s: i + 1 for i, s in enumerate(chars)}
ctoi[&quot;.&quot;] = 0
itoc = {i: s for s, i in ctoi.items()}
vocab_size = len(itoc)
print(itoc)
print(vocab_size)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="DBGBLz67LfcGikiS-HIGL" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>{1: &#x27;a&#x27;, 2: &#x27;b&#x27;, 3: &#x27;c&#x27;, 4: &#x27;d&#x27;, 5: &#x27;e&#x27;, 6: &#x27;f&#x27;, 7: &#x27;g&#x27;, 8: &#x27;h&#x27;, 9: &#x27;i&#x27;, 10: &#x27;j&#x27;, 11: &#x27;k&#x27;, 12: &#x27;l&#x27;, 13: &#x27;m&#x27;, 14: &#x27;n&#x27;, 15: &#x27;o&#x27;, 16: &#x27;p&#x27;, 17: &#x27;q&#x27;, 18: &#x27;r&#x27;, 19: &#x27;s&#x27;, 20: &#x27;t&#x27;, 21: &#x27;u&#x27;, 22: &#x27;v&#x27;, 23: &#x27;w&#x27;, 24: &#x27;x&#x27;, 25: &#x27;y&#x27;, 26: &#x27;z&#x27;, 0: &#x27;.&#x27;}
27
</span></code></pre></div></div></div></div><div id="omYpA1ZYdN" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def build_dataset(words, block_size):
    x, y = [], []
    for w in words:
        context = [0] * block_size
        for ch in w + &quot;.&quot;:
            ix = ctoi[ch]
            x.append(context)
            y.append(ix)
            context = context[1:] + [ix]  # crop and append
    x = torch.tensor(x)
    y = torch.tensor(y)
    print(x.shape, y.shape)
    return x, y</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="LDuYzJi3LPMb_ThnN_MCf" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="vXoRrqFrsB" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def build_all_datasets(block_size):
    random.shuffle(words)
    n1 = int(0.8 * len(words))
    n2 = int(0.9 * len(words))
    xtrain_dataset = build_dataset(words[:n1], block_size)  # 80%
    xval_dataset = build_dataset(words[n1:n2], block_size)  # 10%
    xtest_dataset = build_dataset(words[n2:], block_size)  # 10%
    return xtrain_dataset, xval_dataset, xtest_dataset</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="8O2d2RtKANrJD3iaH46Dw" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="t8LVQ6mA16" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def print_next_character(xtrain, ytrain):
    for x, y in zip(xtrain, ytrain):
        print(&quot;&quot;.join(itoc[ix.item()] for ix in x), &quot;--&gt;&quot;, itoc[y.item()])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="mSK7v0_RFDFe55WSHxv6Z" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="MU7cIifojZ" class="myst-jp-nb-block relative group/block"><p>Specifically many examples of...</p></div><div id="gjbR5N8z8B" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">block_size = (
    3  # context length: how many characters do we take to predict the next one?
)
(xtrain, ytrain), (xval, yval), (xtest, ytest) = build_all_datasets(block_size)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="R2IqfMSwmw121wf-XALYL" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>torch.Size([182625, 3]) torch.Size([182625])
torch.Size([22655, 3]) torch.Size([22655])
torch.Size([22866, 3]) torch.Size([22866])
</span></code></pre></div></div></div></div><div id="D7QU5kv22P" class="myst-jp-nb-block relative group/block"><p>... <code>block_size=3</code> characters and we are trying to predict the fourth one:</p></div><div id="xrTydKSNEI" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print_next_character(xtrain[:20], ytrain[:20])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="oOeRfEiqSoyaME5huq7TV" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>... --&gt; y
..y --&gt; u
.yu --&gt; h
yuh --&gt; e
uhe --&gt; n
hen --&gt; g
eng --&gt; .
... --&gt; d
..d --&gt; i
.di --&gt; o
dio --&gt; n
ion --&gt; d
ond --&gt; r
ndr --&gt; e
dre --&gt; .
... --&gt; x
..x --&gt; a
.xa --&gt; v
xav --&gt; i
avi --&gt; e
</span></code></pre></div></div></div></div><div id="S4oaeRJKr0" class="myst-jp-nb-block relative group/block"><p>Basically, we are breaking down each of these word into little problems of “given <!-- -->3<!-- --> characters, predict the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">4th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">4</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> one”. So this is our data set and this is what we’re trying to get the <strong>nn</strong> to do. Now in <strong>makemore</strong> (part 3), we started to develop our code around these following layer modules. We’re doing this because we want to think of these modules as lego building blocks that we can sort of stack up into <strong>nn</strong>s and we can feed data between these layers and stack them up into sort of graphs. Now we also developed these layers to have APIs and signatures very similar to <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/nn.html" class="link">those that are found in PyTorch<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. And so we have the <code>Linear</code> layer, the <code>BatchNorm1d</code> layer and the <code>Tanh</code> layer that we developed previously:</p></div><div id="jyZddX0WWg" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class Linear:
    def __init__(self, fan_in, fan_out, bias=True):
        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5
        self.bias = torch.zeros(fan_out) if bias else None

    def __call__(self, x):
        self.out = x @ self.weight
        if self.bias is not None:
            self.out += self.bias
        return self.out

    def parameters(self):
        return [self.weight] + ([] if self.bias is None else [self.bias])


class BatchNorm1d:
    def __init__(self, dim, eps=1e-5, momentum=0.1):
        self.eps = eps
        self.momentum = momentum
        self.training = True
        # parameters (trained with backprop)
        self.gamma = torch.ones(dim)
        self.beta = torch.zeros(dim)
        # buffers (trained with a running &#x27;momentum update&#x27;)
        self.running_mean = torch.zeros(dim)
        self.running_var = torch.ones(dim)

    def __call__(self, x):
        # calculate the forward pass
        if self.training:
            xmean = x.mean(0, keepdim=True)  # batch mean
            xvar = x.var(0, keepdim=True)  # batch variance
        else:
            xmean = self.running_mean
            xvar = self.running_var
        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # normalize to unit variance
        self.out = self.gamma * xhat + self.beta
        # update the buffers
        if self.training:
            with torch.no_grad():
                self.running_mean = (
                    1 - self.momentum
                ) * self.running_mean + self.momentum * xmean
                self.running_var = (
                    1 - self.momentum
                ) * self.running_var + self.momentum * xvar
        return self.out

    def parameters(self):
        return [self.gamma, self.beta]


class Tanh:
    def __call__(self, x):
        self.out = torch.tanh(x)
        return self.out

    def parameters(self):
        return []</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="c-pF4fthSWEhE2mmvhdLF" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="HOuVYT4Nss" class="myst-jp-nb-block relative group/block"><p>Αnd <code>Linear</code> just does a matrix multiply in the forward pass of this module, <code>BatchNorm1d</code> of course is this crazy layer that we developed in the previous lecture. What’s crazy about it is... well there’s many things. Number one, it has these running mean and variances that are trained outside of <strong>backprop</strong>. They are trained using exponential moving average inside this layer when we call the forward pass. In addition to that, there’s this <code>self.training</code> flag because the behavior of <strong>batchnorm</strong> is different during train time and evaluation time. And so suddenly we have to be very careful that <strong>batchnorm</strong> is in its correct state. That it’s in the evaluation state or training state. So that’s something to now keep track of something that sometimes introduces bugs because you forget to put it into the right mode. And finally, we saw that <strong>batchnorm</strong> couples the statistics or the activations across the examples in the batch. So normally we thought of the batch as just an efficiency thing, but now we are coupling the computation across batch elements and it’s done for the purposes of controlling the activation statistics as we saw in the previous video. So <strong>batchnorm</strong> is a very weird layer because you have to modulate the training and eval phase. What’s more, you have to wait for the mean and the variance to settle and to actually reach a steady state and a state can become the source of many bugs, usually. And now let’s define the appropriate functions:</p></div><div id="Vbji2r0eJy" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># seed rng for reproducability
torch.manual_seed(42)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="_JNqOPsMT7aWWyT3et3PC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>&lt;torch._C.Generator at 0x7ffa740b3d90&gt;</span></code></div></div></div><div id="sZkgTVljvO" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">n_embd = 10  # the dimensionality of the character embedding vectors
n_hidden = 200  # the number of neurons in the hidden layer of the MLP


def define_nn(block_size, n_embd, n_hidden):
    global C
    C = torch.randn((vocab_size, n_embd))
    n_inputs = n_embd * block_size
    n_outputs = vocab_size
    layers = [
        Linear(n_inputs, n_hidden, bias=False),
        BatchNorm1d(n_hidden),
        Tanh(),
        Linear(n_hidden, n_outputs),
    ]
    # parameter init
    with torch.no_grad():
        layers[-1].weight *= 0.1  # last layer make less confident
    parameters = [C] + [p for l in layers for p in l.parameters()]
    print(sum(p.nelement() for p in parameters))  # number of parameters in total
    for p in parameters:
        p.requires_grad = True
    return layers, parameters</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="O57WZTCNtMWLX3CRMdMEp" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="G3f1opnAGf" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def forward(layers, xb, yb):
    emb = C[xb]  # embed the characters into vectors
    x = emb.view(emb.shape[0], -1)  # concatenate the vectors
    for layer in layers:
        x = layer(x)
    loss = F.cross_entropy(x, yb)  # loss function
    return loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Eif4uhepV4eC1LtXbRAY6" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="AB4JhJ1tuw" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def backward(parameters, loss):
    for p in parameters:
        p.grad = None
    loss.backward()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="oWbkSWbwdIOltHVgnbwyb" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="JnlfbIyFz4" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def update(parameters, lr):
    for p in parameters:
        p.data += -lr * p.grad</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="EpJ65XGPjAbhcPiSWo22A" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="oEEoKETUls" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def train(
    x,
    y,
    layers,
    parameters,
    initial_lr=0.1,
    maxsteps=200000,
    batchsize=32,
    break_at_step=None,
):
    lossi = []
    for i in range(maxsteps):
        # minibatch construct
        bix = torch.randint(0, x.shape[0], (batchsize,))
        xb, yb = x[bix], y[bix]
        loss = forward(layers, xb, yb)
        backward(parameters, loss)
        lr = initial_lr if i &lt; 150000 else initial_lr / 10
        update(parameters, lr=lr)
        # track stats
        if i % 10000 == 0:  # print every once in a while
            print(f&quot;{i:7d}/{maxsteps:7d}: {loss.item():.4f}&quot;)
        lossi.append(loss.log10().item())
        if break_at_step is not None and i &gt;= break_at_step:
            break
    return lossi</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="TgHgPJEnVCmDOSXS14Bqc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="EEjHwECG7C" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def trigger_eval_mode(layers):
    for l in layers:
        l.training = False</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="9Z7pW0DGiWNAtd3v_UK1v" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Dc7LpU49TK" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">@torch.no_grad()
def infer_loss(layers, x, y, prefix=&quot;&quot;):
    loss = forward(layers, x, y)
    print(f&quot;{prefix} {loss}&quot;)
    return loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="T6EsbxbhyzRy2atNl-e7u" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="k3TO2phxOv" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def sample_from_model(block_size, layers):
    for _ in range(20):
        out = []
        context = [0] * block_size  # initialize with all ...
        while True:
            # forward pass the neural net
            emb = C[torch.tensor([context])]  # (1, block_size, n_embd)
            x = emb.view(emb.shape[0], -1)  # concatenate the vectors
            for l in layers:
                x = l(x)
            logits = x
            probs = F.softmax(logits, dim=1)
            # sample from the distribution
            ix = torch.multinomial(probs, num_samples=1).item()
            # shift the context window and track the samples
            context = context[1:] + [ix]
            out.append(ix)
            # if we sample the special &#x27;.&#x27; token, break
            if ix == 0:
                break
        print(&quot;&quot;.join(itoc[i] for i in out))  # decode and print the generated word</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="CNPPwphliT3Ul4XJEY-m-" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="IHfbRx4nqT" class="myst-jp-nb-block relative group/block"><p>These should look somewhat familiar to you by now. Let’s train!</p></div><div id="FDv9cBuXft" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">layers, parameters = define_nn(block_size, n_embd, n_hidden)
lossi = train(xtrain, ytrain, layers, parameters)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="vo_98IKNsIvzePnigEMtX" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>12097
      0/ 200000: 3.2966
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>  10000/ 200000: 2.2322
  20000/ 200000: 2.4111
  30000/ 200000: 2.1004
  40000/ 200000: 2.3157
  50000/ 200000: 2.2104
  60000/ 200000: 1.9653
  70000/ 200000: 1.9767
  80000/ 200000: 2.6738
  90000/ 200000: 2.0837
 100000/ 200000: 2.2730
 110000/ 200000: 1.7491
 120000/ 200000: 2.2891
 130000/ 200000: 2.3443
 140000/ 200000: 2.1731
 150000/ 200000: 1.8246
 160000/ 200000: 1.7614
 170000/ 200000: 2.2419
 180000/ 200000: 2.0803
 190000/ 200000: 2.1326
</span></code></pre></div></div></div></div><div id="XWp398CTu8" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(lossi);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="qNFW6sRX3muR05N4B-dWK" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="wEPxgNjsvS" class="myst-jp-nb-block relative group/block"><p>This <strong>loss</strong> function looks very crazy. We should probably fix this. And that’s because <!-- -->32<!-- --> batch elements are too few. And so you can get very lucky or unlucky in any one of these batches, and it creates a very thicc <strong>loss</strong> function. So we’re gonna fix that soon. Now, before we evaluate the trained <strong>nn</strong> by inferring the training and validation <strong>loss</strong>, we need to remember because of the <strong>batchnorm</strong> layers to set all the layers’ <code>training</code> flag to <code>False</code>:</p></div><div id="stUExqdq9P" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">trigger_eval_mode(layers)
infer_loss(layers, xtrain, ytrain, prefix=&quot;train&quot;)
infer_loss(layers, xval, yval, prefix=&quot;val&quot;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Nj4VXOaNYKv1znYlBxwXY" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>train 2.0583250522613525
val 2.1065292358398438
</span></code></pre></div></div></div></div><div id="kJ4H7TA8Ki" class="myst-jp-nb-block relative group/block"><p>We still have a ways to go, as far as the validation <strong>loss</strong> is concerned. But if we sample from our model, we see that we get relatively name-like results that do no exist in the training set:</p></div><div id="wooaBiAO5S" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sample_from_model(block_size=block_size, layers=layers)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="dX7VMLucaSO2Mp98cJ3z1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>damiara.
alyzah.
fard.
azalee.
sayah.
ayvi.
reino.
sophemuellani.
ciaub.
alith.
sira.
liza.
jah.
grancealynna.
jamaur.
ben.
quan.
torie.
coria.
cer.
</span></code></pre></div></div></div></div><div id="QkLGpvI0OG" class="myst-jp-nb-block relative group/block"><p>But we can improve our <strong>loss</strong> and improve our results even further. We’ll start by fixing that thicc loss plot!</p></div><div id="eGIZdCKHQ0" class="myst-jp-nb-block relative group/block"><h2 id="fixing-the-loss-plot" class="relative group"><span class="heading-text">Fixing the <strong>loss</strong> plot</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#fixing-the-loss-plot" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="OZjxc6khDg" class="myst-jp-nb-block relative group/block"><p>One way to turn this thicc loss plot into a normal one is to only plot the mean. Remember, <code>lossi</code> is a very long list of floats that contains a <strong>loss</strong> for each training episode:</p></div><div id="a6bhVnwFPy" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">len(lossi), lossi[:5]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="iH0ZsWMebgOjEm3szyM-0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>(200000,
 [0.5180676579475403,
  0.5164594054222107,
  0.507362961769104,
  0.507546603679657,
  0.4992470443248749])</span></code></div></div></div><div id="UMGzPWFB8s" class="myst-jp-nb-block relative group/block"><p>Let’s segment this very long list into a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span> tensor of rows, with each row containing <!-- -->1000<!-- --> loss values:</p></div><div id="eBcJK1x379" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">t_loss = torch.tensor(lossi).view(-1, 1000)
t_loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="ZA0xa8aMHeZbsLx3x0N5s" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>tensor([[0.5181, 0.5165, 0.5074,  ..., 0.4204, 0.3860, 0.4014],
        [0.3937, 0.3930, 0.4177,  ..., 0.3788, 0.3896, 0.4054],
        [0.3426, 0.4191, 0.3918,  ..., 0.4447, 0.4419, 0.2821],
        ...,
        [0.3625, 0.3517, 0.3376,  ..., 0.3266, 0.3191, 0.3271],
        [0.2550, 0.3659, 0.2968,  ..., 0.2744, 0.3853, 0.3300],
        [0.3041, 0.2740, 0.3213,  ..., 0.3081, 0.4082, 0.3207]])</span></code></div></div></div><div id="AdVrkiDGqd" class="myst-jp-nb-block relative group/block"><p>Now, if we take the mean of each row, we end up with a list of <strong>loss</strong> averages:</p></div><div id="jgRf9n5L2d" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">mean_t_loss = t_loss.mean(1)
mean_t_loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="-S76SXC9pTpbL2W0qTnO8" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>tensor([0.4059, 0.3791, 0.3698, 0.3681, 0.3657, 0.3639, 0.3624, 0.3593, 0.3557,
        0.3561, 0.3516, 0.3515, 0.3504, 0.3501, 0.3491, 0.3477, 0.3498, 0.3474,
        0.3494, 0.3449, 0.3456, 0.3440, 0.3452, 0.3461, 0.3429, 0.3456, 0.3458,
        0.3438, 0.3408, 0.3437, 0.3435, 0.3407, 0.3424, 0.3412, 0.3415, 0.3404,
        0.3419, 0.3391, 0.3414, 0.3396, 0.3392, 0.3408, 0.3394, 0.3416, 0.3389,
        0.3390, 0.3376, 0.3407, 0.3364, 0.3376, 0.3393, 0.3362, 0.3371, 0.3349,
        0.3393, 0.3369, 0.3363, 0.3349, 0.3338, 0.3386, 0.3366, 0.3388, 0.3370,
        0.3379, 0.3349, 0.3378, 0.3325, 0.3358, 0.3353, 0.3390, 0.3369, 0.3366,
        0.3354, 0.3350, 0.3375, 0.3347, 0.3352, 0.3352, 0.3318, 0.3359, 0.3348,
        0.3338, 0.3350, 0.3367, 0.3331, 0.3333, 0.3346, 0.3356, 0.3339, 0.3339,
        0.3332, 0.3331, 0.3352, 0.3356, 0.3350, 0.3335, 0.3330, 0.3299, 0.3344,
        0.3350, 0.3318, 0.3295, 0.3328, 0.3336, 0.3345, 0.3341, 0.3319, 0.3342,
        0.3329, 0.3299, 0.3346, 0.3312, 0.3312, 0.3344, 0.3340, 0.3305, 0.3319,
        0.3344, 0.3302, 0.3315, 0.3335, 0.3319, 0.3345, 0.3326, 0.3331, 0.3319,
        0.3317, 0.3331, 0.3316, 0.3313, 0.3319, 0.3340, 0.3306, 0.3329, 0.3306,
        0.3322, 0.3332, 0.3313, 0.3309, 0.3348, 0.3297, 0.3324, 0.3305, 0.3311,
        0.3316, 0.3308, 0.3301, 0.3323, 0.3289, 0.3313, 0.3199, 0.3201, 0.3196,
        0.3233, 0.3184, 0.3179, 0.3180, 0.3172, 0.3175, 0.3176, 0.3200, 0.3194,
        0.3196, 0.3195, 0.3186, 0.3166, 0.3192, 0.3179, 0.3168, 0.3171, 0.3173,
        0.3188, 0.3175, 0.3176, 0.3174, 0.3197, 0.3182, 0.3167, 0.3187, 0.3217,
        0.3165, 0.3187, 0.3144, 0.3165, 0.3183, 0.3187, 0.3179, 0.3161, 0.3182,
        0.3177, 0.3171, 0.3187, 0.3194, 0.3183, 0.3157, 0.3156, 0.3167, 0.3168,
        0.3187, 0.3179])</span></code></div></div></div><div id="Lw5ESRoZdr" class="myst-jp-nb-block relative group/block"><p>If we plot this tensor list of mean losses, we should get a nicer <strong>loss</strong> plot:</p></div><div id="udndiLOrRV" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(mean_t_loss);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="rO63x-DcxkXoHJ00ni1I0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="RHFG1ngy9o" class="myst-jp-nb-block relative group/block"><p>Now, the progress we make during training is much more clearly visible! Also, notice the learning rate decay, where the <strong>loss</strong> drops to a even lower minimum. This is the <strong>loss</strong> plot we are going to be using going forward.</p></div><div id="KOG28M8y8M" class="myst-jp-nb-block relative group/block"><h2 id="torchifying-the-code-layers-containers-torch-nn" class="relative group"><span class="heading-text">torchifying the code: layers, containers, torch.nn</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#torchifying-the-code-layers-containers-torch-nn" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="Ue87bOVogJ" class="myst-jp-nb-block relative group/block"><p>Now it’s time to simplify our forward function a little bit. Notice how the embeddings and flattening operations are calculated outside of the layers:</p></div><div id="H2wSDXWQPP" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def forward(layers, xb, yb):
    emb = C[xb] # embed the characters into vectors
    x = emb.view(emb.shape[0], -1) # concatenate the vectors
    for layer in layers:
        ...</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="CNMu1b8Q0L" class="myst-jp-nb-block relative group/block"><p>To start tidying things up, let’s mirror <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" class="link"><code>torch.nn.Embedding</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten" class="link"><code>torch.nn.Flatten</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> with our own incredibly simplified equivalent modules:</p></div><div id="mGb81AQ7mF" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class Embedding:
    def __init__(self, n_embd, embd_dim):
        self.weight = torch.randn((n_embd, embd_dim))

    def __call__(self, ix):
        self.out = self.weight[ix]
        return self.out

    def parameters(self):
        return [self.weight]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="GerpfKAacMgtsdNRcmecH" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="VyJVe3UNNd" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class Flatten:
    def __call__(self, x):
        self.out = x.view(x.shape[0], -1)
        return self.out

    def parameters(self):
        return []</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Qq-rL4z5bhZ3jFtzjxVd5" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="VIGWhlwNSp" class="myst-jp-nb-block relative group/block"><p>These will simply be responsible for indexing and flattening. We can now simplify our forward pass by including the embedding and flattening operations as modules in the definition of the layers:</p></div><div id="WGsGfP0Eh3" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def define_nn(block_size, n_embd, n_hidden):
    n_inputs = n_embd * block_size
    n_outputs = vocab_size
    layers = [
        Embedding(vocab_size, n_embd),
        Flatten(),
        Linear(n_inputs, n_hidden, bias=False),
        BatchNorm1d(n_hidden),
        Tanh(),
        Linear(n_hidden, n_outputs),
    ]
    # parameter init
    with torch.no_grad():
        layers[-1].weight *= 0.1  # last layer make less confident
    parameters = [p for l in layers for p in l.parameters()]
    print(sum(p.nelement() for p in parameters))  # number of parameters in total
    for p in parameters:
        p.requires_grad = True
    return layers, parameters</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="LSq6Zc5Ia-ysRHSGkqiue" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="EI4MWA1eiU" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def forward(layers, xb, yb):
    x = xb
    for layer in layers:
        x = layer(x)
    loss = F.cross_entropy(x, yb)  # loss function
    return loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="4M0d3TpbYx_9WbTgPwi5a" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="kk6vRN9Ygh" class="myst-jp-nb-block relative group/block"><p>Awesome. Now we can even further simplify our forward pass by replacing the list that contains our layers with our simplified implementation of the <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" class="link"><code>torch.nn.Sequential</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> container: this object contains layers and the functionality to iteratively pass data through them. Meaning that we now define a bunch of layers as a <code>Sequential</code> object (i.e. a model) through which we can pass input data (e.g. <code>x</code>), without the need to explicitly loop.</p></div><div id="zFeiUbMxvt" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class Sequential:
    def __init__(self, layers):
        self.layers = layers

    def __call__(self, x):
        for layer in self.layers:
            x = layer(x)
        self.out = x
        return self.out

    def parameters(self):
        # get parameters of all layers and stretch them out into one list
        return [p for layer in self.layers for p in layer.parameters()]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Hxsv_x4Lsu9g8Pu56VkKI" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="I6tgtMTA3S" class="myst-jp-nb-block relative group/block"><p>Let’s now further simplify our functions by replacing the <code>layers</code> list with <code>model</code>, a <code>Sequential</code> object:</p></div><div id="VbQa9DkvEe" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def define_nn(block_size, n_embd, n_hidden):
    n_inputs = n_embd * block_size
    n_outputs = vocab_size
    model = Sequential(
        [
            Embedding(vocab_size, n_embd),
            Flatten(),
            Linear(n_inputs, n_hidden, bias=False),
            BatchNorm1d(n_hidden),
            Tanh(),
            Linear(n_hidden, n_outputs),
        ]
    )
    # parameter init
    with torch.no_grad():
        model.layers[-1].weight *= 0.1  # last layer make less confident
    parameters = model.parameters()
    print(sum(p.nelement() for p in parameters))  # number of parameters in total
    for p in parameters:
        p.requires_grad = True
    return model, parameters</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="hMfnBt86GnWdV_7R7bfQo" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="jMOCLc3I1W" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def forward(model, xb, yb):
    logits = model(xb)
    loss = F.cross_entropy(logits, yb)  # loss function
    return loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="9QRsLRXYtz7PMr75LzedO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="AmiqxqeXvV" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def train(
    x,
    y,
    model,
    parameters,
    initial_lr=0.1,
    maxsteps=200000,
    batchsize=32,
    break_at_step=None,
):
    lossi = []
    for i in range(maxsteps):
        # minibatch construct
        bix = torch.randint(0, x.shape[0], (batchsize,))
        xb, yb = x[bix], y[bix]
        loss = forward(model, xb, yb)
        backward(parameters, loss)
        lr = initial_lr if i &lt; 150000 else initial_lr / 10
        update(parameters, lr=lr)
        # track stats
        if i % 10000 == 0:  # print every once in a while
            print(f&quot;{i:7d}/{maxsteps:7d}: {loss.item():.4f}&quot;)
        lossi.append(loss.log10().item())
        if break_at_step is not None and i &gt;= break_at_step:
            break
    return lossi</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="haDFvZocagjzaefyu5CSZ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="JPs9AcBxDJ" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def trigger_eval_mode(model):
    for l in model.layers:
        l.training = False</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="fGFfMu-h0Y5QdNNc5nKJB" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="FcY5j4fT2U" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">@torch.no_grad()
def infer_loss(model, x, y, prefix=&quot;&quot;):
    loss = forward(model, x, y)
    print(f&quot;{prefix} {loss}&quot;)
    return loss</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="ogbd5aE0a95dL4LBGbDky" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="aYrUeMtLmd" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def sample_from_model(block_size, model):
    for _ in range(20):
        out = []
        context = [0] * block_size  # initialize with all ...
        while True:
            # forward pass the neural net
            logits = model(torch.tensor([context]))
            probs = F.softmax(logits, dim=1)
            # sample from the distribution
            ix = torch.multinomial(probs, num_samples=1).item()
            # shift the context window and track the samples
            context = context[1:] + [ix]
            out.append(ix)
            # if we sample the special &#x27;.&#x27; token, break
            if ix == 0:
                break
        print(&quot;&quot;.join(itoc[i] for i in out))  # decode and print the generated word</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="fCw37VGEhqUGxxfJUgQsM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="oezuUBGvgq" class="myst-jp-nb-block relative group/block"><p>And let’s verify that our new definitions work by re-training our <strong>nn</strong>:</p></div><div id="g0AcK4m94J" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, parameters = define_nn(block_size, n_embd, n_hidden)
lossi = train(xtrain, ytrain, model, parameters)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="dBExKyNGTCopCOUTnZttS" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>12097
      0/ 200000: 3.3055
  10000/ 200000: 2.1954
  20000/ 200000: 2.2630
  30000/ 200000: 2.0618
  40000/ 200000: 2.0468
  50000/ 200000: 2.1775
  60000/ 200000: 2.1750
  70000/ 200000: 1.9390
  80000/ 200000: 2.1816
  90000/ 200000: 2.0516
 100000/ 200000: 2.0578
 110000/ 200000: 2.2706
 120000/ 200000: 2.3313
 130000/ 200000: 2.1557
 140000/ 200000: 2.0983
 150000/ 200000: 1.9418
 160000/ 200000: 1.9421
 170000/ 200000: 2.1256
 180000/ 200000: 2.2467
 190000/ 200000: 1.6821
</span></code></pre></div></div></div></div><div id="ENXZjTZTZT" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="G0IKFvTptWOpAvGuGQF_s" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="muyRAGzxNt" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">trigger_eval_mode(model)
infer_loss(model, xtrain, ytrain, prefix=&quot;train&quot;)
infer_loss(model, xval, yval, prefix=&quot;val&quot;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="L_76Uz5PMsmHnsCGy6a2S" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>train 2.0581207275390625
val 2.105104684829712
</span></code></pre></div></div></div></div><div id="LfW5Jc7N3K" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sample_from_model(block_size, model)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="8EuJfNACQqvwJJGhKNRZI" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>masea.
iman.
ryy.
ayee.
havajine.
miliakendalikain.
amagntanton.
aviona.
jah.
wiseegh.
avon.
man.
tovi.
sullessa.
marcuz.
jazia.
abellabell.
athin.
ahkiara.
krister.
</span></code></pre></div></div></div></div><div id="wVCERE0dfR" class="myst-jp-nb-block relative group/block"><p>Cool. Now it’s time to decrease the loss even further by scaling up our model to make it bigger and deeper!</p></div><div id="eKenlbFV12" class="myst-jp-nb-block relative group/block"><h2 id="wavenet-overview" class="relative group"><span class="heading-text"><strong>WaveNet</strong> overview</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#wavenet-overview" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="DOVRBL45mJ" class="myst-jp-nb-block relative group/block"><p>Currently, we are using this architecture here:</p></div><div id="YhMPmQwhiF" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;bengio2003nn.jpeg&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="tdS5NfDre_docrS7wGovR" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/a21abcc7498c74c85d4a3cd5f51b3817.jpeg" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="K7KPvSIZPr" class="myst-jp-nb-block relative group/block"><p>where we are taking in some number of characters, going into a single hidden layer, and then going to the prediction of the next character. The problem here is we don’t have a naive way of making this bigger in a productive way. We could, of course, use our <strong>nn</strong>. We could use our layers, sort of like building block materials to introduce additional layers here and make the network deeper. But it is still the case that we are crushing all of the characters into a single layer all the way at the beginning. And even if we make this a layer bigger by adding neurons, it’s still kind of like silly to squash all that information so fast in a single step. What we’d like to do instead is we’d like our network to look a lot more like this <strong>WaveNet</strong> case:</p></div><div id="xsWTsYVRxC" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig3.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="R3714rKNHv8VIkYoQMM_G" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/198c39366ff68e8b03ccb06df349f47a.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="f0QxqRmAw8" class="myst-jp-nb-block relative group/block"><p>So you see in <strong>WaveNet</strong>, when we are trying to make the prediction for the next character in a sequence a function of the previous characters that feed in. But it is not the case that all of these different characters are just crushed to a single layer and then you have a sandwich. They are crushed slowly. So in particular, we take two characters and we fuse them into sort of like a bigram representation. And we do that for all these characters consecutively. And then we take the bigrams and we fuse those into four character level chunks. And then we fuse again. And so we do that in this tree-like hierarchical manner. So we fuse the information from the previous context <em>gradually</em>, as the network deepens. This is the kind of architecture that we want to implement. Now in the <strong>WaveNet</strong> case, this is a visualization of a stack of <em>dilated</em> causal convolution layers. And this makes it sound very scary, but actually the idea is quite simple. And the fact that it’s a <em>dilated</em> causal convolution layer is really just an implementation detail to make everything fast. We’re going to see that later. But for now, let’s just keep going. We’re going to keep the basic idea of it, which is this progressive fusion. So we want to make the network deeper, and at each level, we want to fuse only two consecutive elements. Two characters, then two bigrams, then two fourgrams, and so on. So let’s implement this.</p></div><div id="DlUWkPDoLF" class="myst-jp-nb-block relative group/block"><h2 id="bumping-the-context-size-to-8" class="relative group"><span class="heading-text">Bumping the context size to <!-- -->8</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#bumping-the-context-size-to-8" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="pcW19AS73l" class="myst-jp-nb-block relative group/block"><p>Okay, so first up, let me scroll to where we built the dataset, and let’s change the block size from <!-- -->3<!-- --> to <!-- -->8<!-- -->. So we’re going to be taking <!-- -->8<!-- --> characters of context to predict the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">9th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">9</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> character:</p></div><div id="s4kRnjEvgt" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">block_size = 8
(xtrain, ytrain), (xval, yval), (xtest, ytest) = build_all_datasets(block_size)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Nkox4liLCfEv9lHdzOygY" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>torch.Size([182473, 8]) torch.Size([182473])
torch.Size([22827, 8]) torch.Size([22827])
torch.Size([22846, 8]) torch.Size([22846])
</span></code></pre></div></div></div></div><div id="Zg3nukFvqW" class="myst-jp-nb-block relative group/block"><p>So the dataset now looks like this:</p></div><div id="VpjE9MOgSl" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print_next_character(xtrain[:20], ytrain[:20])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="F_Q2LbLb2qEiV5sr6nH0l" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>........ --&gt; c
.......c --&gt; a
......ca --&gt; t
.....cat --&gt; h
....cath --&gt; y
...cathy --&gt; .
........ --&gt; k
.......k --&gt; e
......ke --&gt; n
.....ken --&gt; a
....kena --&gt; d
...kenad --&gt; i
..kenadi --&gt; .
........ --&gt; a
.......a --&gt; m
......am --&gt; i
.....ami --&gt; .
........ --&gt; l
.......l --&gt; a
......la --&gt; r
</span></code></pre></div></div></div></div><div id="wB6zQqYaCt" class="myst-jp-nb-block relative group/block"><p>These <!-- -->8<!-- --> characters are going to be processed in the above tree-like structure. Let’s find out how to implement this hierarchical scheme! But before doing that, let’s train our simple fully-connected <strong>nn</strong> with this new dataset and see how well it performs:</p></div><div id="A2rMIeEaPN" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, parameters = define_nn(block_size, n_embd, n_hidden)
lossi = train(xtrain, ytrain, model, parameters)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="hQcRBkBLk6firB8cj5-Y-" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>22097
      0/ 200000: 3.3024
  10000/ 200000: 2.1462
  20000/ 200000: 2.2304
  30000/ 200000: 2.1978
  40000/ 200000: 2.3442
  50000/ 200000: 2.1926
  60000/ 200000: 2.4338
  70000/ 200000: 2.0021
  80000/ 200000: 2.0781
  90000/ 200000: 1.7328
 100000/ 200000: 2.2064
 110000/ 200000: 1.9591
 120000/ 200000: 1.9200
 130000/ 200000: 1.7876
 140000/ 200000: 2.0151
 150000/ 200000: 1.9124
 160000/ 200000: 1.9154
 170000/ 200000: 2.4858
 180000/ 200000: 2.0312
 190000/ 200000: 1.7150
</span></code></pre></div></div></div></div><div id="SfGGekqu2Y" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="orMTooKDLUSM1p-LUFLCK" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="fVfjKQFiBa" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">trigger_eval_mode(model)
infer_loss(model, xtrain, ytrain, prefix=&quot;train&quot;)
infer_loss(model, xval, yval, prefix=&quot;val&quot;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="0SrlD_mIbzF17fdsL10Zc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>train 1.9159809350967407
val 2.0343399047851562
</span></code></pre></div></div></div></div><div id="IpO9E3fn2T" class="myst-jp-nb-block relative group/block"><p>Interesting! The <strong>loss</strong> has improved compared to the <code>block_size = 3</code> case. Let’s log our losses so far:</p></div><div id="UEild0QNAr" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105
# context: 3 -&gt; 8 (22K params): train 1.915, val 2.034</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="iNfNV3kzuh" class="myst-jp-nb-block relative group/block"><p>Also, if we sample from the model, we can see the names improving qualitatively as well:</p></div><div id="ML0qoqeFpb" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sample_from_model(block_size, model)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="7XPK52nDAGwVOmPdDTUA5" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>kobi.
pran.
marlecm.
lunghan.
camillo.
shatar.
elizee.
lumarius.
deris.
brook.
madaniy.
yarel.
milaal.
aylen.
nikora.
niani.
sahanlaa.
elaya.
malixa.
dalioluw.
</span></code></pre></div></div></div></div><div id="TkzKytWHi3" class="myst-jp-nb-block relative group/block"><p>So we could, of course, spend a lot of time here tuning things and scaling up our network further. But let’s continue and let’s implement the hierarchical model and treat this as just a rough baseline performance. There’s a lot of optimization left on the table in terms of some of the hyperparameters that you’re hopefully getting a sense of now.</p></div><div id="YtcpFov3T6" class="myst-jp-nb-block relative group/block"><h2 id="implementing-wavenet" class="relative group"><span class="heading-text">Implementing <strong>WaveNet</strong></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#implementing-wavenet" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="LpcYeCpl5d" class="myst-jp-nb-block relative group/block"><p>Let’s now create a bit of a scratch space for us to just look at the forward pass of the  <strong>nn</strong> and inspect the shape of the tensors along the way of the forward pass:</p></div><div id="GCC7LOY2dT" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># let&#x27;s look at a batch of just 4 examples
ix = torch.randint(0, xtrain.shape[0], (4,))
xb, yb = xtrain[ix], ytrain[ix]
logits = model(xb)
print(xb.shape)
xb</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="sg7jdNssq0npdVOEe5p6b" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>torch.Size([4, 8])
</span></code></pre></div></div><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>tensor([[ 0,  0,  0,  0,  0,  0,  0, 12],
        [ 0,  0,  0,  0,  0,  0, 18,  5],
        [ 0,  0,  0, 11,  1, 12,  9, 14],
        [ 0,  0,  0,  0,  0, 11,  9, 18]])</span></code></div></div></div><div id="D4eukLCo13" class="myst-jp-nb-block relative group/block"><p>Here we are just temporarily, for debugging purposes, creating a batch of just, say, <!-- -->4<!-- --> examples. So <!-- -->4<!-- --> random integers. Then, we are plucking out those rows from our training set. And then we are passing into the model the input <code>xb</code>. Now the shape of <code>xb</code> here, because we only have <!-- -->4<!-- --> examples. And <!-- -->8<!-- --> is the current block size. So <code>xb</code> contains <!-- -->4<!-- --> rows/examples of <!-- -->8<!-- -->  characters each. And each integer tensor row of <code>xb</code> just contains the identities of those characters. Therefore, the first layer of our <strong>nn</strong> is the embedding layer. So passing <code>xb</code>, this integer tensor, through the <code>Embedding</code> layer creates an output:</p></div><div id="rmmo7BfezC" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model.layers[0].out.shape  # output of Embedding layer</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="o3HDGQwSb2XAe1PlpQQO1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 8, 10])</span></code></div></div></div><div id="dUySlbow7V" class="myst-jp-nb-block relative group/block"><p>So our embedding table <code>C</code> has, for each character, a <!-- -->10<!-- -->-dimensional vector (<code>n_embd=10</code>) that we are trying to learn. What the layer does here is it plucks out the embedding vector for each one of these integers (of <code>xb</code> and organizes it all in a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>8</mn><mo>×</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">4\times8\times10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span> tensor. So all of these integers are translated into <!-- -->10<!-- -->-dimensional vectors inside this <!-- -->3<!-- -->-dimensional tensor now.</p></div><div id="p0Os9nybFD" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model.layers[1].out.shape  # output of Flatten layer</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="6SbscynFAyFpaKCpv-lzP" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 80])</span></code></div></div></div><div id="PV4QlOWilr" class="myst-jp-nb-block relative group/block"><p>Now passing that through the <code>Flatten</code> layer, as you recall, what this does is it views this tensor as just a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>80</mn></mrow><annotation encoding="application/x-tex">4\times80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">80</span></span></span></span></span> tensor. And what that effectively does is that all these <!-- -->10<!-- -->-dimensional embeddings for all these <!-- -->8<!-- --> characters just end up being stretched out into a long row. And that looks kind of like a concatenation operation, basically. So by viewing the tensor differently, we now have a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>80</mn></mrow><annotation encoding="application/x-tex">4\times80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">80</span></span></span></span></span>. And inside this <!-- -->80<!-- -->, it’s all the <!-- -->10<!-- -->-dimensional vectors just concatenated next to each other.</p></div><div id="avT6yTOqGL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model.layers[2].out.shape  # output of Linear layer</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="hw3opsVXRKVuFnvqSTNrJ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 200])</span></code></div></div></div><div id="o1Hxiu8rif" class="myst-jp-nb-block relative group/block"><p>And the linear layer, of course, takes <!-- -->80<!-- --> and creates <!-- -->200<!-- --> channels just via matrix multiplication. So far, so good. Now let’s see something surprising. Let’s look at the insides of the <code>Linear</code> layer and remind ourselves how it works:</p></div><div id="mYc48NsjrW" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class Linear:
    def __init__(self, fan_in, fan_out, bias=True):
        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5
        self.bias = torch.zeros(fan_out) if bias else None

    def __call__(self, x):
        self.out = x @ self.weight
        if self.bias is not None:
            self.out += self.bias
        return self.out
...</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="ye5RKSz8ae" class="myst-jp-nb-block relative group/block"><p>The <code>Linear</code> layer here in a forward pass takes the input <code>x</code>, multiplies it with a weight and then optionally adds a bias. And the weight is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>, as defined here, and the bias is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">1D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>. So effectively, in terms of the shapes involved, what’s happening inside this <code>Linear</code> layer looks like this right now. And we’re using random numbers here, but just to illustrate the shapes and what happens:</p></div><div id="aJfCKRfBl2" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">(torch.randn(4, 80) @ torch.randn(80, 200) + torch.randn(200)).shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="69HmbYuGBvhPRr8tQ1BGP" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 200])</span></code></div></div></div><div id="EOplKK57P6" class="myst-jp-nb-block relative group/block"><p>Basically, a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>80</mn></mrow><annotation encoding="application/x-tex">4\times80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">80</span></span></span></span></span> comes into the <code>Linear</code> layer, gets multiplied by a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>80</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">80\times200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">80</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span> weight matrix inside, and then there’s a plus <!-- -->200<!-- --> bias. And the shape of the whole thing that comes out of the <code>Linear</code> layer is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">4\times200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span>, as we see here. Notice, by the way, that the matrix multiplication here will create a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>x</mi><mn>200</mn></mrow><annotation encoding="application/x-tex">4x200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">200</span></span></span></span></span> tensor, and then when adding <!-- -->200<!-- --> there’s a broadcasting happening here, but since <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>x</mi><mn>200</mn></mrow><annotation encoding="application/x-tex">4x200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">200</span></span></span></span></span> broadcasts with <!-- -->200<!-- -->, everything works here. So now the surprising thing is how this works. Specifically, something you may not expect is that this input here, that is being matrix-multiplied, doesn’t actually have to be <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>. This matrix multiply operator in <code>PyTorch</code> is quite powerful, and in fact, you can actually pass in higher dimensional arrays or tensors, and everything works fine. So for example, <code>torch.randn(4, 80)</code> could instead be <code>torch.randn(4, 5, 80)</code> (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>80</mn></mrow><annotation encoding="application/x-tex">4\times5\times80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">80</span></span></span></span></span>) and the result in that case would become <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">4\times5\times200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span>. You can add as many dimensions as you like to the left of the last dimension of the input tensor (here, dimension <!-- -->80<!-- -->). And so effectively, what’s happening is that the matrix multiplication only works on a matrix multiplication on the last dimension, and the dimensions before it in the input tensor are left unchanged. So basically, these dimensions to the left of the last dimension are all treated as just a batch dimension. So we can have multiple batch dimensions (e.g. <code>torch.randn(4, 5, 6, 7, 80)</code>), and then in parallel over all those dimensions, we are doing the matrix multiplication only on the last dimension. So this is quite convenient, because we can use that in our <strong>nn</strong> now. Remember that we have these <!-- -->8<!-- --> characters coming in, e.g.</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># 1 2 3 4 5 6 7 8</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>And we don’t want to now flatten all of it out into a large <!-- -->8<!-- -->-dimensional vector, because we don’t want to matrix multiply <!-- -->80<!-- --> into a weight matrix multiply immediately. Instead, we want to group these like this:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># (1 2) (3 4) (5 6) (7 8)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>So every consecutive two elements should now basically be flattened and multiplied by a weight matrix. But the idea is that all of these four groups here, we’d like to process in parallel. So it’s kind of like a extra batch dimension that we can introduce. And then we can, in parallel, basically process all of these bigram groups in the four extra batch dimension of an individual example, and also over the actual batch dimension of the four examples. So let’s see what this is all about and how that works. Right now, we take a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>80</mn></mrow><annotation encoding="application/x-tex">4\times80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">80</span></span></span></span></span> and multiply it by <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>80</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">80\times200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">80</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span> in the linear layer. Effectively, what we want is instead of <!-- -->8<!-- --> characters (<!-- -->80<!-- --> embedding numbers) coming in, we only want <!-- -->2<!-- --> characters (<!-- -->20<!-- --> embedding numbers) to come in. Therefore, if we want that, we can’t have a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>x</mi><mn>80</mn></mrow><annotation encoding="application/x-tex">4x80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">80</span></span></span></span></span> feeding into the <code>Linear</code> layer, but instead <!-- -->4<!-- --> groups of <!-- -->2<!-- --> characters to be feeding in, like this:</p></div><div id="Y6HGsQMjLi" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">(torch.randn(4, 4, 20) @ torch.randn(20, 200) + torch.randn(200)).shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="ecVzALDioxibsEixQnOr2" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 4, 200])</span></code></div></div></div><div id="GxQRvwCujj" class="myst-jp-nb-block relative group/block"><p>Therefore, what we would want to do now is change the <code>Flatten</code> layer so that it doesn’t output a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>x</mi><mn>80</mn></mrow><annotation encoding="application/x-tex">4x80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">80</span></span></span></span></span> but a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>x</mi><mn>4</mn><mi>x</mi><mn>20</mn></mrow><annotation encoding="application/x-tex">4x4x20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">20</span></span></span></span></span> where basically in each row tensor of <code>xb</code>:</p></div><div id="jQfTiEEaGz" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">xb</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="mEPBZlfZ5W9hJFdqmCb4s" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>tensor([[ 0,  0,  0,  0,  0,  0,  0, 12],
        [ 0,  0,  0,  0,  0,  0, 18,  5],
        [ 0,  0,  0, 11,  1, 12,  9, 14],
        [ 0,  0,  0,  0,  0, 11,  9, 18]])</span></code></div></div></div><div id="n3QnEmqu2M" class="myst-jp-nb-block relative group/block"><p>every two consecutive characters (e.g. <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><mn>10</mn><mo separator="true">,</mo><mn>21</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><mn>12</mn><mo separator="true">,</mo><mn>9</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><mn>5</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0, 0), (10, 21), (12,  9), (5, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mopen">(</span><span class="mord">10</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">21</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mopen">(</span><span class="mord">12</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">9</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mopen">(</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>) are packed in on the very last dimension (i.e. <!-- -->20<!-- -->). So that the first dimension (i.e. <!-- -->4<!-- -->) is the first batch dimension and the second dimension (i.e. <!-- -->4<!-- -->) is the second batch dimension. And this is where we want to get to:</p></div><div id="AZEHiAd81d" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">(torch.randn(4, 4, 20) @ torch.randn(20, 200) + torch.randn(200)).shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Eye6Q47xxNMduBcpGUtxZ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 4, 200])</span></code></div></div></div><div id="atOpNlE7Tz" class="myst-jp-nb-block relative group/block"><p>Now we have to change our <code>Flatten</code> layer (so that it doesn’t fully flatten out the examples, but creates a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">4\times4\times20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span></span> instead of a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>80</mn></mrow><annotation encoding="application/x-tex">4\times80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">80</span></span></span></span></span>) and our <code>Linear</code> layer (to expect <!-- -->20<!-- --> instead of <!-- -->80<!-- -->). So let’s see how this could be implemented. Basically, right now we have an input that is a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>8</mn><mo>×</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">4\times8\times10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span> that feeds into the <code>Flatten</code> layer, and currently the <code>Flatten</code> layer just stretches it out:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class Flatten:
    def __call__(self, x):
        self.out = x.view(x.shape[0], -1)
        return self.out
...</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>through the <code>view</code> operation. Effectively what it does now is:</p></div><div id="RyrN9r34R9" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">e = torch.randn(
    4, 8, 10
)  # goal: want this to be (4, 4, 20) where consecutive 10-d vectors get concatenated
e.view(4, -1).shape  # yields 4x80</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="mmZqwoRaRxj_2avIspzna" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 80])</span></code></div></div></div><div id="p3iAaX2LYy" class="myst-jp-nb-block relative group/block"><p>But we want to just view the same tensor as a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>x</mi><mn>4</mn><mi>x</mi><mn>20</mn></mrow><annotation encoding="application/x-tex">4x4x20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">4</span><span class="mord mathnormal">x</span><span class="mord">20</span></span></span></span></span> instead, so:</p></div><div id="q1Nh0efxrX" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">e.view(4, 4, -1).shape  # yields 4x4x20: this is what we want!</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Vbh688w0OY2_9d0NfN_y3" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([4, 4, 20])</span></code></div></div></div><div id="aRDYCeDD8t" class="myst-jp-nb-block relative group/block"><p>Easy, right? Let’s now rewrite <code>Flatten</code>, but since ours will now start to depart from <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten" class="link"><code>torch.nn.Flatten</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, we’ll rename it to <code>FlattenConsecutive</code> just to make sure that our APIs are somewhat similar but not the same:</p></div><div id="gP2f2FZLn3" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class FlattenConsecutive:
    def __init__(self, n):
        self.n = n

    def __call__(self, x):
        b, t, c = x.shape
        x = x.view(b, t // self.n, c * self.n)
        if x.shape[1] == 1:
            x = x.squeeze(1)
        self.out = x
        return self.out

    def parameters(self):
        return []</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="-53ms26mwfJjoLp53jpfb" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="xEc6aEx2G3" class="myst-jp-nb-block relative group/block"><p>So <code>FlattenConsecutive</code> takes in and flattens only some <code>n</code> consecutive elements and puts them into the last dimension. In <code>__call__</code> we parse the <!-- -->3<!-- --> dimensions of the input <code>x</code> as <code>b</code>, <code>c</code>, <code>t</code> (e.g. <!-- -->4<!-- -->, <!-- -->8<!-- -->, <!-- -->10<!-- -->) and then we view <code>x</code> as a <code>b</code>, <code>t // n</code>, <code>c * n</code> tensor (e.g. <!-- -->4<!-- -->, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">8/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">8/2</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mo>⋅</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">10 \cdot 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span></span>, <em>a.k.a.</em>: <!-- -->4<!-- -->, <!-- -->4<!-- -->, <!-- -->20<!-- -->). Last but not least, we check whether the middle dimension of <code>x</code> (<code>x.shape[1]</code>) is <!-- -->1<!-- --> and if so, then we simply squeeze out that dimension (e.g. <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>1</mn><mo>×</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">4\times1\times10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span> would become <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">4\times10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span></span>). Let’s now replace <code>Flatten</code> with our new <code>FlattenConsecutive</code>, while maintaining the same functionality:</p></div><div id="fnMm97VNwS" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def define_nn(block_size, n_embd, n_hidden):
    n_inputs = n_embd * block_size
    n_outputs = vocab_size
    model = Sequential(
        [
            Embedding(vocab_size, n_embd),
            FlattenConsecutive(block_size),
            Linear(n_inputs, n_hidden, bias=False),
            BatchNorm1d(n_hidden),
            Tanh(),
            Linear(n_hidden, n_outputs),
        ]
    )
    # parameter init
    with torch.no_grad():
        model.layers[-1].weight *= 0.1  # last layer make less confident
    parameters = model.parameters()
    print(sum(p.nelement() for p in parameters))  # number of parameters in total
    for p in parameters:
        p.requires_grad = True
    return model, parameters</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="XYC6Q63fsYj6sYf5KTafW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="diHJkhaqpq" class="myst-jp-nb-block relative group/block"><p>Now, let’s define the model and verify that the shapes of the layer outputs are the same after feeding one batch of data into it:</p></div><div id="jFRfOJemET" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, _ = define_nn(block_size, n_embd, n_hidden)
print(xb.shape)
model(xb)
for l in model.layers:
    print(l.__class__.__name__, &quot;:&quot;, tuple(l.out.shape))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="qGXsGNe0zVMvDLlmfA9ZG" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>22097
torch.Size([4, 8])
Embedding : (4, 8, 10)
FlattenConsecutive : (4, 80)
Linear : (4, 200)
BatchNorm1d : (4, 200)
Tanh : (4, 200)
Linear : (4, 27)
</span></code></pre></div></div></div></div><div id="ZGmJ8LXzTC" class="myst-jp-nb-block relative group/block"><p>So, we see the shapes as we expect them after every single layer in its output. Now, let’s try to restructure it and do it hierarchically:</p></div><div id="MxUp2kQp6H" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def define_nn(block_size, n_embd, n_hidden):
    n_consec = 2
    n_inputs = n_embd * n_consec
    n_outputs = vocab_size
    model = Sequential(
        [
            Embedding(vocab_size, n_embd),
            FlattenConsecutive(n_consec),
            Linear(n_inputs, n_hidden, bias=False),
            BatchNorm1d(n_hidden),
            Tanh(),
            FlattenConsecutive(n_consec),
            Linear(n_hidden * n_consec, n_hidden, bias=False),
            BatchNorm1d(n_hidden),
            Tanh(),
            FlattenConsecutive(n_consec),
            Linear(n_hidden * n_consec, n_hidden, bias=False),
            BatchNorm1d(n_hidden),
            Tanh(),
            Linear(n_hidden, n_outputs),
        ]
    )
    # parameter init
    with torch.no_grad():
        model.layers[-1].weight *= 0.1  # last layer make less confident
    parameters = model.parameters()
    print(sum(p.nelement() for p in parameters))  # number of parameters in total
    for p in parameters:
        p.requires_grad = True
    return model, parameters</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="nbdFeRku1Z755v8aqKRV2" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="kZVejTR1J9" class="myst-jp-nb-block relative group/block"><p>Now, let’s inspect the numbers in between after a forward pass on a new <strong>nn</strong>:</p></div><div id="Em2Kfs60CL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, _ = define_nn(block_size, n_embd, n_hidden)
print(xb.shape)
model(xb)
for l in model.layers:
    print(l.__class__.__name__, &quot;:&quot;, tuple(l.out.shape))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="3pUHuPniEyYEm1a65ZC01" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>170897
torch.Size([4, 8])
Embedding : (4, 8, 10)
FlattenConsecutive : (4, 4, 20)
Linear : (4, 4, 200)
BatchNorm1d : (4, 4, 200)
Tanh : (4, 4, 200)
FlattenConsecutive : (4, 2, 400)
Linear : (4, 2, 200)
BatchNorm1d : (4, 2, 200)
Tanh : (4, 2, 200)
FlattenConsecutive : (4, 400)
Linear : (4, 200)
BatchNorm1d : (4, 200)
Tanh : (4, 200)
Linear : (4, 27)
</span></code></pre></div></div></div></div><div id="tTdZcRFniZ" class="myst-jp-nb-block relative group/block"><p>So <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>8</mn><mo>×</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">4\times8\times20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span></span> was flattened consecutively into <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">4\times4\times20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span></span>. Through the <code>Linear</code> layer, this was projected into <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">4\times4\times200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span>. And then <code>BatchNorm1d</code> just works out of the box and so does <code>Tanh</code>, which is element-wise. Then we crushed it again. So we flattened consecutively once more and ended up with a <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>2</mn><mo>×</mo><mn>400</mn></mrow><annotation encoding="application/x-tex">4\times2\times400</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">400</span></span></span></span></span> now. Then <code>Linear</code> brought it back down to <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>2</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">4\times2\times200</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span></span></span></span></span>, <code>BatchNorm1d</code> and <code>Tanh</code> didn’t change the shape and for the last flattening,
it squeezed out that dimension of <!-- -->1<!-- -->, we end up with <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>400</mn></mrow><annotation encoding="application/x-tex">4\times400</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">400</span></span></span></span></span>. And then <code>Linear</code>, <code>BatchNorm1d</code>, <code>Tanh</code> and the last <code>Linear</code> yield our logits that end up in the same shape as they were before. Now, we actually have a nice three-layer <strong>nn</strong> that basically corresponds to this <strong>WaveNet</strong> network:</p></div><div id="JDZrzDk5go" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig3.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="OAxh042jRWFa_alxrpSGd" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/198c39366ff68e8b03ccb06df349f47a.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="e3LxKSYc8O" class="myst-jp-nb-block relative group/block"><p>with the only difference that we are using a blocksize of <!-- -->8<!-- --> instead of <!-- -->16<!-- -->, as depicted above. Now with a new architecture, we just have to kind of figure out some good channel numbers (numbers of hidden units) to use here. If we decrease the number to:</p></div><div id="P80SJxZqD6" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">n_hidden = 68</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="HIyYRbiB0tpUOO7GYORvH" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="w7aCP4qGUO" class="myst-jp-nb-block relative group/block"><p>then the total number of parameters comes out to <!-- -->22000<!-- -->: exactly the same that we had before (when <code>n_hidden=200</code>). So we have the same amount of capacity with this <strong>nn</strong> in terms of the number of parameters. But the question is whether we are utilizing those parameters in a more efficient architecture.</p></div><div id="sbMa5KOI3w" class="myst-jp-nb-block relative group/block"><h2 id="training-the-wavenet-first-pass" class="relative group"><span class="heading-text">Training the <strong>WaveNet</strong>: first pass</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#training-the-wavenet-first-pass" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="jYaKync9Yf" class="myst-jp-nb-block relative group/block"><p>Let’s train this <strong>WaveNet</strong> and see the results:</p></div><div id="TikuzuXF4H" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, parameters = define_nn(block_size, n_embd, n_hidden)
lossi = train(xtrain, ytrain, model, parameters)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="CtFSwlJFl_pr7tKhWFt3Q" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>22397
      0/ 200000: 3.2978
  10000/ 200000: 2.1271
  20000/ 200000: 2.0807
  30000/ 200000: 1.6842
  40000/ 200000: 2.0252
  50000/ 200000: 2.3853
  60000/ 200000: 2.4678
  70000/ 200000: 1.7907
  80000/ 200000: 2.2092
  90000/ 200000: 2.3790
 100000/ 200000: 1.7643
 110000/ 200000: 1.6553
 120000/ 200000: 1.9414
 130000/ 200000: 1.9827
 140000/ 200000: 1.7703
 150000/ 200000: 1.8300
 160000/ 200000: 1.6640
 170000/ 200000: 1.9619
 180000/ 200000: 1.7971
 190000/ 200000: 1.9981
</span></code></pre></div></div></div></div><div id="DOnvAKCMM5" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="GVGB_Y2IVu1t3YjoNGAZg" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="bRaHpalMDg" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">trigger_eval_mode(model)
infer_loss(model, xtrain, ytrain, prefix=&quot;train&quot;)
infer_loss(model, xval, yval, prefix=&quot;val&quot;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="MS6aYr_-f28zvwRQeVTZt" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>train 1.9376758337020874
val 2.026397943496704
</span></code></pre></div></div></div></div><div id="HV7PLt8Ar6" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105
# context: 3 -&gt; 8 (22K params): train 1.915, val 2.034
# flat -&gt; hierachical (22K params): train 1.937, val 2.026</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="EtyYzsWgyd" class="myst-jp-nb-block relative group/block"><p>As you can see, changing from the flat to hierachical model (while keeping the same number of parameters) is not giving us any noticeable significant benefit in terms of the <strong>loss</strong>.  That said, there are two things to point out. Number one, we didn’t really “torture” the architecture here very much. And there’s a bunch of hyperparameter search that we could do in terms of how we allocate our budget of parameters to what layers. Number two, we still may have a bug inside the <code>BatchNorm1d</code> layer. So let’s take a look at that because it runs, but doesn’t do the right thing.</p></div><div id="r0XnED0R5S" class="myst-jp-nb-block relative group/block"><h2 id="fixing-the-batchnorm1d-bug" class="relative group"><span class="heading-text">Fixing the BatchNorm1d bug</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#fixing-the-batchnorm1d-bug" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="lfIVPuN7sE" class="myst-jp-nb-block relative group/block"><p>If we train for just one step and we print the layer output shapes:</p></div><div id="TMAPTLyGtw" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">_ = train(xtrain, ytrain, model, parameters, break_at_step=1)
model(xb)
for l in model.layers:
    print(l.__class__.__name__, &quot;:&quot;, tuple(l.out.shape))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Es7tBtN0HEjRpOFMbxwGJ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>      0/ 200000: 2.0969
Embedding : (4, 8, 10)
FlattenConsecutive : (4, 4, 20)
Linear : (4, 4, 68)
BatchNorm1d : (4, 4, 68)
Tanh : (4, 4, 68)
FlattenConsecutive : (4, 2, 136)
Linear : (4, 2, 68)
BatchNorm1d : (4, 2, 68)
Tanh : (4, 2, 68)
FlattenConsecutive : (4, 136)
Linear : (4, 68)
BatchNorm1d : (4, 68)
Tanh : (4, 68)
Linear : (4, 27)
</span></code></pre></div></div></div></div><div id="gxvAyPKNZb" class="myst-jp-nb-block relative group/block"><p>currently, it looks like the BatchNorm is receiving an input that is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>68</mn></mrow><annotation encoding="application/x-tex">32\times4\times68</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">32</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">68</span></span></span></span></span>, right? Let’s take a look at the implementation of <code>BatchNorm</code>:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class BatchNorm1d:
    def __init__(self, dim, eps=1e-5, momentum=0.1):
        self.eps = eps
        self.momentum = momentum
        self.training = True
        # parameters (trained with backprop)
        self.gamma = torch.ones(dim)
        self.beta = torch.zeros(dim)
        # buffers (trained with a running &#x27;momentum update&#x27;)
        self.running_mean = torch.zeros(dim)
        self.running_var = torch.ones(dim)
  
    def __call__(self, x):
        # calculate the forward pass
        if self.training:
            xmean = x.mean(0, keepdim=True) # batch mean
            xvar = x.var(0, keepdim=True) # batch variance
        else:
            xmean = self.running_mean
            xvar = self.running_var
        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance
        self.out = self.gamma * xhat + self.beta
        # update the buffers
        if self.training:
            with torch.no_grad():
                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean
                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar
        return self.out
  
    def parameters(self):
        return [self.gamma, self.beta]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>It assumed, in the way we wrote it and at the time, that the input <code>x</code> is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>. So it was <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">N \times D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>, where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span> was the batch size. So that’s why we only reduced the mean and the variance over the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">0th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">0</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> dimension. But now <code>x</code> will basically become <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">3D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">3</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>. So what’s happening inside the <strong>batchnorm</strong> layer right now? And how come it’s working at all and not giving any errors? The reason for that is basically because everything broadcasts properly, but the <strong>batchnorm</strong> is not doing what we want it to do. So in particular, let’s basically think through what’s happening inside the <strong>batchnorm</strong>. Let’s look at what’s happening here in a simplified example:</p></div><div id="GsFjQDsT5x" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">e = torch.randn(32, 4, 68)
emean = e.mean(0, keepdim=True)  # 1, 4, 68
evar = e.var(0, keepdim=True)  # 1, 4, 68
ehat = (e - emean) / torch.sqrt(evar + 1e-5)  # 32, 4, 68
ehat.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="gjuRrPLu3PQTIC6M4r-Fo" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([32, 4, 68])</span></code></div></div></div><div id="J2Gi5etrpL" class="myst-jp-nb-block relative group/block"><p>So we’re receiving an input of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>68</mn></mrow><annotation encoding="application/x-tex">32\times4\times68</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">32</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">68</span></span></span></span></span>. And then we are doing here <code>x.mean()</code>, but we have <code>e</code> instead of <code>x</code>. But we’re doing the mean over <!-- -->0<!-- --> and that’s actually giving us <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>68</mn></mrow><annotation encoding="application/x-tex">1\times4\times68</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">68</span></span></span></span></span>. So we’re doing the mean only over the very first dimension. And it’s giving us a mean and a variance that still maintains the middle dimension in between (i.e. <!-- -->4<!-- -->). So these means are only taken over <!-- -->32<!-- --> numbers in the first dimension. And then, when we perform the <code>ehat</code> assignment, everything broadcasts correctly still. But basically what ends up happening is when we also look at the running mean:</p></div><div id="Y9uRNseVba" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model.layers[3].running_mean.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="HfRZRxntCppJeeM5WPsHz" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([1, 4, 68])</span></code></div></div></div><div id="Wd9DE0y1vT" class="myst-jp-nb-block relative group/block"><p>the shape of this running mean now is <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>68</mn></mrow><annotation encoding="application/x-tex">1\times4\times68</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">68</span></span></span></span></span>. Instead of it being just a size of dimension, because we have <!-- -->68<!-- --> channels, we expect to have <!-- -->68<!-- --> means and variances that we’re maintaining. But actually, we have an array of <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>68</mn></mrow><annotation encoding="application/x-tex">4\times68</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">68</span></span></span></span></span>. And so basically what this is telling us is this <strong>batchnorm</strong> is currently working in parallel over <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>68</mn></mrow><annotation encoding="application/x-tex">4\times68</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">68</span></span></span></span></span> instead of just <!-- -->68<!-- --> channels. So basically we are maintaining this. We are maintaining statistics for every one of these four positions individually and independently. And instead, what we want to do is we want to treat this middle <!-- -->4<!-- --> dimension as a batch dimension, just like the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">0th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">0</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> dimension. So as far as the <strong>batchnorm</strong> is concerned, it doesn’t want to average... We don’t want to average over <!-- -->32<!-- --> numbers. But instead, we want to now average over <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn><mo>×</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">32\times4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">32</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span></span></span></span></span> numbers for every single one of these <!-- -->68<!-- --> channels. Since <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.mean.html" class="link"><code>torch.mean</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> allows us to reduce over multiple (and not just one) dimensions at the same time, we’ll do just that and reduce over both the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">0th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">0</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">1st</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span></span> dimensions:</p></div><div id="hAS5Ov7ngc" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">e = torch.randn(32, 4, 68)
emean = e.mean((0, 1), keepdim=True)  # 1, 1, 68
evar = e.var((0, 1), keepdim=True)  # 1, 1, 68
ehat = (e - emean) / torch.sqrt(evar + 1e-5)  # 32, 4, 68
ehat.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="3MdRY9ZSkb_aFuDCOE_HY" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([32, 4, 68])</span></code></div></div></div><div id="RDT8x7JSeV" class="myst-jp-nb-block relative group/block"><p>Although the final shape of <code>ehat</code> remains the same, we see now that:</p></div><div id="aTZ9irHHSb" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">emean.shape, evar.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="02Y4ivqAdLvgKxTq9lHeC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>(torch.Size([1, 1, 68]), torch.Size([1, 1, 68]))</span></code></div></div></div><div id="VWCpntnkzb" class="myst-jp-nb-block relative group/block"><p>instead of <code>1, 4, 68</code>, since we reduced over both of the batch dimensions, it yields only <!-- -->68<!-- --> numbers total for each tensor, with a bunch of spurious leftover <!-- -->1<!-- --> dimensions remaining. Therefore, this is what should be happening with our <code>running_mean</code> and <code>running_var</code> tensors inside our <code>BatchNorm1d</code> implementation. So the change is pretty straightforward:</p></div><div id="HDlb8m7wky" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">class BatchNorm1d:
    def __init__(self, dim, eps=1e-5, momentum=0.1):
        self.eps = eps
        self.momentum = momentum
        self.training = True
        # parameters (trained with backprop)
        self.gamma = torch.ones(dim)
        self.beta = torch.zeros(dim)
        # buffers (trained with a running &#x27;momentum update&#x27;)
        self.running_mean = torch.zeros(dim)
        self.running_var = torch.ones(dim)

    def __call__(self, x):
        # calculate the forward pass
        if self.training:
            if x.ndim == 2:
                dim = 0
            elif x.ndim == 3:
                dim = (0, 1)
            xmean = x.mean(dim, keepdim=True)  # batch mean
            xvar = x.var(dim, keepdim=True)  # batch variance
        else:
            xmean = self.running_mean
            xvar = self.running_var
        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # normalize to unit variance
        self.out = self.gamma * xhat + self.beta
        # update the buffers
        if self.training:
            with torch.no_grad():
                self.running_mean = (
                    1 - self.momentum
                ) * self.running_mean + self.momentum * xmean
                self.running_var = (
                    1 - self.momentum
                ) * self.running_var + self.momentum * xvar
        return self.out

    def parameters(self):
        return [self.gamma, self.beta]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="dqBFKsbRQLk0zyS_-lBPe" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="KtR0EtdhVD" class="myst-jp-nb-block relative group/block"><p>Basically, now in <code>__call__</code> we are checking the dimensionality of <code>x</code> and based on it we are determining the <code>dim</code> parameters to be passed to the <code>mean</code> and <code>var</code> functions. Now, to point out one more thing. We’re actually departing from the API of PyTorch here a little bit, because when you go read the documentation of <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html" class="link"><code>torch.nn.BatchNorm1d</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, it says:</p><blockquote><ul><li><p>Input: <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N,C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mclose">)</span></span></span></span></span> or <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo separator="true">,</mo><mi>L</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N,C,L)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">L</span><span class="mclose">)</span></span></span></span></span>, where <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span> is the batch size, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> is the number of features or channels, and <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span> is the sequence length</p></li></ul></blockquote></div><div id="AQujZ2XIPF" class="myst-jp-nb-block relative group/block"><p>Notice, the input to this layer can either be <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span></span> (batch size) <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">×</span></span></span></span></span> <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> (number of features or channels) or it actually does accept three-dimensional inputs, but it expects it to be <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>C</mi><mo>×</mo><mi>L</mi></mrow><annotation encoding="application/x-tex">N\times C \times L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span> (sequence legth). So this is a problem because you see how <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> is nested here in the middle. And so when it gets <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">3D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">3</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span> inputs, this <strong>batchnorm</strong> layer will reduce over <code>0</code> and <code>2</code> instead of <code>0</code> and <code>1</code>. So basically, <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html" class="link"><code>torch.nn.BatchNorm1d</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> layer assumes that <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> will always be the first dimension, whereas we assume here that <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> is the last dimension, and there are some number of batch dimensions beforehand. And so, it expects <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">N\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> or <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>C</mi><mo>×</mo><mi>L</mi></mrow><annotation encoding="application/x-tex">N\times C\times L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span>, whereas we expect <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">N\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span> or <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>L</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">N\times L\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span>. So just a small deviation from the <code>PyTorch</code> API. Now, after updating our <code>BatchNorm1d</code>, if we redefine our <strong>nn</strong> and run for one step:</p></div><div id="eQ7Uzds34u" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, parameters = define_nn(block_size, n_embd, n_hidden)
_ = train(xtrain, ytrain, model, parameters, break_at_step=1)
model(xb)
for l in model.layers:
    print(l.__class__.__name__, &quot;:&quot;, tuple(l.out.shape))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="uUKrCwlmRcqmQmf1L4lbZ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>22397
      0/ 200000: 3.2907
Embedding : (4, 8, 10)
FlattenConsecutive : (4, 4, 20)
Linear : (4, 4, 68)
BatchNorm1d : (4, 4, 68)
Tanh : (4, 4, 68)
FlattenConsecutive : (4, 2, 136)
Linear : (4, 2, 68)
BatchNorm1d : (4, 2, 68)
Tanh : (4, 2, 68)
FlattenConsecutive : (4, 136)
Linear : (4, 68)
BatchNorm1d : (4, 68)
Tanh : (4, 68)
Linear : (4, 27)
</span></code></pre></div></div></div></div><div id="qEQsU7YlaA" class="myst-jp-nb-block relative group/block"><p>the shapes are of course the same as before, but now if we inspect the shape of the <code>running_mean</code> inside the <strong>batchnorm</strong> layer:</p></div><div id="O8QhsQULnN" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model.layers[3].running_mean.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YBOxMtqKwmTJ290QzlLuf" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([1, 1, 68])</span></code></div></div></div><div id="HG8ULqce57" class="myst-jp-nb-block relative group/block"><p>So correctly now we are only maintaining <!-- -->68<!-- --> means, for every one of our channels, and we are treating the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">0th</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">0</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span></span></span></span></span> and the <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">1st</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span></span></span></span></span> dimension as batch dimensions, which is exactly what we want!</p></div><div id="RH5t6KxwTT" class="myst-jp-nb-block relative group/block"><h2 id="re-training-the-wavenet-after-bug-fix" class="relative group"><span class="heading-text">Re-training the <strong>WaveNet</strong> after bug fix</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#re-training-the-wavenet-after-bug-fix" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="LCKGTIFNME" class="myst-jp-nb-block relative group/block"><p>So let’s retrain the <strong>nn</strong> now, after the bug fix:</p></div><div id="ApdAU1IILE" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, parameters = define_nn(block_size, n_embd, n_hidden)
lossi = train(xtrain, ytrain, model, parameters)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Ed-JmtZBHOKV7n8IFBZFq" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>22397
      0/ 200000: 3.3054
  10000/ 200000: 2.2512
  20000/ 200000: 2.3514
  30000/ 200000: 2.5115
  40000/ 200000: 1.6012
  50000/ 200000: 2.1728
  60000/ 200000: 1.8859
  70000/ 200000: 2.1417
  80000/ 200000: 2.0348
  90000/ 200000: 1.7458
 100000/ 200000: 1.7257
 110000/ 200000: 1.9065
 120000/ 200000: 2.0347
 130000/ 200000: 2.1898
 140000/ 200000: 2.2163
 150000/ 200000: 1.7984
 160000/ 200000: 1.4846
 170000/ 200000: 1.7952
 180000/ 200000: 2.0809
 190000/ 200000: 2.2824
</span></code></pre></div></div></div></div><div id="f0gTFNtTFL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="g9EpAcwhSruZDUIdJJeI1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="HR8PCwhTE1" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">trigger_eval_mode(model)
infer_loss(model, xtrain, ytrain, prefix=&quot;train&quot;)
infer_loss(model, xval, yval, prefix=&quot;val&quot;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="lDDqcuIz-iZXEF-B8-h-H" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>train 1.911558985710144
val 2.019017219543457
</span></code></pre></div></div></div></div><div id="X0O6Ay6Gvc" class="myst-jp-nb-block relative group/block"><p>And we can see that we are getting a tiny improvement in our training and validation losses:</p></div><div id="RoHnIOUXhi" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105
# context: 3 -&gt; 8 (22K params): train 1.915, val 2.034
# flat -&gt; hierachical (22K params): train 1.937, val 2.026
# fix bug in batchnorm: train 1.911, val 2.019</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="Tamuz4AwNL" class="myst-jp-nb-block relative group/block"><p>The reason this improvement is to be expected is that now we have less numbers going into the estimates of the mean and variance which allows everything to be more stable and less wiggly.</p></div><div id="RxC7fE8LxJ" class="myst-jp-nb-block relative group/block"><h2 id="scaling-up-our-wavenet" class="relative group"><span class="heading-text">Scaling up our <strong>WaveNet</strong></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#scaling-up-our-wavenet" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="lQiBl7mYJQ" class="myst-jp-nb-block relative group/block"><p>And with this more general architecture in place, we are now set up to push the performance further by increasing the size of the network:</p></div><div id="i0oxV0I0oK" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">n_embd = 24  # the dimensionality of the character embedding vectors
n_hidden = 128  # the number of neurons in the hidden layer of the MLP</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="yN2D5VJNN9XJIAh73U4mR" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="HrOxQi3Y18" class="myst-jp-nb-block relative group/block"><p>And using the exact same architecture, we now have</p></div><div id="ODWVpBJ8PR" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">model, parameters = define_nn(block_size, n_embd, n_hidden)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="w8YhqTNCQ6ZgcWWMzSYP9" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>76579
</span></code></pre></div></div></div></div><div id="uLGZfefyFO" class="myst-jp-nb-block relative group/block"><p>76579<!-- --> parameters and the training takes a lot longer:</p></div><div id="DfwlQkqsx7" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">lossi = train(xtrain, ytrain, model, parameters)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="5dRqj5-qzJgBdxyKAs3_s" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>      0/ 200000: 3.3060
  10000/ 200000: 2.1627
  20000/ 200000: 1.8125
  30000/ 200000: 2.1831
  40000/ 200000: 1.9874
  50000/ 200000: 2.3684
  60000/ 200000: 2.1482
  70000/ 200000: 1.7558
  80000/ 200000: 1.8260
  90000/ 200000: 1.8867
 100000/ 200000: 1.9521
 110000/ 200000: 1.9662
 120000/ 200000: 1.9416
 130000/ 200000: 2.0037
 140000/ 200000: 1.9890
 150000/ 200000: 1.7099
 160000/ 200000: 1.8770
 170000/ 200000: 1.5360
 180000/ 200000: 1.4641
 190000/ 200000: 1.8875
</span></code></pre></div></div></div></div><div id="MwtTXClL9A" class="myst-jp-nb-block relative group/block"><p>but we do get a nice curve:</p></div><div id="QzxPwW9VcB" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plt.figure()
plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="aObYpYkyAOm7vFmLerCkV" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="zmIr7OsPK0" class="myst-jp-nb-block relative group/block"><p>and we are now getting even better performance:</p></div><div id="OlHUG1Mkvm" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">trigger_eval_mode(model)
infer_loss(model, xtrain, ytrain, prefix=&quot;train&quot;)
infer_loss(model, xval, yval, prefix=&quot;val&quot;);</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="aH0qMGfujwM93y6YFKhVz" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>train 1.7666022777557373
val 1.9965752363204956
</span></code></pre></div></div></div></div><div id="HRjIAqtFfE" class="myst-jp-nb-block relative group/block"><p>So, to compare to previous performances:</p></div><div id="UROm27pay1" class="myst-jp-nb-block relative group/block"><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105
# context: 3 -&gt; 8 (22K params): train 1.915, val 2.034
# flat -&gt; hierachical (22K params): train 1.937, val 2.026
# fix bug in batchnorm: train 1.911, val 2.019
# scale up the network: n_embd 24, n_hidden 128 (76K params): train 1.768, val 1.990</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="YhPl7trZOy" class="myst-jp-nb-block relative group/block"><p>However because the experiments are starting to take longer to train, we are a little bit in the dark with respect to the correct setting of the hyperparameters here and the learning rates and so on. And so we are missing sort of like an experimental harness on which we could run a number of experiments and really tune this architecture very well.</p></div><div id="Gr6fWf2LND" class="myst-jp-nb-block relative group/block"><h2 id="wavenet-but-with-dilated-causal-convolutions" class="relative group"><span class="heading-text">WaveNet but with dilated causal convolutions</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#wavenet-but-with-dilated-causal-convolutions" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="NMyCHtBbX0" class="myst-jp-nb-block relative group/block"><p>So let’s conclude now with a few notes. We basically improved our performance noticeably from a val <strong>loss</strong> of <!-- -->2.10<!-- --> to <!-- -->1.99<!-- -->. But this shouldn’t be the focus as we are kind of in the dark. We have no experimental harness, we are just guessing and checking. And this whole thing is pretty terrible to be honest. We are just looking at the training <strong>loss</strong>, whereas we should be looking at the training and validation <strong>loss</strong> together. That said, we did implement the <strong>WaveNet</strong> architecture from the <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/1609.03499" class="link">paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>:</p></div><div id="nw15DeDq8t" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig3.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="9oAb_qXt1_Yj1K-lx2HBB" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/198c39366ff68e8b03ccb06df349f47a.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="Nwx8rEqtmr" class="myst-jp-nb-block relative group/block"><p>But we did not implement this specific forward pass of it:</p></div><div id="GvBLmkZWzN" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig4.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="kJ1YvI-_nIqkLmJVXCud3" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/54272b3d206b11fb693990a90d767eee.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="J2xQTHS0Pd" class="myst-jp-nb-block relative group/block"><p>where you have a more complicated kind of gated linear layer with residual connections, skip connections and so on... So we did not implement this, but only the tree-like model. All things considered, let’s briefly go over how what we’ve done here relates to convolutional neural networks as used in the <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/1609.03499" class="link">WaveNet paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. Basically the use of convolutions is strictly for efficiency. It doesn’t actually change the model we’ve implemented. So, here for example:</p></div><div id="OqD8dfc6IZ" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print_next_character(xtrain[46:54], ytrain[46:54])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YnRQGUjZr_P2NWjD6D4Nu" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>........ --&gt; a
.......a --&gt; n
......an --&gt; a
.....ana --&gt; l
....anal --&gt; i
...anali --&gt; s
..analis --&gt; a
.analisa --&gt; .
</span></code></pre></div></div></div></div><div id="yIVtlI6X8O" class="myst-jp-nb-block relative group/block"><p>we see the name <code>analisa</code> from our training set and it has <!-- -->7<!-- --> letters, so that is <!-- -->8<!-- --> rows which correspond to independent examples of that name. Now, we can forward any one of these rows independently:</p></div><div id="d9Z1U4jZeG" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># forward a single example
single_example = xtrain[[7]]  # index by [[7]] to get an extra batch dimension
logits = model(single_example)
logits.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="yWWc0rvok2nhUwVbr7rTi" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([1, 27])</span></code></div></div></div><div id="c53siohnC3" class="myst-jp-nb-block relative group/block"><p>Now imagine that instead of just a single example, you would like to forward all of the <!-- -->8<!-- --> examples that make up the name into the network at the same time:</p></div><div id="l9HkJ30fTz" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># forward all of them
logits = torch.zeros(8, 27)
for i in range(7):
    logits[i] = model(xtrain[[7 + i]])
logits.shape</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="0Z-9aFwKPWhvVuvqPJ0kc" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>torch.Size([8, 27])</span></code></div></div></div><div id="Y8vUDgavRU" class="myst-jp-nb-block relative group/block"><p>Of course, as we’ve implemented this right now, this is <!-- -->8<!-- --> independent calls to our model. But what convolutions allow you to do is they allow you to “slide” this model efficiently over the input sequence. And so this for loop we just wrote out can be done not “outside”, through iteration, in Python, but “inside” of kernels in <a href="https://en.wikipedia.org/wiki/CUDA" class="hover-link" target="_blank" rel="noreferrer" data-state="closed"><code>CUDA</code></a>. And so this for loop gets hidden into the convolution. So basically you can think of the convolution as a for loop applying a little linear filter over space of some input sequence. And in our case the space we’re interested in is one dimensional. And we are interested in sliding these filter over the input data. This diagram is quite helpful for understanding actually:</p></div><div id="BXk5qZDtJW" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from IPython.display import Image, display

display(Image(filename=&quot;wavenet_fig3.png&quot;))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="xhVHoebnqxiH_oGGMuIZU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/build/198c39366ff68e8b03ccb06df349f47a.png" alt="&lt;IPython.core.display.Image object&gt;"/></div></div></div><div id="hCUFV3FJXp" class="myst-jp-nb-block relative group/block"><p>Here, you can see highlighted with black arrows a single tree of the calculation we just described. So depicted here, calculating a single orange node at the <strong>Output</strong> layer corresponds to us in our example forwarding a single example and getting out a single output. But what convolutions allow you to do is it allows you to take this black tree-like structure and kind of like slide it over the <strong>Input</strong> sequence (blue nodes) and calculate all of the orange outputs at the same time. In the above figure, this sliding action is represented by the dashed connections between the nodes. In our example:</p></div><div id="D5JACI6KYn" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print_next_character(xtrain[46:54], ytrain[46:54])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="sbUFWhmfDsa9VxLfI5jPw" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>........ --&gt; a
.......a --&gt; n
......an --&gt; a
.....ana --&gt; l
....anal --&gt; i
...anali --&gt; s
..analis --&gt; a
.analisa --&gt; .
</span></code></pre></div></div></div></div><div id="MEG5Pk3g9K" class="myst-jp-nb-block relative group/block"><p>this sliding operation would correspond to calculating all the above <!-- -->8<!-- --> outputs at all the positions of the name (like we did in an explicit loop) at the same time. And the reason this is much more efficient is because the for loop is inside the <code>CUDA</code> kernels. That makes it efficient. Also, notice the node re-use in the diagram were for example in the first <strong>Hidden Layer</strong> each white node is the right child of the white node above it (in the second <strong>Hidden Layer</strong>), but also the left child of another white node (also in the second <strong>Hidden Layer</strong>). In the first <strong>Hidden Layer</strong>, each node and its value is used twice. Therefore, in our above example snippet, with our naive way we would have to recalculate the value that corresponds to such a node, whereas with such a convolutional <strong>nn</strong> we are allowed to reuse it. So, in the convolutional <strong>nn</strong> you can think of the linear layer as filters. And we take these filters and their linear filters and we slide them over the input sequence and we calculate the first layer, the second layer, the third layer and then the output layer of the sandwich and it is all done very efficiently using these convolutions.</p></div><div id="tFDFErlkuZ" class="myst-jp-nb-block relative group/block"><h2 id="summary" class="relative group"><span class="heading-text">Summary</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#summary" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="JXEymRMSX8" class="myst-jp-nb-block relative group/block"><p>Another thing to take away from this lecture is having modeled our <strong>nn</strong> lego blocks: the module classes (<code>Linear</code>, etc.) after modules from <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/nn.html" class="link"><code>torch.nn</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. So it is now very easy to start using modules directly from PyTorch, from hereon. The next thing I hope you got a bit of a sense of is what the development process of building deep neural networks looks like. Which I think was relatively representative to some extent. So number one, we are spending a lot of time in the <a target="_blank" rel="noreferrer" href="https://pytorch.org/docs/stable/nn.html" class="link">documentation page of PyTorch<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="external-link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. And we’re reading through all the layers, looking at documentations, what are the shapes of the inputs, what they can be, what does the layer do, and so on. Unfortunately, however, the PyTorch documentation is not very good, at least not at the time these lectures were implemented. The PyTorch developers spend a ton of time on hardcore engineering of all kinds of distributed primitives, etc. But no one is rigorously maintaining documentation. It will lie to you, it will be wrong, it will be incomplete, it will be unclear. So unfortunately, it is what it is and you just kind of have to do your best with what they give us. Also, there’s a ton of trying to make the shapes work. And there’s a lot of gymnastics around these multi-dimensional arrays. Are they <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">2D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">3D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">3</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>, <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>D</mi></mrow><annotation encoding="application/x-tex">4D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span></span>? What shapes do the layers take? Is it <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>C</mi><mo>×</mo><mi>L</mi></mrow><annotation encoding="application/x-tex">N\times C\times L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span> or <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>L</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">N\times L\times C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></span>? And you’re permuting and viewing, and it just gets pretty messy. And so that brings me to number three. It’s often helpful to first prototype these layers and implementations in jupyter notebooks and make sure that all the shapes work out, initially making sure everything is correct. And then, once you’re satisfied with the functionality, you can copy-paste the code into your actual code base or repository (e.g. in VSCode). So these are roughly only some notes on the development process of working with <strong>nn</strong>s.</p></div><div id="dUbjuqQsuX" class="myst-jp-nb-block relative group/block"><h2 id="outro" class="relative group"><span class="heading-text">Outro</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#outro" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="mzuWpT5Led" class="myst-jp-nb-block relative group/block"><p>Lastly, this lecture unlocks a lot of potential further lectures because, number one, we have to convert our <strong>nn</strong> to actually use these dilated causal convolutional layers, so implementing the convnet. Number two, we potentially start to get into what this means, where are residual connections and skip connections and why are they useful. Number three, as we already mentioned, we don’t have any experimental harness. So right now, we are just guessing and checking everything. This is not representative of typical deep learning workflows. You usually have to set up your evaluation harness. You have lots of arguments that your script can take. You’re more comfortably kicking off a lot of experiments. You’re looking at a lot of plots of training and validation losses, and you’re looking at what is working and what is not working. And you’re working on this like population level, and you’re doing all these hyperparameter searches. So we’ve done none of that so far. So how to set that up and how to make it good, I think is a whole other topic. And number four, we should probably cover RNNs, LSTMs, GRUs, and of course Transformers. So many places to go, and we’ll cover that in the future. That’s all for now. Bye! :)</p></div><div class="myst-backmatter-parts"></div><div class="myst-footer-links flex pt-10 mb-10 space-x-4"><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-prev" href="/micrograduate/makemore4"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">microgra∇uate</div>5. makemore (part 4): becoming a backprop ninja</div></div></a><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-next" href="/micrograduate/picogpt"><div class="flex h-full align-middle"><div class="flex-grow"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">microgra∇uate</div>7. picoGPT: implementing a tiny GPT from scratch</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/build/_shared/chunk-7UUHRSK3.js"/><link rel="modulepreload" href="/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-EDJFWIEV.js"/><link rel="modulepreload" href="/build/_shared/chunk-ECLX7DIY.js"/><link rel="modulepreload" href="/build/routes/$-AD65NCUT.js"/><script>window.__remixContext = {"url":"/micrograduate/makemore5","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.8.0","options":{"favicon":"/build/logo-41d11e76379ce65cb1488d7091bd6190.png","logo":"/build/book_logo-70662400b994afa052636dd09f97f5e1.png","folders":true,"style":"/build/custom-1785d14292468f3d773055ae5446319b.css"},"nav":[],"actions":[],"projects":[{"title":"microgra∇uate","github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","toc":[{"file":"index.md"},{"file":"micrograduate/micrograd.ipynb"},{"file":"micrograduate/makemore1.ipynb"},{"file":"micrograduate/makemore2.ipynb"},{"file":"micrograduate/makemore3.ipynb"},{"file":"micrograduate/makemore4.ipynb"},{"file":"micrograduate/makemore5.ipynb"},{"file":"micrograduate/picogpt.ipynb"}],"thumbnail":"/build/heading-673a2e43fc80ba15305ee790558fe91d.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"micrograduate.micrograd","title":"1. micrograd: implementing an autograd engine","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore1","title":"2. makemore (part 1): implementing a bigram character-level language model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore2","title":"3. makemore (part 2): mlp","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore3","title":"4. makemore (part 3): activations \u0026 gradients, batchnorm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore4","title":"5. makemore (part 4): becoming a backprop ninja","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore5","title":"6. makemore (part 5): building a WaveNet","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.picogpt","title":"7. picoGPT: implementing a tiny GPT from scratch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":3,"myst":"1.8.0","options":{"favicon":"/build/logo-41d11e76379ce65cb1488d7091bd6190.png","logo":"/build/book_logo-70662400b994afa052636dd09f97f5e1.png","folders":true,"style":"/build/custom-1785d14292468f3d773055ae5446319b.css"},"nav":[],"actions":[],"projects":[{"title":"microgra∇uate","github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","toc":[{"file":"index.md"},{"file":"micrograduate/micrograd.ipynb"},{"file":"micrograduate/makemore1.ipynb"},{"file":"micrograduate/makemore2.ipynb"},{"file":"micrograduate/makemore3.ipynb"},{"file":"micrograduate/makemore4.ipynb"},{"file":"micrograduate/makemore5.ipynb"},{"file":"micrograduate/picogpt.ipynb"}],"thumbnail":"/build/heading-673a2e43fc80ba15305ee790558fe91d.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"micrograduate.micrograd","title":"1. micrograd: implementing an autograd engine","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore1","title":"2. makemore (part 1): implementing a bigram character-level language model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore2","title":"3. makemore (part 2): mlp","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore3","title":"4. makemore (part 3): activations \u0026 gradients, batchnorm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore4","title":"5. makemore (part 4): becoming a backprop ninja","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore5","title":"6. makemore (part 5): building a WaveNet","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.picogpt","title":"7. picoGPT: implementing a tiny GPT from scratch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":3,"kind":"Notebook","sha256":"10cc35aed28ce253f4849cd83b2710de172d81ae0479bdcbda690be595c94a1d","slug":"micrograduate.makemore5","location":"/micrograduate/makemore5.ipynb","dependencies":[],"frontmatter":{"title":"6. makemore (part 5): building a WaveNet","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"micrograduate-env","language":"python"},"github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","source_url":"https://github.com/ckaraneen/micrograduate/blob/main/micrograduate/makemore5.ipynb","edit_url":"https://github.com/ckaraneen/micrograduate/edit/main/micrograduate/makemore5.ipynb","exports":[{"format":"ipynb","filename":"makemore5.ipynb","url":"/build/makemore5-02942d97e3f46c378ede5d867c2c50df.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import sys\n\nIN_COLAB = \"google.colab\" in sys.modules\nif IN_COLAB:\n    print(\"Cloning repo...\")\n    !git clone --quiet https://github.com/ckaraneen/micrograduate.git \u003e /dev/null\n    %cd micrograduate\n    print(\"Installing requirements...\")\n    !pip install --quiet uv\n    !uv pip install --system --quiet -r requirements.txt","key":"eJqcGqiCtM"},{"type":"outputs","id":"z4VAzFqZlcOYTTTCH2gzU","children":[],"key":"NxeDZnMEby"}],"key":"eHKbYuZEDA"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Intro","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HKbTsh8tHC"}],"identifier":"intro","label":"Intro","html_id":"intro","implicit":true,"key":"H2ByrcGRLx"}],"visibility":"show","key":"au1PwzWHbr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Hi, everyone! Today we are continuing our implementation of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NAuYHEqm3q"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"makemore","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xe6H8ZDsC9"}],"key":"nAEcwSzzdL"},{"type":"text","value":", our favorite character-level language model. Now, over the last few lectures, we’ve built up an architecture that is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VLeNnmCqDj"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"mlp","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YJFCzvpz38"}],"key":"icG4FTAXgn"},{"type":"text","value":" character-level language model. So we see that it receives ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mwJEa46sii"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fq01gTNnXu"},{"type":"text","value":" previous characters and tries to predict the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xMJJhqf9RV"},{"type":"inlineMath","value":"4th","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"yDF83xB0dV"},{"type":"text","value":" character in a sequence using one hidden layer of neurons with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"j4YEjBuGH4"},{"type":"inlineCode","value":"tanh","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iMMAhrDCrf"},{"type":"text","value":" nonlinearities:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TizPZUenPt"}],"key":"E259AFXNKP"}],"key":"ZiOJ0xcylA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"bengio2003nn.jpeg\"))","key":"dgW32uztUm"},{"type":"outputs","id":"LHI5dfmPV0Ue3oTV2dMPs","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/jpeg":{"content_type":"image/jpeg","hash":"a21abcc7498c74c85d4a3cd5f51b3817","path":"/build/a21abcc7498c74c85d4a3cd5f51b3817.jpeg"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"sCofXhFFHD"}],"key":"CltiKNcCAK"}],"key":"Y3sS4eT7Pg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So what we’d like to do now in this lecture is to complexify this architecture. In particular, we would like to take more characters in a sequence as an input, not just ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"i5VNGMacVs"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"izZySiwTVs"},{"type":"text","value":". In addition to that, we don’t just want to feed them all into a single hidden layer, because that squashes too much information too quickly. Instead, we would like to make a deeper model that progressively fuses this information to make its guess about the next character in a sequence. We’re actually going to arrive at something that looks very much like ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hQLNb5ZIJF"},{"type":"link","url":"https://arxiv.org/abs/1609.03499","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KerVwicDRL"}],"key":"LpKlGi719d"},{"type":"text","value":", a paper published by DeepMind in 2016","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xzn8LKaF2w"}],"urlSource":"https://arxiv.org/abs/1609.03499","key":"ubxAvyXvuB"},{"type":"text","value":". Which is a language model basically, but it tries to predict audio sequences instead of character-level sequences or word-level sequences:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PvkNiZIFO5"}],"key":"xCarME2x8b"}],"key":"niG9Dr8ayw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig1.png\"))","key":"axou1XsnEj"},{"type":"outputs","id":"C5IS8CR1iw_HkHwtUzn_I","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"3f9530b394e99dfd6655c51628e3e70c","path":"/build/3f9530b394e99dfd6655c51628e3e70c.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"xXve0eOSG4"}],"key":"fFeaonSML1"}],"key":"haUXp00kbq"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"But fundamentally, the modeling setup is identical. It is an autoregressive model and it tries to predict the next character in a sequence:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"su7NL1DKFH"}],"key":"Vmc03qLWyu"}],"key":"ZxUetjrHrv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_eq1.png\"))","key":"ahXPKXTo42"},{"type":"outputs","id":"iCfI8zUDEWarCxhWur0ON","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"45fa30aa01de3ef1b6dadc47c8cfd86f","path":"/build/45fa30aa01de3ef1b6dadc47c8cfd86f.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"gWJp4k5j74"}],"key":"l8pZFCVFUl"}],"key":"tHVrLvt5I6"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And the architecture actually takes this interesting hierarchical sort of approach to predicting the next character in a sequence with this tree-like structure:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q3vdEI3pQb"}],"key":"G4DLSIqp7M"}],"key":"PrI5vQb4QU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig3.png\"))","key":"s5d8giqAAM"},{"type":"outputs","id":"XsQ8MpC7CywZjTGSr9Kpq","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"198c39366ff68e8b03ccb06df349f47a","path":"/build/198c39366ff68e8b03ccb06df349f47a.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"Ghoznr4ov1"}],"key":"LtSJnaLvvU"}],"key":"rsg07a0MYy"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And this is the architecture:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mi5JXoGjc9"}],"key":"FktuqOwExo"}],"key":"TojUG82wrL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig4.png\"))","key":"iGyDowDDB3"},{"type":"outputs","id":"xpmYDj0Dh1CIQOmV2RPAe","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"54272b3d206b11fb693990a90d767eee","path":"/build/54272b3d206b11fb693990a90d767eee.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"OQymJHNHqw"}],"key":"QcYu3T1RLZ"}],"key":"wkE5m9EHLg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And we’re going to implement it in this lesson. So let’s get started!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YZN0NQxFmT"}],"key":"qQ7g9NDsMJ"}],"key":"Ad8l84N7DL"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Starter code walkthrough","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mtQY2Snqs1"}],"identifier":"starter-code-walkthrough","label":"Starter code walkthrough","html_id":"starter-code-walkthrough","implicit":true,"key":"Jo6HSKCOkx"}],"visibility":"show","key":"CzbgLK75Ps"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The starter code for this part is very similar to where we ended up in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hdJXRx4Him"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"makemore","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NP8mxzX9KB"}],"key":"sSpKbzXZBj"},{"type":"text","value":" (part 3). So very briefly, we are doing imports:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TgHDwzf5g5"}],"key":"pXAe1XURBG"}],"key":"W0zwKHEh9W"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import random\nrandom.seed(42)\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt # for making figures\nif IN_COLAB:\n    %matplotlib inline\nelse:\n    %matplotlib ipympl\nSEED = 2147483647","key":"f7LZae9W1I"},{"type":"outputs","id":"YoEb5PIPdN7IrVa6Sepsc","children":[],"key":"FaModR41Df"}],"key":"DTXdXWpgEi"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We are reading our data set of words:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qwdsLxdSjp"}],"key":"dSIzwG1yFn"}],"key":"i5c255hMW0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# read in all the words\nwords = open(\"names.txt\", \"r\").read().splitlines()\nprint(len(words))\nprint(max(len(w) for w in words))\nprint(words[:8])","key":"OpP3wt2hab"},{"type":"outputs","id":"xO10k7-qnI0gzLiqp6Xbn","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"32033\n15\n['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"},"children":[],"key":"C59AOvySwn"}],"key":"cC6ryyWRDs"}],"key":"ApC8XllmDv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And we are processing the dataset of words into lots and lots of individual examples:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hvhj0ZhgTc"}],"key":"JIBBF9VC4N"}],"key":"DtnhRU3fJ3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# build the vocabulary of characters and mappings to/from integers\nchars = sorted(list(set(\"\".join(words))))\nctoi = {s: i + 1 for i, s in enumerate(chars)}\nctoi[\".\"] = 0\nitoc = {i: s for s, i in ctoi.items()}\nvocab_size = len(itoc)\nprint(itoc)\nprint(vocab_size)","key":"jISDIzhKXK"},{"type":"outputs","id":"DBGBLz67LfcGikiS-HIGL","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n27\n"},"children":[],"key":"PK4yJJTXd8"}],"key":"hT6LEG6xJR"}],"key":"BUqH4iBwqW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def build_dataset(words, block_size):\n    x, y = [], []\n    for w in words:\n        context = [0] * block_size\n        for ch in w + \".\":\n            ix = ctoi[ch]\n            x.append(context)\n            y.append(ix)\n            context = context[1:] + [ix]  # crop and append\n    x = torch.tensor(x)\n    y = torch.tensor(y)\n    print(x.shape, y.shape)\n    return x, y","key":"qBxkeyvDlf"},{"type":"outputs","id":"LDuYzJi3LPMb_ThnN_MCf","children":[],"key":"FSaOPUox6r"}],"key":"omYpA1ZYdN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def build_all_datasets(block_size):\n    random.shuffle(words)\n    n1 = int(0.8 * len(words))\n    n2 = int(0.9 * len(words))\n    xtrain_dataset = build_dataset(words[:n1], block_size)  # 80%\n    xval_dataset = build_dataset(words[n1:n2], block_size)  # 10%\n    xtest_dataset = build_dataset(words[n2:], block_size)  # 10%\n    return xtrain_dataset, xval_dataset, xtest_dataset","key":"dDkvpArQXr"},{"type":"outputs","id":"8O2d2RtKANrJD3iaH46Dw","children":[],"key":"ZnGoFTkjRg"}],"key":"vXoRrqFrsB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def print_next_character(xtrain, ytrain):\n    for x, y in zip(xtrain, ytrain):\n        print(\"\".join(itoc[ix.item()] for ix in x), \"--\u003e\", itoc[y.item()])","key":"p3T2zM2Ef5"},{"type":"outputs","id":"mSK7v0_RFDFe55WSHxv6Z","children":[],"key":"EoxzfsXTlf"}],"key":"t8LVQ6mA16"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Specifically many examples of...","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YZWts3shzs"}],"key":"LRlPkj5o9d"}],"key":"MU7cIifojZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"block_size = (\n    3  # context length: how many characters do we take to predict the next one?\n)\n(xtrain, ytrain), (xval, yval), (xtest, ytest) = build_all_datasets(block_size)","key":"GLLA77V1Yq"},{"type":"outputs","id":"R2IqfMSwmw121wf-XALYL","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"torch.Size([182625, 3]) torch.Size([182625])\ntorch.Size([22655, 3]) torch.Size([22655])\ntorch.Size([22866, 3]) torch.Size([22866])\n"},"children":[],"key":"cGOEtJjjt5"}],"key":"fM9dIbwGxW"}],"key":"gjbR5N8z8B"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"... ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZFezRpWEYR"},{"type":"inlineCode","value":"block_size=3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XqVh4TI1D9"},{"type":"text","value":" characters and we are trying to predict the fourth one:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M6NAMeGzpT"}],"key":"K0GCCOkO1r"}],"key":"D7QU5kv22P"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print_next_character(xtrain[:20], ytrain[:20])","key":"UHQnyTYd7Q"},{"type":"outputs","id":"oOeRfEiqSoyaME5huq7TV","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"... --\u003e y\n..y --\u003e u\n.yu --\u003e h\nyuh --\u003e e\nuhe --\u003e n\nhen --\u003e g\neng --\u003e .\n... --\u003e d\n..d --\u003e i\n.di --\u003e o\ndio --\u003e n\nion --\u003e d\nond --\u003e r\nndr --\u003e e\ndre --\u003e .\n... --\u003e x\n..x --\u003e a\n.xa --\u003e v\nxav --\u003e i\navi --\u003e e\n"},"children":[],"key":"KkoXhXLEbQ"}],"key":"cFiEo8tmfs"}],"key":"xrTydKSNEI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Basically, we are breaking down each of these word into little problems of “given ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YeCNSRobUL"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k4SO94bLHx"},{"type":"text","value":" characters, predict the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IYkUt8nFpo"},{"type":"inlineMath","value":"4th","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UKdiHJ3JBU"},{"type":"text","value":" one”. So this is our data set and this is what we’re trying to get the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MtCJLy6bzn"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fbcuEjRT7x"}],"key":"iEiYS1Lczz"},{"type":"text","value":" to do. Now in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CIEYaSeGOJ"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"makemore","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NGG7UDuFoR"}],"key":"YhutuvRGNm"},{"type":"text","value":" (part 3), we started to develop our code around these following layer modules. We’re doing this because we want to think of these modules as lego building blocks that we can sort of stack up into ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SEPqjxMJ1Z"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kMXaVGS51p"}],"key":"NpIYvvTJHo"},{"type":"text","value":"s and we can feed data between these layers and stack them up into sort of graphs. Now we also developed these layers to have APIs and signatures very similar to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fkbrzm6Erx"},{"type":"link","url":"https://pytorch.org/docs/stable/nn.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"those that are found in PyTorch","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PkKQDUNvUg"}],"urlSource":"https://pytorch.org/docs/stable/nn.html","key":"TvfeN5r5gI"},{"type":"text","value":". And so we have the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"A3ru1qM3Lv"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TLRbgOBINU"},{"type":"text","value":" layer, the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aumJsSfBzr"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oXLOPmVSpq"},{"type":"text","value":" layer and the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MEnmdMKxAg"},{"type":"inlineCode","value":"Tanh","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Yk5f0MKPfW"},{"type":"text","value":" layer that we developed previously:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"slp3KCdjWq"}],"key":"DGPvIXnr9x"}],"key":"S4oaeRJKr0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class Linear:\n    def __init__(self, fan_in, fan_out, bias=True):\n        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n        self.bias = torch.zeros(fan_out) if bias else None\n\n    def __call__(self, x):\n        self.out = x @ self.weight\n        if self.bias is not None:\n            self.out += self.bias\n        return self.out\n\n    def parameters(self):\n        return [self.weight] + ([] if self.bias is None else [self.bias])\n\n\nclass BatchNorm1d:\n    def __init__(self, dim, eps=1e-5, momentum=0.1):\n        self.eps = eps\n        self.momentum = momentum\n        self.training = True\n        # parameters (trained with backprop)\n        self.gamma = torch.ones(dim)\n        self.beta = torch.zeros(dim)\n        # buffers (trained with a running 'momentum update')\n        self.running_mean = torch.zeros(dim)\n        self.running_var = torch.ones(dim)\n\n    def __call__(self, x):\n        # calculate the forward pass\n        if self.training:\n            xmean = x.mean(0, keepdim=True)  # batch mean\n            xvar = x.var(0, keepdim=True)  # batch variance\n        else:\n            xmean = self.running_mean\n            xvar = self.running_var\n        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # normalize to unit variance\n        self.out = self.gamma * xhat + self.beta\n        # update the buffers\n        if self.training:\n            with torch.no_grad():\n                self.running_mean = (\n                    1 - self.momentum\n                ) * self.running_mean + self.momentum * xmean\n                self.running_var = (\n                    1 - self.momentum\n                ) * self.running_var + self.momentum * xvar\n        return self.out\n\n    def parameters(self):\n        return [self.gamma, self.beta]\n\n\nclass Tanh:\n    def __call__(self, x):\n        self.out = torch.tanh(x)\n        return self.out\n\n    def parameters(self):\n        return []","key":"meYWItMsuL"},{"type":"outputs","id":"c-pF4fthSWEhE2mmvhdLF","children":[],"key":"a97L6f129p"}],"key":"jyZddX0WWg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Αnd ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hpA75jpujx"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BXH9zoG9od"},{"type":"text","value":" just does a matrix multiply in the forward pass of this module, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DdhWkyAIBS"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mHZfVN7wm5"},{"type":"text","value":" of course is this crazy layer that we developed in the previous lecture. What’s crazy about it is... well there’s many things. Number one, it has these running mean and variances that are trained outside of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qe7uG7IR1P"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"backprop","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jasptPv6HX"}],"key":"KYlpMxQ4Dc"},{"type":"text","value":". They are trained using exponential moving average inside this layer when we call the forward pass. In addition to that, there’s this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XGpccpVpjQ"},{"type":"inlineCode","value":"self.training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PkeWHbJE8q"},{"type":"text","value":" flag because the behavior of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uTlp7rShh3"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vW44P8Vywq"}],"key":"uejC9ECl5p"},{"type":"text","value":" is different during train time and evaluation time. And so suddenly we have to be very careful that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DlyFyittQH"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"euSbMG4hOG"}],"key":"gMHMVLbXEP"},{"type":"text","value":" is in its correct state. That it’s in the evaluation state or training state. So that’s something to now keep track of something that sometimes introduces bugs because you forget to put it into the right mode. And finally, we saw that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ScHFTaWcQx"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HkTlnlOPxX"}],"key":"NKHVUiWbPB"},{"type":"text","value":" couples the statistics or the activations across the examples in the batch. So normally we thought of the batch as just an efficiency thing, but now we are coupling the computation across batch elements and it’s done for the purposes of controlling the activation statistics as we saw in the previous video. So ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CYNAkWB6P8"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AISKkZL496"}],"key":"MNo8ZTyZUU"},{"type":"text","value":" is a very weird layer because you have to modulate the training and eval phase. What’s more, you have to wait for the mean and the variance to settle and to actually reach a steady state and a state can become the source of many bugs, usually. And now let’s define the appropriate functions:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u65ansGNxO"}],"key":"OLSVZBY7bp"}],"key":"HOuVYT4Nss"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# seed rng for reproducability\ntorch.manual_seed(42)","key":"w7VpSc1kyy"},{"type":"outputs","id":"_JNqOPsMT7aWWyT3et3PC","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":23,"metadata":{},"data":{"text/plain":{"content":"\u003ctorch._C.Generator at 0x7ffa740b3d90\u003e","content_type":"text/plain"}}},"children":[],"key":"pxyJnM8Cqh"}],"key":"xV4k5wJpS5"}],"key":"Vbji2r0eJy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"n_embd = 10  # the dimensionality of the character embedding vectors\nn_hidden = 200  # the number of neurons in the hidden layer of the MLP\n\n\ndef define_nn(block_size, n_embd, n_hidden):\n    global C\n    C = torch.randn((vocab_size, n_embd))\n    n_inputs = n_embd * block_size\n    n_outputs = vocab_size\n    layers = [\n        Linear(n_inputs, n_hidden, bias=False),\n        BatchNorm1d(n_hidden),\n        Tanh(),\n        Linear(n_hidden, n_outputs),\n    ]\n    # parameter init\n    with torch.no_grad():\n        layers[-1].weight *= 0.1  # last layer make less confident\n    parameters = [C] + [p for l in layers for p in l.parameters()]\n    print(sum(p.nelement() for p in parameters))  # number of parameters in total\n    for p in parameters:\n        p.requires_grad = True\n    return layers, parameters","key":"RaOdD21H0h"},{"type":"outputs","id":"O57WZTCNtMWLX3CRMdMEp","children":[],"key":"O66V4vOe1A"}],"key":"sZkgTVljvO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def forward(layers, xb, yb):\n    emb = C[xb]  # embed the characters into vectors\n    x = emb.view(emb.shape[0], -1)  # concatenate the vectors\n    for layer in layers:\n        x = layer(x)\n    loss = F.cross_entropy(x, yb)  # loss function\n    return loss","key":"d71cMJp9nj"},{"type":"outputs","id":"Eif4uhepV4eC1LtXbRAY6","children":[],"key":"cVTtcWsVTH"}],"key":"G3f1opnAGf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def backward(parameters, loss):\n    for p in parameters:\n        p.grad = None\n    loss.backward()","key":"uPBsyKxpja"},{"type":"outputs","id":"oWbkSWbwdIOltHVgnbwyb","children":[],"key":"LQqlG4QxtH"}],"key":"AB4JhJ1tuw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def update(parameters, lr):\n    for p in parameters:\n        p.data += -lr * p.grad","key":"NsE4qGODj2"},{"type":"outputs","id":"EpJ65XGPjAbhcPiSWo22A","children":[],"key":"rrkqaAQDaY"}],"key":"JnlfbIyFz4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def train(\n    x,\n    y,\n    layers,\n    parameters,\n    initial_lr=0.1,\n    maxsteps=200000,\n    batchsize=32,\n    break_at_step=None,\n):\n    lossi = []\n    for i in range(maxsteps):\n        # minibatch construct\n        bix = torch.randint(0, x.shape[0], (batchsize,))\n        xb, yb = x[bix], y[bix]\n        loss = forward(layers, xb, yb)\n        backward(parameters, loss)\n        lr = initial_lr if i \u003c 150000 else initial_lr / 10\n        update(parameters, lr=lr)\n        # track stats\n        if i % 10000 == 0:  # print every once in a while\n            print(f\"{i:7d}/{maxsteps:7d}: {loss.item():.4f}\")\n        lossi.append(loss.log10().item())\n        if break_at_step is not None and i \u003e= break_at_step:\n            break\n    return lossi","key":"RmRTceCWHi"},{"type":"outputs","id":"TgHgPJEnVCmDOSXS14Bqc","children":[],"key":"ZotMAK3eyX"}],"key":"oEEoKETUls"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def trigger_eval_mode(layers):\n    for l in layers:\n        l.training = False","key":"mqjblymBat"},{"type":"outputs","id":"9Z7pW0DGiWNAtd3v_UK1v","children":[],"key":"wsJG9VLaoR"}],"key":"EEjHwECG7C"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@torch.no_grad()\ndef infer_loss(layers, x, y, prefix=\"\"):\n    loss = forward(layers, x, y)\n    print(f\"{prefix} {loss}\")\n    return loss","key":"hiSDE49YRz"},{"type":"outputs","id":"T6EsbxbhyzRy2atNl-e7u","children":[],"key":"x25yx99kMF"}],"key":"Dc7LpU49TK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def sample_from_model(block_size, layers):\n    for _ in range(20):\n        out = []\n        context = [0] * block_size  # initialize with all ...\n        while True:\n            # forward pass the neural net\n            emb = C[torch.tensor([context])]  # (1, block_size, n_embd)\n            x = emb.view(emb.shape[0], -1)  # concatenate the vectors\n            for l in layers:\n                x = l(x)\n            logits = x\n            probs = F.softmax(logits, dim=1)\n            # sample from the distribution\n            ix = torch.multinomial(probs, num_samples=1).item()\n            # shift the context window and track the samples\n            context = context[1:] + [ix]\n            out.append(ix)\n            # if we sample the special '.' token, break\n            if ix == 0:\n                break\n        print(\"\".join(itoc[i] for i in out))  # decode and print the generated word","key":"qH1OQzvdBq"},{"type":"outputs","id":"CNPPwphliT3Ul4XJEY-m-","children":[],"key":"dBfjyTc5YW"}],"key":"k3TO2phxOv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"These should look somewhat familiar to you by now. Let’s train!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ChTR1VVe1L"}],"key":"tNi3RYWRt9"}],"key":"IHfbRx4nqT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"layers, parameters = define_nn(block_size, n_embd, n_hidden)\nlossi = train(xtrain, ytrain, layers, parameters)","key":"QGwis33TFL"},{"type":"outputs","id":"vo_98IKNsIvzePnigEMtX","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"12097\n      0/ 200000: 3.2966\n"},"children":[],"key":"KHUGzLnu5P"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"  10000/ 200000: 2.2322\n  20000/ 200000: 2.4111\n  30000/ 200000: 2.1004\n  40000/ 200000: 2.3157\n  50000/ 200000: 2.2104\n  60000/ 200000: 1.9653\n  70000/ 200000: 1.9767\n  80000/ 200000: 2.6738\n  90000/ 200000: 2.0837\n 100000/ 200000: 2.2730\n 110000/ 200000: 1.7491\n 120000/ 200000: 2.2891\n 130000/ 200000: 2.3443\n 140000/ 200000: 2.1731\n 150000/ 200000: 1.8246\n 160000/ 200000: 1.7614\n 170000/ 200000: 2.2419\n 180000/ 200000: 2.0803\n 190000/ 200000: 2.1326\n"},"children":[],"key":"gLxikmf3kK"}],"key":"Efr7jrWEGE"}],"key":"FDv9cBuXft"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(lossi);","key":"anaUb3XfXe"},{"type":"outputs","id":"qNFW6sRX3muR05N4B-dWK","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"c0ff1cdd47ba47c79578bbd5f0c5f983\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"48e19c2cf41d8f75fc83c18d5baccf0d","path":"/build/48e19c2cf41d8f75fc83c18d5baccf0d.png"},"text/html":{"content_type":"text/html","hash":"a25d5bfbebab9c1f574ead8922d0b080","path":"/build/a25d5bfbebab9c1f574ead8922d0b080.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"rlKmTYz7B5"}],"key":"OVxlkkrGhN"}],"key":"XWp398CTu8"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rtqDL38beQ"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Uf41amjSdS"}],"key":"HyYxYun4BU"},{"type":"text","value":" function looks very crazy. We should probably fix this. And that’s because ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lP4u4jwDOI"},{"type":"text","value":"32","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dlNd952FyJ"},{"type":"text","value":" batch elements are too few. And so you can get very lucky or unlucky in any one of these batches, and it creates a very thicc ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m1eLSvA2ro"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XqWgQiKVGe"}],"key":"NagYKU5LTz"},{"type":"text","value":" function. So we’re gonna fix that soon. Now, before we evaluate the trained ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q6LTZPv2CX"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OlCcX2tjtp"}],"key":"z0FU9Ddzvw"},{"type":"text","value":" by inferring the training and validation ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k0U5eYIUnd"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"z1aKcIlOfo"}],"key":"eydqlPEBPr"},{"type":"text","value":", we need to remember because of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e1OBgmOgQy"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jLpStq17YR"}],"key":"CVQw0vsTWo"},{"type":"text","value":" layers to set all the layers’ ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rnLDGOwqFD"},{"type":"inlineCode","value":"training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vH7EX4msDV"},{"type":"text","value":" flag to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MhhY5i3dM4"},{"type":"inlineCode","value":"False","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CGCCDoz9WH"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Dyt1aWVVbw"}],"key":"cchbaAsS7W"}],"key":"wEPxgNjsvS"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"trigger_eval_mode(layers)\ninfer_loss(layers, xtrain, ytrain, prefix=\"train\")\ninfer_loss(layers, xval, yval, prefix=\"val\");","key":"EBAiEcYUET"},{"type":"outputs","id":"Nj4VXOaNYKv1znYlBxwXY","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"train 2.0583250522613525\nval 2.1065292358398438\n"},"children":[],"key":"Rwz6tqDM8s"}],"key":"aTubOpYxeN"}],"key":"stUExqdq9P"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We still have a ways to go, as far as the validation ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"chI61rpYdG"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vM8L4uQrAs"}],"key":"KchcsIcIGb"},{"type":"text","value":" is concerned. But if we sample from our model, we see that we get relatively name-like results that do no exist in the training set:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pdH2Vr5GQM"}],"key":"gqqLRaGVt8"}],"key":"kJ4H7TA8Ki"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sample_from_model(block_size=block_size, layers=layers)","key":"ejLLoW7lJd"},{"type":"outputs","id":"dX7VMLucaSO2Mp98cJ3z1","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"damiara.\nalyzah.\nfard.\nazalee.\nsayah.\nayvi.\nreino.\nsophemuellani.\nciaub.\nalith.\nsira.\nliza.\njah.\ngrancealynna.\njamaur.\nben.\nquan.\ntorie.\ncoria.\ncer.\n"},"children":[],"key":"vMeuHYPKXs"}],"key":"MFlttYk7pp"}],"key":"wooaBiAO5S"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"But we can improve our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cfisiodk1l"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OJbfheiJIk"}],"key":"unZ5256WAm"},{"type":"text","value":" and improve our results even further. We’ll start by fixing that thicc loss plot!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"A8W2qdCHlo"}],"key":"UMKaHmxagl"}],"key":"QkLGpvI0OG"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fixing the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OOLDEyWzhJ"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qy6WTIEqef"}],"key":"ibPsPD5MHy"},{"type":"text","value":" plot","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DFUuYfJARE"}],"identifier":"fixing-the-loss-plot","label":"Fixing the loss plot","html_id":"fixing-the-loss-plot","implicit":true,"key":"ZSZayVF5tp"}],"key":"eGIZdCKHQ0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"One way to turn this thicc loss plot into a normal one is to only plot the mean. Remember, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l4Zo09gwOL"},{"type":"inlineCode","value":"lossi","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EfeSQv0TOc"},{"type":"text","value":" is a very long list of floats that contains a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yu8btS5jCL"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IGAGAGNh5K"}],"key":"wtsYji57JY"},{"type":"text","value":" for each training episode:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rTQ1U5ymjT"}],"key":"wgZRFczWLa"}],"key":"OZjxc6khDg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"len(lossi), lossi[:5]","key":"fx2xahjXpR"},{"type":"outputs","id":"iH0ZsWMebgOjEm3szyM-0","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":36,"metadata":{},"data":{"text/plain":{"content":"(200000,\n [0.5180676579475403,\n  0.5164594054222107,\n  0.507362961769104,\n  0.507546603679657,\n  0.4992470443248749])","content_type":"text/plain"}}},"children":[],"key":"w4K8oyC4rr"}],"key":"vRYH5bokAM"}],"key":"a6bhVnwFPy"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s segment this very long list into a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dWkPoBPjVk"},{"type":"inlineMath","value":"2D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"er0vzoqr2h"},{"type":"text","value":" tensor of rows, with each row containing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QjXdPmtGwh"},{"type":"text","value":"1000","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yW0lPcIqWy"},{"type":"text","value":" loss values:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dJe2mYiVDX"}],"key":"gntajX001S"}],"key":"UMGzPWFB8s"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"t_loss = torch.tensor(lossi).view(-1, 1000)\nt_loss","key":"y7o9bNpRZS"},{"type":"outputs","id":"ZA0xa8aMHeZbsLx3x0N5s","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":37,"metadata":{},"data":{"text/plain":{"content":"tensor([[0.5181, 0.5165, 0.5074,  ..., 0.4204, 0.3860, 0.4014],\n        [0.3937, 0.3930, 0.4177,  ..., 0.3788, 0.3896, 0.4054],\n        [0.3426, 0.4191, 0.3918,  ..., 0.4447, 0.4419, 0.2821],\n        ...,\n        [0.3625, 0.3517, 0.3376,  ..., 0.3266, 0.3191, 0.3271],\n        [0.2550, 0.3659, 0.2968,  ..., 0.2744, 0.3853, 0.3300],\n        [0.3041, 0.2740, 0.3213,  ..., 0.3081, 0.4082, 0.3207]])","content_type":"text/plain"}}},"children":[],"key":"QxTUObdPPC"}],"key":"drdBuudBnA"}],"key":"eBcJK1x379"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, if we take the mean of each row, we end up with a list of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Nl1rzx8d9p"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jiAr7Gd0IE"}],"key":"ZV257dmHWD"},{"type":"text","value":" averages:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xoZqbrYltR"}],"key":"CugEReq64m"}],"key":"AdVrkiDGqd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"mean_t_loss = t_loss.mean(1)\nmean_t_loss","key":"Ve2emfkXxh"},{"type":"outputs","id":"-S76SXC9pTpbL2W0qTnO8","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":38,"metadata":{},"data":{"text/plain":{"content":"tensor([0.4059, 0.3791, 0.3698, 0.3681, 0.3657, 0.3639, 0.3624, 0.3593, 0.3557,\n        0.3561, 0.3516, 0.3515, 0.3504, 0.3501, 0.3491, 0.3477, 0.3498, 0.3474,\n        0.3494, 0.3449, 0.3456, 0.3440, 0.3452, 0.3461, 0.3429, 0.3456, 0.3458,\n        0.3438, 0.3408, 0.3437, 0.3435, 0.3407, 0.3424, 0.3412, 0.3415, 0.3404,\n        0.3419, 0.3391, 0.3414, 0.3396, 0.3392, 0.3408, 0.3394, 0.3416, 0.3389,\n        0.3390, 0.3376, 0.3407, 0.3364, 0.3376, 0.3393, 0.3362, 0.3371, 0.3349,\n        0.3393, 0.3369, 0.3363, 0.3349, 0.3338, 0.3386, 0.3366, 0.3388, 0.3370,\n        0.3379, 0.3349, 0.3378, 0.3325, 0.3358, 0.3353, 0.3390, 0.3369, 0.3366,\n        0.3354, 0.3350, 0.3375, 0.3347, 0.3352, 0.3352, 0.3318, 0.3359, 0.3348,\n        0.3338, 0.3350, 0.3367, 0.3331, 0.3333, 0.3346, 0.3356, 0.3339, 0.3339,\n        0.3332, 0.3331, 0.3352, 0.3356, 0.3350, 0.3335, 0.3330, 0.3299, 0.3344,\n        0.3350, 0.3318, 0.3295, 0.3328, 0.3336, 0.3345, 0.3341, 0.3319, 0.3342,\n        0.3329, 0.3299, 0.3346, 0.3312, 0.3312, 0.3344, 0.3340, 0.3305, 0.3319,\n        0.3344, 0.3302, 0.3315, 0.3335, 0.3319, 0.3345, 0.3326, 0.3331, 0.3319,\n        0.3317, 0.3331, 0.3316, 0.3313, 0.3319, 0.3340, 0.3306, 0.3329, 0.3306,\n        0.3322, 0.3332, 0.3313, 0.3309, 0.3348, 0.3297, 0.3324, 0.3305, 0.3311,\n        0.3316, 0.3308, 0.3301, 0.3323, 0.3289, 0.3313, 0.3199, 0.3201, 0.3196,\n        0.3233, 0.3184, 0.3179, 0.3180, 0.3172, 0.3175, 0.3176, 0.3200, 0.3194,\n        0.3196, 0.3195, 0.3186, 0.3166, 0.3192, 0.3179, 0.3168, 0.3171, 0.3173,\n        0.3188, 0.3175, 0.3176, 0.3174, 0.3197, 0.3182, 0.3167, 0.3187, 0.3217,\n        0.3165, 0.3187, 0.3144, 0.3165, 0.3183, 0.3187, 0.3179, 0.3161, 0.3182,\n        0.3177, 0.3171, 0.3187, 0.3194, 0.3183, 0.3157, 0.3156, 0.3167, 0.3168,\n        0.3187, 0.3179])","content_type":"text/plain"}}},"children":[],"key":"vardLAJnbs"}],"key":"Fse4xokuRX"}],"key":"jgRf9n5L2d"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"If we plot this tensor list of mean losses, we should get a nicer ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TGGTInIjgt"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LvKMsTWhWO"}],"key":"BE8c3JU6GM"},{"type":"text","value":" plot:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dVJ6JtMjGr"}],"key":"BxCVJ6igDi"}],"key":"Lw5ESRoZdr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(mean_t_loss);","key":"KrlZK56rzY"},{"type":"outputs","id":"rO63x-DcxkXoHJ00ni1I0","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"42dc20cba22c45458c6f9877637adf70\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"5d9ce90e435b7c612969d574e5fe3c25","path":"/build/5d9ce90e435b7c612969d574e5fe3c25.png"},"text/html":{"content_type":"text/html","hash":"069f0424ea33d6e559bb93a29a286a49","path":"/build/069f0424ea33d6e559bb93a29a286a49.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"FdBrr32kgy"}],"key":"qWDNRmHqi1"}],"key":"udndiLOrRV"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, the progress we make during training is much more clearly visible! Also, notice the learning rate decay, where the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h3ybE4oBxI"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GafF6VS7SM"}],"key":"HgT224xQnb"},{"type":"text","value":" drops to a even lower minimum. This is the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UHvnRIVf1M"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a9gIiNfOpn"}],"key":"nb3WoLm2hW"},{"type":"text","value":" plot we are going to be using going forward.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vKmlIZVyzK"}],"key":"xKLXQJgPws"}],"key":"RHFG1ngy9o"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"torchifying the code: layers, containers, torch.nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mhK0uE7eIr"}],"identifier":"torchifying-the-code-layers-containers-torch-nn","label":"torchifying the code: layers, containers, torch.nn","html_id":"torchifying-the-code-layers-containers-torch-nn","implicit":true,"key":"f6wTpa4v2k"}],"visibility":"show","key":"KOG28M8y8M"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now it’s time to simplify our forward function a little bit. Notice how the embeddings and flattening operations are calculated outside of the layers:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lbU3bpVrK5"}],"key":"nqXWQuYpao"}],"key":"Ue87bOVogJ"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"def forward(layers, xb, yb):\n    emb = C[xb] # embed the characters into vectors\n    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n    for layer in layers:\n        ...","position":{"start":{"line":1,"column":1},"end":{"line":7,"column":1}},"key":"ih12LNKGtF"}],"key":"H2wSDXWQPP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To start tidying things up, let’s mirror ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dRIrX6Tnbi"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn.Embedding","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Oju1oiOYa6"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding","key":"pgVzk4MNOc"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"p7DdoiYozv"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn.Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TayC0O6UCq"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten","key":"r1iBfvsvpV"},{"type":"text","value":" with our own incredibly simplified equivalent modules:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CIdAQdfMY0"}],"key":"jk15Py19Kd"}],"key":"CNMu1b8Q0L"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class Embedding:\n    def __init__(self, n_embd, embd_dim):\n        self.weight = torch.randn((n_embd, embd_dim))\n\n    def __call__(self, ix):\n        self.out = self.weight[ix]\n        return self.out\n\n    def parameters(self):\n        return [self.weight]","key":"z4mALd1eE0"},{"type":"outputs","id":"GerpfKAacMgtsdNRcmecH","children":[],"key":"b20nlCjANB"}],"key":"mGb81AQ7mF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class Flatten:\n    def __call__(self, x):\n        self.out = x.view(x.shape[0], -1)\n        return self.out\n\n    def parameters(self):\n        return []","key":"qSlA4BI1gu"},{"type":"outputs","id":"Qq-rL4z5bhZ3jFtzjxVd5","children":[],"key":"cKZ3WQCDeI"}],"key":"VyJVe3UNNd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"These will simply be responsible for indexing and flattening. We can now simplify our forward pass by including the embedding and flattening operations as modules in the definition of the layers:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hfbd3yXkSL"}],"key":"It2hysyX5k"}],"key":"VIGWhlwNSp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def define_nn(block_size, n_embd, n_hidden):\n    n_inputs = n_embd * block_size\n    n_outputs = vocab_size\n    layers = [\n        Embedding(vocab_size, n_embd),\n        Flatten(),\n        Linear(n_inputs, n_hidden, bias=False),\n        BatchNorm1d(n_hidden),\n        Tanh(),\n        Linear(n_hidden, n_outputs),\n    ]\n    # parameter init\n    with torch.no_grad():\n        layers[-1].weight *= 0.1  # last layer make less confident\n    parameters = [p for l in layers for p in l.parameters()]\n    print(sum(p.nelement() for p in parameters))  # number of parameters in total\n    for p in parameters:\n        p.requires_grad = True\n    return layers, parameters","key":"EBrM4sjNRM"},{"type":"outputs","id":"LSq6Zc5Ia-ysRHSGkqiue","children":[],"key":"bZ6cYdIiDJ"}],"key":"WGsGfP0Eh3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def forward(layers, xb, yb):\n    x = xb\n    for layer in layers:\n        x = layer(x)\n    loss = F.cross_entropy(x, yb)  # loss function\n    return loss","key":"EmFaNVmrtC"},{"type":"outputs","id":"4M0d3TpbYx_9WbTgPwi5a","children":[],"key":"i5DpYX1sLY"}],"key":"EI4MWA1eiU"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Awesome. Now we can even further simplify our forward pass by replacing the list that contains our layers with our simplified implementation of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZKrxtwvVRI"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn.Sequential","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kUFzUvtu05"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential","key":"hN1Cd5jhx3"},{"type":"text","value":" container: this object contains layers and the functionality to iteratively pass data through them. Meaning that we now define a bunch of layers as a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"igxMvs0dFL"},{"type":"inlineCode","value":"Sequential","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l1sIj4n9dm"},{"type":"text","value":" object (i.e. a model) through which we can pass input data (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DdHA633qAR"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b8PTEuyQHf"},{"type":"text","value":"), without the need to explicitly loop.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O9wsvjWGcR"}],"key":"G2M7tsRRAQ"}],"key":"kk6vRN9Ygh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class Sequential:\n    def __init__(self, layers):\n        self.layers = layers\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        self.out = x\n        return self.out\n\n    def parameters(self):\n        # get parameters of all layers and stretch them out into one list\n        return [p for layer in self.layers for p in layer.parameters()]","key":"dZqYFSyYwk"},{"type":"outputs","id":"Hxsv_x4Lsu9g8Pu56VkKI","children":[],"key":"DetI3kog6t"}],"key":"zFeiUbMxvt"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s now further simplify our functions by replacing the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QMjs5Bs6MY"},{"type":"inlineCode","value":"layers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CigdIvVyOR"},{"type":"text","value":" list with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cABNdzTZvG"},{"type":"inlineCode","value":"model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CVvKCuk9pu"},{"type":"text","value":", a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vAtoDGatVh"},{"type":"inlineCode","value":"Sequential","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mCQPgTkT9G"},{"type":"text","value":" object:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zzJpizCNsI"}],"key":"iRQMyTIaFv"}],"key":"I6tgtMTA3S"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def define_nn(block_size, n_embd, n_hidden):\n    n_inputs = n_embd * block_size\n    n_outputs = vocab_size\n    model = Sequential(\n        [\n            Embedding(vocab_size, n_embd),\n            Flatten(),\n            Linear(n_inputs, n_hidden, bias=False),\n            BatchNorm1d(n_hidden),\n            Tanh(),\n            Linear(n_hidden, n_outputs),\n        ]\n    )\n    # parameter init\n    with torch.no_grad():\n        model.layers[-1].weight *= 0.1  # last layer make less confident\n    parameters = model.parameters()\n    print(sum(p.nelement() for p in parameters))  # number of parameters in total\n    for p in parameters:\n        p.requires_grad = True\n    return model, parameters","key":"o4uUXypG47"},{"type":"outputs","id":"hMfnBt86GnWdV_7R7bfQo","children":[],"key":"R5yCZgietB"}],"key":"VbQa9DkvEe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def forward(model, xb, yb):\n    logits = model(xb)\n    loss = F.cross_entropy(logits, yb)  # loss function\n    return loss","key":"D4u5UjQlnk"},{"type":"outputs","id":"9QRsLRXYtz7PMr75LzedO","children":[],"key":"iDohKJuaAc"}],"key":"jMOCLc3I1W"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def train(\n    x,\n    y,\n    model,\n    parameters,\n    initial_lr=0.1,\n    maxsteps=200000,\n    batchsize=32,\n    break_at_step=None,\n):\n    lossi = []\n    for i in range(maxsteps):\n        # minibatch construct\n        bix = torch.randint(0, x.shape[0], (batchsize,))\n        xb, yb = x[bix], y[bix]\n        loss = forward(model, xb, yb)\n        backward(parameters, loss)\n        lr = initial_lr if i \u003c 150000 else initial_lr / 10\n        update(parameters, lr=lr)\n        # track stats\n        if i % 10000 == 0:  # print every once in a while\n            print(f\"{i:7d}/{maxsteps:7d}: {loss.item():.4f}\")\n        lossi.append(loss.log10().item())\n        if break_at_step is not None and i \u003e= break_at_step:\n            break\n    return lossi","key":"aDvpm2wXv1"},{"type":"outputs","id":"haDFvZocagjzaefyu5CSZ","children":[],"key":"gCv8a5q1D1"}],"key":"AmiqxqeXvV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def trigger_eval_mode(model):\n    for l in model.layers:\n        l.training = False","key":"gSH1664QjX"},{"type":"outputs","id":"fGFfMu-h0Y5QdNNc5nKJB","children":[],"key":"BgB0F5SLch"}],"key":"JPs9AcBxDJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"@torch.no_grad()\ndef infer_loss(model, x, y, prefix=\"\"):\n    loss = forward(model, x, y)\n    print(f\"{prefix} {loss}\")\n    return loss","key":"fihdPlEjur"},{"type":"outputs","id":"ogbd5aE0a95dL4LBGbDky","children":[],"key":"PvwEv60V3h"}],"key":"FcY5j4fT2U"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def sample_from_model(block_size, model):\n    for _ in range(20):\n        out = []\n        context = [0] * block_size  # initialize with all ...\n        while True:\n            # forward pass the neural net\n            logits = model(torch.tensor([context]))\n            probs = F.softmax(logits, dim=1)\n            # sample from the distribution\n            ix = torch.multinomial(probs, num_samples=1).item()\n            # shift the context window and track the samples\n            context = context[1:] + [ix]\n            out.append(ix)\n            # if we sample the special '.' token, break\n            if ix == 0:\n                break\n        print(\"\".join(itoc[i] for i in out))  # decode and print the generated word","key":"fvKONUWAIf"},{"type":"outputs","id":"fCw37VGEhqUGxxfJUgQsM","children":[],"key":"G5R9Ioy2eP"}],"key":"aYrUeMtLmd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And let’s verify that our new definitions work by re-training our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dOQqJe6uF1"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"y6rjy49V9r"}],"key":"QFNvHadaqE"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jsYZG6oyfP"}],"key":"t0QCj013Rt"}],"key":"oezuUBGvgq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, parameters = define_nn(block_size, n_embd, n_hidden)\nlossi = train(xtrain, ytrain, model, parameters)","key":"XNhN7RttnM"},{"type":"outputs","id":"dBExKyNGTCopCOUTnZttS","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"12097\n      0/ 200000: 3.3055\n  10000/ 200000: 2.1954\n  20000/ 200000: 2.2630\n  30000/ 200000: 2.0618\n  40000/ 200000: 2.0468\n  50000/ 200000: 2.1775\n  60000/ 200000: 2.1750\n  70000/ 200000: 1.9390\n  80000/ 200000: 2.1816\n  90000/ 200000: 2.0516\n 100000/ 200000: 2.0578\n 110000/ 200000: 2.2706\n 120000/ 200000: 2.3313\n 130000/ 200000: 2.1557\n 140000/ 200000: 2.0983\n 150000/ 200000: 1.9418\n 160000/ 200000: 1.9421\n 170000/ 200000: 2.1256\n 180000/ 200000: 2.2467\n 190000/ 200000: 1.6821\n"},"children":[],"key":"QQDlGdym66"}],"key":"TdQwKGI9F1"}],"key":"g0AcK4m94J"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));","key":"FdTXYaF0v9"},{"type":"outputs","id":"G0IKFvTptWOpAvGuGQF_s","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"3bb3fea1b9d14a5aa8d6287c63f7ddac\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"dc071225b20724ced3b45fdcad310314","path":"/build/dc071225b20724ced3b45fdcad310314.png"},"text/html":{"content_type":"text/html","hash":"528384c689a08e25b51452974422c1bb","path":"/build/528384c689a08e25b51452974422c1bb.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"C9pAlAwXFf"}],"key":"O7psvJtSmG"}],"key":"ENXZjTZTZT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"trigger_eval_mode(model)\ninfer_loss(model, xtrain, ytrain, prefix=\"train\")\ninfer_loss(model, xval, yval, prefix=\"val\");","key":"HU3F4Tx2WV"},{"type":"outputs","id":"L_76Uz5PMsmHnsCGy6a2S","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"train 2.0581207275390625\nval 2.105104684829712\n"},"children":[],"key":"RFgm6qO2D8"}],"key":"FkjnRcJfcT"}],"key":"muyRAGzxNt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sample_from_model(block_size, model)","key":"UptIgGD4qJ"},{"type":"outputs","id":"8EuJfNACQqvwJJGhKNRZI","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"masea.\niman.\nryy.\nayee.\nhavajine.\nmiliakendalikain.\namagntanton.\naviona.\njah.\nwiseegh.\navon.\nman.\ntovi.\nsullessa.\nmarcuz.\njazia.\nabellabell.\nathin.\nahkiara.\nkrister.\n"},"children":[],"key":"WuH44cV31E"}],"key":"oC5vlYIfCA"}],"key":"LfW5Jc7N3K"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Cool. Now it’s time to decrease the loss even further by scaling up our model to make it bigger and deeper!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tFL0hpaq1Q"}],"key":"eMFxeGhyye"}],"key":"wVCERE0dfR"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QHMZNDwQYB"}],"key":"gRMXL1nF8Y"},{"type":"text","value":" overview","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nP2x29aGzO"}],"identifier":"wavenet-overview","label":"WaveNet overview","html_id":"wavenet-overview","implicit":true,"key":"t9mLk4LU0z"}],"visibility":"show","key":"eKenlbFV12"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Currently, we are using this architecture here:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gp3Y34d6Vz"}],"key":"V867XB7Rzt"}],"key":"DOVRBL45mJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"bengio2003nn.jpeg\"))","key":"JZZ095PCHG"},{"type":"outputs","id":"tdS5NfDre_docrS7wGovR","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/jpeg":{"content_type":"image/jpeg","hash":"a21abcc7498c74c85d4a3cd5f51b3817","path":"/build/a21abcc7498c74c85d4a3cd5f51b3817.jpeg"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"SDed4WcfOO"}],"key":"nGiSweoUGu"}],"key":"YhMPmQwhiF"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"where we are taking in some number of characters, going into a single hidden layer, and then going to the prediction of the next character. The problem here is we don’t have a naive way of making this bigger in a productive way. We could, of course, use our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Yg71Kx5Nv4"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rLm0Jwdztf"}],"key":"SrgQ7rBzr1"},{"type":"text","value":". We could use our layers, sort of like building block materials to introduce additional layers here and make the network deeper. But it is still the case that we are crushing all of the characters into a single layer all the way at the beginning. And even if we make this a layer bigger by adding neurons, it’s still kind of like silly to squash all that information so fast in a single step. What we’d like to do instead is we’d like our network to look a lot more like this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kK5AqOFHSF"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"asYZFjxh6e"}],"key":"crBTfuD5bE"},{"type":"text","value":" case:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rb5lJ4bvbH"}],"key":"apvhcKflvF"}],"key":"K7KPvSIZPr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig3.png\"))","key":"Feg3Sx3MlP"},{"type":"outputs","id":"R3714rKNHv8VIkYoQMM_G","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"198c39366ff68e8b03ccb06df349f47a","path":"/build/198c39366ff68e8b03ccb06df349f47a.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"Yy3KeJTlTy"}],"key":"DFHI0bi6ZA"}],"key":"xsWTsYVRxC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So you see in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hRbpOMNk7N"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aFAvseKn9k"}],"key":"xXJKcShqpg"},{"type":"text","value":", when we are trying to make the prediction for the next character in a sequence a function of the previous characters that feed in. But it is not the case that all of these different characters are just crushed to a single layer and then you have a sandwich. They are crushed slowly. So in particular, we take two characters and we fuse them into sort of like a bigram representation. And we do that for all these characters consecutively. And then we take the bigrams and we fuse those into four character level chunks. And then we fuse again. And so we do that in this tree-like hierarchical manner. So we fuse the information from the previous context ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mvqrA3qbAb"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"gradually","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KhSVxa38bL"}],"key":"voUca0t2l9"},{"type":"text","value":", as the network deepens. This is the kind of architecture that we want to implement. Now in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LCUeK1DyYc"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vYQy1NhgAI"}],"key":"ROk0dbVNM6"},{"type":"text","value":" case, this is a visualization of a stack of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cPX2LsR1nT"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"dilated","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Loe8LxZwPO"}],"key":"GX95ocDxo8"},{"type":"text","value":" causal convolution layers. And this makes it sound very scary, but actually the idea is quite simple. And the fact that it’s a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eAojsegVyb"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"dilated","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xd0DhhQGUC"}],"key":"URTWSzolTv"},{"type":"text","value":" causal convolution layer is really just an implementation detail to make everything fast. We’re going to see that later. But for now, let’s just keep going. We’re going to keep the basic idea of it, which is this progressive fusion. So we want to make the network deeper, and at each level, we want to fuse only two consecutive elements. Two characters, then two bigrams, then two fourgrams, and so on. So let’s implement this.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Io5GaA4PSQ"}],"key":"i5W9ihZPqP"}],"key":"f0QxqRmAw8"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Bumping the context size to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aMZXXLEga3"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xrnof1cHN5"}],"identifier":"bumping-the-context-size-to-8","label":"Bumping the context size to 8","html_id":"bumping-the-context-size-to-8","implicit":true,"key":"otRcyzoJZK"}],"key":"DlUWkPDoLF"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Okay, so first up, let me scroll to where we built the dataset, and let’s change the block size from ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Blw6FqD7zu"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AHF1UHeAtH"},{"type":"text","value":" to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YMyOaESCox"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iujy4AiEKN"},{"type":"text","value":". So we’re going to be taking ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Rt4t4Bs5MK"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ramUMDMBSx"},{"type":"text","value":" characters of context to predict the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hJpWH1fTZC"},{"type":"inlineMath","value":"9th","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e9\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e9th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e9\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"L9raRQkFyD"},{"type":"text","value":" character:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kf6OyGRSVa"}],"key":"pqsAuUyI4a"}],"key":"pcW19AS73l"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"block_size = 8\n(xtrain, ytrain), (xval, yval), (xtest, ytest) = build_all_datasets(block_size)","key":"dTDdr9fhpk"},{"type":"outputs","id":"Nkox4liLCfEv9lHdzOygY","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"torch.Size([182473, 8]) torch.Size([182473])\ntorch.Size([22827, 8]) torch.Size([22827])\ntorch.Size([22846, 8]) torch.Size([22846])\n"},"children":[],"key":"iGZ9LdNDfX"}],"key":"gDRlQZcnbZ"}],"key":"s4kRnjEvgt"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So the dataset now looks like this:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K7AYU8Fya1"}],"key":"CvvE0TQTfT"}],"key":"Zg3nukFvqW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print_next_character(xtrain[:20], ytrain[:20])","key":"ROa1VhHq95"},{"type":"outputs","id":"F_Q2LbLb2qEiV5sr6nH0l","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"........ --\u003e c\n.......c --\u003e a\n......ca --\u003e t\n.....cat --\u003e h\n....cath --\u003e y\n...cathy --\u003e .\n........ --\u003e k\n.......k --\u003e e\n......ke --\u003e n\n.....ken --\u003e a\n....kena --\u003e d\n...kenad --\u003e i\n..kenadi --\u003e .\n........ --\u003e a\n.......a --\u003e m\n......am --\u003e i\n.....ami --\u003e .\n........ --\u003e l\n.......l --\u003e a\n......la --\u003e r\n"},"children":[],"key":"noC6yGkVfA"}],"key":"AAzY2IIL0C"}],"key":"VpjE9MOgSl"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"These ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FkDSAcXjnN"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iRBgxP6KUu"},{"type":"text","value":" characters are going to be processed in the above tree-like structure. Let’s find out how to implement this hierarchical scheme! But before doing that, let’s train our simple fully-connected ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zVnZ1fCNUX"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G00WBKVVab"}],"key":"JieTtHjRhY"},{"type":"text","value":" with this new dataset and see how well it performs:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aC4tlywWrs"}],"key":"k0001G7obt"}],"key":"wB6zQqYaCt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, parameters = define_nn(block_size, n_embd, n_hidden)\nlossi = train(xtrain, ytrain, model, parameters)","key":"H4e6ih8Lxo"},{"type":"outputs","id":"hQcRBkBLk6firB8cj5-Y-","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"22097\n      0/ 200000: 3.3024\n  10000/ 200000: 2.1462\n  20000/ 200000: 2.2304\n  30000/ 200000: 2.1978\n  40000/ 200000: 2.3442\n  50000/ 200000: 2.1926\n  60000/ 200000: 2.4338\n  70000/ 200000: 2.0021\n  80000/ 200000: 2.0781\n  90000/ 200000: 1.7328\n 100000/ 200000: 2.2064\n 110000/ 200000: 1.9591\n 120000/ 200000: 1.9200\n 130000/ 200000: 1.7876\n 140000/ 200000: 2.0151\n 150000/ 200000: 1.9124\n 160000/ 200000: 1.9154\n 170000/ 200000: 2.4858\n 180000/ 200000: 2.0312\n 190000/ 200000: 1.7150\n"},"children":[],"key":"eV5kCOzrCk"}],"key":"CpiOanoA19"}],"key":"A2rMIeEaPN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));","key":"uEogLYUnmU"},{"type":"outputs","id":"orMTooKDLUSM1p-LUFLCK","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"ff615d43a98747bd9c51619102571855\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"165817da5ba45451a2b5cc72d6b0048c","path":"/build/165817da5ba45451a2b5cc72d6b0048c.png"},"text/html":{"content_type":"text/html","hash":"d15454142d80cffdbabe07305558aecc","path":"/build/d15454142d80cffdbabe07305558aecc.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"vT5MPbpfyZ"}],"key":"eTjjLGqOtJ"}],"key":"SfGGekqu2Y"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"trigger_eval_mode(model)\ninfer_loss(model, xtrain, ytrain, prefix=\"train\")\ninfer_loss(model, xval, yval, prefix=\"val\");","key":"ohrxevntzS"},{"type":"outputs","id":"0SrlD_mIbzF17fdsL10Zc","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"train 1.9159809350967407\nval 2.0343399047851562\n"},"children":[],"key":"kauCtgYUEb"}],"key":"sUqdNkLaRg"}],"key":"fVfjKQFiBa"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Interesting! The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TpcPO85SHG"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FAdPOolEw8"}],"key":"Qp51YgHcaB"},{"type":"text","value":" has improved compared to the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Tyw9iODfTR"},{"type":"inlineCode","value":"block_size = 3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rQhEwXg0pK"},{"type":"text","value":" case. Let’s log our losses so far:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XRlmpgplLm"}],"key":"py2KlGehuJ"}],"key":"IpO9E3fn2T"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"code","lang":"python","value":"# original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n# context: 3 -\u003e 8 (22K params): train 1.915, val 2.034","position":{"start":{"line":1,"column":1},"end":{"line":4,"column":1}},"key":"rLla52Gujn"}],"visibility":"show","key":"UEild0QNAr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Also, if we sample from the model, we can see the names improving qualitatively as well:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ALbrZ8Bq2g"}],"key":"qMNWfubnMD"}],"key":"iNfNV3kzuh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sample_from_model(block_size, model)","key":"hj8DOaZ5ag"},{"type":"outputs","id":"7XPK52nDAGwVOmPdDTUA5","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"kobi.\npran.\nmarlecm.\nlunghan.\ncamillo.\nshatar.\nelizee.\nlumarius.\nderis.\nbrook.\nmadaniy.\nyarel.\nmilaal.\naylen.\nnikora.\nniani.\nsahanlaa.\nelaya.\nmalixa.\ndalioluw.\n"},"children":[],"key":"PW5xXBHfmT"}],"key":"zApEMAlpvt"}],"key":"ML0qoqeFpb"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So we could, of course, spend a lot of time here tuning things and scaling up our network further. But let’s continue and let’s implement the hierarchical model and treat this as just a rough baseline performance. There’s a lot of optimization left on the table in terms of some of the hyperparameters that you’re hopefully getting a sense of now.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r5phnRpA1J"}],"key":"DdzU83Ie9R"}],"key":"TkzKytWHi3"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Implementing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"otQJlB30Mo"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uPpSjntK4Q"}],"key":"l9IlqV9PkB"}],"identifier":"implementing-wavenet","label":"Implementing WaveNet","html_id":"implementing-wavenet","implicit":true,"key":"iP5fsodqov"}],"visibility":"show","key":"YtcpFov3T6"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s now create a bit of a scratch space for us to just look at the forward pass of the  ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"p2cBsDXvrX"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OIAbezy88a"}],"key":"iwR0TRdUhS"},{"type":"text","value":" and inspect the shape of the tensors along the way of the forward pass:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vBdU3ZVwad"}],"key":"SLxKeLzNxi"}],"key":"LpcYeCpl5d"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# let's look at a batch of just 4 examples\nix = torch.randint(0, xtrain.shape[0], (4,))\nxb, yb = xtrain[ix], ytrain[ix]\nlogits = model(xb)\nprint(xb.shape)\nxb","key":"riQ8Lln6jF"},{"type":"outputs","id":"sg7jdNssq0npdVOEe5p6b","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"torch.Size([4, 8])\n"},"children":[],"key":"eZCHDid9et"},{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":63,"metadata":{},"data":{"text/plain":{"content":"tensor([[ 0,  0,  0,  0,  0,  0,  0, 12],\n        [ 0,  0,  0,  0,  0,  0, 18,  5],\n        [ 0,  0,  0, 11,  1, 12,  9, 14],\n        [ 0,  0,  0,  0,  0, 11,  9, 18]])","content_type":"text/plain"}}},"children":[],"key":"cX6gRrkv5W"}],"key":"V01XVXWZX2"}],"key":"GCC7LOY2dT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Here we are just temporarily, for debugging purposes, creating a batch of just, say, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VoaG4q9qwl"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wGp0YeNjSo"},{"type":"text","value":" examples. So ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QtdHohSo7S"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GxbrDgOKTX"},{"type":"text","value":" random integers. Then, we are plucking out those rows from our training set. And then we are passing into the model the input ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hUaUARzySv"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xGghB7JUCc"},{"type":"text","value":". Now the shape of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U1lthZHT1z"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hhDJgntBMW"},{"type":"text","value":" here, because we only have ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"w5MlVb5D2j"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fYjHo7mZZN"},{"type":"text","value":" examples. And ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FXzH0B1uG3"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wT7w8bNEBJ"},{"type":"text","value":" is the current block size. So ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OWOZXJPfRX"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZPmcqsoHUP"},{"type":"text","value":" contains ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xk1qRQwCk4"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vQHql24Kjj"},{"type":"text","value":" rows/examples of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LgyrkSHFWQ"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"me6UgsY3oj"},{"type":"text","value":"  characters each. And each integer tensor row of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zdC2RzFiit"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IkKDo4bNeH"},{"type":"text","value":" just contains the identities of those characters. Therefore, the first layer of our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZDwjxeCVC4"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bSqKsmqvse"}],"key":"uLTBHuyoC6"},{"type":"text","value":" is the embedding layer. So passing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rVNSB9u0Tr"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bmEW1bR6gn"},{"type":"text","value":", this integer tensor, through the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VODyV6hIpI"},{"type":"inlineCode","value":"Embedding","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wIfXAevVpn"},{"type":"text","value":" layer creates an output:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cVYNmo7lO3"}],"key":"nhy097r72z"}],"key":"D4eukLCo13"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model.layers[0].out.shape  # output of Embedding layer","key":"gQPZLxTpWt"},{"type":"outputs","id":"o3HDGQwSb2XAe1PlpQQO1","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":64,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 8, 10])","content_type":"text/plain"}}},"children":[],"key":"QivWkMXpJp"}],"key":"JMW9NjEl2p"}],"key":"rmmo7BfezC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So our embedding table ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dV8SdqbJUD"},{"type":"inlineCode","value":"C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"El7qWonWhl"},{"type":"text","value":" has, for each character, a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"g7DQHcI927"},{"type":"text","value":"10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nDb8dGKVDl"},{"type":"text","value":"-dimensional vector (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QgYaTHPXEv"},{"type":"inlineCode","value":"n_embd=10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DvWxV2K5eB"},{"type":"text","value":") that we are trying to learn. What the layer does here is it plucks out the embedding vector for each one of these integers (of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Gjhbc55e5a"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ykYwmqoq3r"},{"type":"text","value":" and organizes it all in a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Jw3z0afPEo"},{"type":"inlineMath","value":"4\\times8\\times10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e10\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times8\\times10\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e8\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e10\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"V8GrHWLH8S"},{"type":"text","value":" tensor. So all of these integers are translated into ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I3kTYspF46"},{"type":"text","value":"10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WvqsPfwJaD"},{"type":"text","value":"-dimensional vectors inside this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"varnJHHnrY"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yDUd4f4HLO"},{"type":"text","value":"-dimensional tensor now.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YKCDuVP0ei"}],"key":"pra3pG2UPS"}],"key":"dUySlbow7V"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model.layers[1].out.shape  # output of Flatten layer","key":"wcEngOWVYD"},{"type":"outputs","id":"6SbscynFAyFpaKCpv-lzP","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":65,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 80])","content_type":"text/plain"}}},"children":[],"key":"mG8akKXCx4"}],"key":"F0AItABJTP"}],"key":"p0Os9nybFD"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now passing that through the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PHUdKgosfI"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dky8STsw8W"},{"type":"text","value":" layer, as you recall, what this does is it views this tensor as just a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K7r1N8nmGb"},{"type":"inlineMath","value":"4\\times80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"J6eYRFlntt"},{"type":"text","value":" tensor. And what that effectively does is that all these ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jEr2gya5qT"},{"type":"text","value":"10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rDSrpZHnRW"},{"type":"text","value":"-dimensional embeddings for all these ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CwYqO8o6G5"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UpmTVG22DA"},{"type":"text","value":" characters just end up being stretched out into a long row. And that looks kind of like a concatenation operation, basically. So by viewing the tensor differently, we now have a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SnxkVvXZN9"},{"type":"inlineMath","value":"4\\times80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"fVqTSV9rCP"},{"type":"text","value":". And inside this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WtbgWj65jx"},{"type":"text","value":"80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ui5jRFfUWg"},{"type":"text","value":", it’s all the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IlhqHPK00L"},{"type":"text","value":"10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aHvpUEtm0t"},{"type":"text","value":"-dimensional vectors just concatenated next to each other.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"P6egfEKq0a"}],"key":"V7uEwxDkCR"}],"key":"PV4QlOWilr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model.layers[2].out.shape  # output of Linear layer","key":"ocKSgKVTQi"},{"type":"outputs","id":"hw3opsVXRKVuFnvqSTNrJ","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":66,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 200])","content_type":"text/plain"}}},"children":[],"key":"s4wThSDF2y"}],"key":"ANATsZ9t3F"}],"key":"avT6yTOqGL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And the linear layer, of course, takes ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JFGwIwTIMa"},{"type":"text","value":"80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zQgFgjRnHV"},{"type":"text","value":" and creates ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uRl8yOjsWR"},{"type":"text","value":"200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e4ZoLA5XUX"},{"type":"text","value":" channels just via matrix multiplication. So far, so good. Now let’s see something surprising. Let’s look at the insides of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OkbIZxTAsg"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IBiWKZznUO"},{"type":"text","value":" layer and remind ourselves how it works:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FhvGRaQ6O6"}],"key":"OXmh4BzIKN"}],"key":"o1Hxiu8rif"},{"type":"block","kind":"notebook-content","children":[{"type":"code","lang":"python","value":"class Linear:\n    def __init__(self, fan_in, fan_out, bias=True):\n        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n        self.bias = torch.zeros(fan_out) if bias else None\n\n    def __call__(self, x):\n        self.out = x @ self.weight\n        if self.bias is not None:\n            self.out += self.bias\n        return self.out\n...","position":{"start":{"line":1,"column":1},"end":{"line":13,"column":1}},"key":"EgKxloHrtk"}],"key":"mYc48NsjrW"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f1U7KIxMf8"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"suxaF7Gd6K"},{"type":"text","value":" layer here in a forward pass takes the input ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rcdbZSutcQ"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M0WJFolJMn"},{"type":"text","value":", multiplies it with a weight and then optionally adds a bias. And the weight is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M6ykPgSdrb"},{"type":"inlineMath","value":"2D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"gQirjEjltF"},{"type":"text","value":", as defined here, and the bias is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DoLe1o2Dx6"},{"type":"inlineMath","value":"1D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"FW4ns8o7IF"},{"type":"text","value":". So effectively, in terms of the shapes involved, what’s happening inside this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"f0EQ26oeUs"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WEP9EkFwKa"},{"type":"text","value":" layer looks like this right now. And we’re using random numbers here, but just to illustrate the shapes and what happens:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IZIz1ylg3b"}],"key":"xO3rpfyOpy"}],"key":"ye5RKSz8ae"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"(torch.randn(4, 80) @ torch.randn(80, 200) + torch.randn(200)).shape","key":"bsLtIpQjXl"},{"type":"outputs","id":"69HmbYuGBvhPRr8tQ1BGP","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":67,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 200])","content_type":"text/plain"}}},"children":[],"key":"MjBl0R7iAF"}],"key":"Ncg3fNnXqo"}],"key":"aJfCKRfBl2"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Basically, a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UjNLtKkWda"},{"type":"inlineMath","value":"4\\times80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"a2ot4bVAxJ"},{"type":"text","value":" comes into the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uGL6m3UeRa"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DOYCTYOzcu"},{"type":"text","value":" layer, gets multiplied by a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JFhJyaxvGa"},{"type":"inlineMath","value":"80\\times200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e80\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e80\\times200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"NtlrjY0qPO"},{"type":"text","value":" weight matrix inside, and then there’s a plus ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zdrVaoGOFm"},{"type":"text","value":"200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yXr0BbmWkq"},{"type":"text","value":" bias. And the shape of the whole thing that comes out of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HZWBEfv26l"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m1CSJArLLO"},{"type":"text","value":" layer is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pOLZRbfeJf"},{"type":"inlineMath","value":"4\\times200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ftGNUgrGin"},{"type":"text","value":", as we see here. Notice, by the way, that the matrix multiplication here will create a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iSQFhl7rmx"},{"type":"inlineMath","value":"4x200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4x200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Tl7vnXJp0l"},{"type":"text","value":" tensor, and then when adding ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wQJQIKJAtA"},{"type":"text","value":"200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ye0T81w5UN"},{"type":"text","value":" there’s a broadcasting happening here, but since ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KBqATOAvsA"},{"type":"inlineMath","value":"4x200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4x200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"U0YVOXwBzT"},{"type":"text","value":" broadcasts with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"atpIj2T27c"},{"type":"text","value":"200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"g09xWfs5i4"},{"type":"text","value":", everything works here. So now the surprising thing is how this works. Specifically, something you may not expect is that this input here, that is being matrix-multiplied, doesn’t actually have to be ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FxmYrFlFet"},{"type":"inlineMath","value":"2D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"aKHEyyOuN9"},{"type":"text","value":". This matrix multiply operator in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CjMlD9OpX9"},{"type":"inlineCode","value":"PyTorch","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pebysbKN6h"},{"type":"text","value":" is quite powerful, and in fact, you can actually pass in higher dimensional arrays or tensors, and everything works fine. So for example, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SBS58OfAko"},{"type":"inlineCode","value":"torch.randn(4, 80)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dXe4I687hX"},{"type":"text","value":" could instead be ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qtOLF8X3Lm"},{"type":"inlineCode","value":"torch.randn(4, 5, 80)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GzsSClBEzl"},{"type":"text","value":" (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ySNSL794fX"},{"type":"inlineMath","value":"4\\times5\\times80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e5\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times5\\times80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e5\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"oQqbRSpHXT"},{"type":"text","value":") and the result in that case would become ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WCgt93ejae"},{"type":"inlineMath","value":"4\\times5\\times200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e5\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times5\\times200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e5\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"PioHhjG1Fk"},{"type":"text","value":". You can add as many dimensions as you like to the left of the last dimension of the input tensor (here, dimension ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SP4icPgJH3"},{"type":"text","value":"80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qPIo9zVjTK"},{"type":"text","value":"). And so effectively, what’s happening is that the matrix multiplication only works on a matrix multiplication on the last dimension, and the dimensions before it in the input tensor are left unchanged. So basically, these dimensions to the left of the last dimension are all treated as just a batch dimension. So we can have multiple batch dimensions (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U9UqkiFzUp"},{"type":"inlineCode","value":"torch.randn(4, 5, 6, 7, 80)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VZtSwh9vxq"},{"type":"text","value":"), and then in parallel over all those dimensions, we are doing the matrix multiplication only on the last dimension. So this is quite convenient, because we can use that in our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"avXN2fh9uU"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LeCnzbMRiL"}],"key":"FJpzJHatSz"},{"type":"text","value":" now. Remember that we have these ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YjTTfYT6le"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BY0EhT2o2i"},{"type":"text","value":" characters coming in, e.g.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PJXQw6kCNB"}],"key":"IctX9TcJNd"},{"type":"code","lang":"python","value":"# 1 2 3 4 5 6 7 8","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"key":"bHiMFtsPLI"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"And we don’t want to now flatten all of it out into a large ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"J6GJNYlLHp"},{"type":"text","value":"8","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"hWu6LHvX5x"},{"type":"text","value":"-dimensional vector, because we don’t want to matrix multiply ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TCbHHCwToA"},{"type":"text","value":"80","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"BTDudBjfgi"},{"type":"text","value":" into a weight matrix multiply immediately. Instead, we want to group these like this:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Lfjv9rzs3m"}],"key":"NiMdmMdApf"},{"type":"code","lang":"python","value":"# (1 2) (3 4) (5 6) (7 8)","position":{"start":{"line":9,"column":1},"end":{"line":11,"column":1}},"key":"kVVK9q95zG"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"So every consecutive two elements should now basically be flattened and multiplied by a weight matrix. But the idea is that all of these four groups here, we’d like to process in parallel. So it’s kind of like a extra batch dimension that we can introduce. And then we can, in parallel, basically process all of these bigram groups in the four extra batch dimension of an individual example, and also over the actual batch dimension of the four examples. So let’s see what this is all about and how that works. Right now, we take a ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"KlQ5LJyFwu"},{"type":"inlineMath","value":"4\\times80","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"sc3ocYcj1f"},{"type":"text","value":" and multiply it by ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"faLPfjMsqs"},{"type":"inlineMath","value":"80\\times200","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e80\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e80\\times200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"yHGTkRlpYl"},{"type":"text","value":" in the linear layer. Effectively, what we want is instead of ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"PwFtfviOpM"},{"type":"text","value":"8","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"gOedWCONrN"},{"type":"text","value":" characters (","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"ygKPD3lHMI"},{"type":"text","value":"80","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"HDqGO7fZYh"},{"type":"text","value":" embedding numbers) coming in, we only want ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"wsxFcdIC6d"},{"type":"text","value":"2","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"fnHZguIs0s"},{"type":"text","value":" characters (","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"cnkIKGmSIK"},{"type":"text","value":"20","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"YeczEuZmTV"},{"type":"text","value":" embedding numbers) to come in. Therefore, if we want that, we can’t have a ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"tbJ9QkVGBr"},{"type":"inlineMath","value":"4x80","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4x80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"tMAukbGnIM"},{"type":"text","value":" feeding into the ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"s3sli0XLrH"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"xUtzrzMbOt"},{"type":"text","value":" layer, but instead ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"vDbIEpQzS3"},{"type":"text","value":"4","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"rMYWUNUSen"},{"type":"text","value":" groups of ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"BqsKXHeiM0"},{"type":"text","value":"2","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"QqqR0vwBGp"},{"type":"text","value":" characters to be feeding in, like this:","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"LjMu8FvbKJ"}],"key":"oGRVRUXJjT"}],"key":"EOplKK57P6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"(torch.randn(4, 4, 20) @ torch.randn(20, 200) + torch.randn(200)).shape","key":"DptAwi8KuI"},{"type":"outputs","id":"ecVzALDioxibsEixQnOr2","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":68,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 4, 200])","content_type":"text/plain"}}},"children":[],"key":"gpnq17t2aB"}],"key":"A9IleNlwmh"}],"key":"Y6HGsQMjLi"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Therefore, what we would want to do now is change the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EKH6MQjIN2"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E89wVLcUlR"},{"type":"text","value":" layer so that it doesn’t output a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wZOapwQM2Q"},{"type":"inlineMath","value":"4x80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4x80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"NDF9Q8wOAw"},{"type":"text","value":" but a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xu4AXEA4sl"},{"type":"inlineMath","value":"4x4x20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e20\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4x4x20\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e20\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"edJivrKPO6"},{"type":"text","value":" where basically in each row tensor of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K5Xgiih26B"},{"type":"inlineCode","value":"xb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GMb98RKrDo"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Pc8fwWI0vG"}],"key":"wufaYv9Lmc"}],"key":"GxQRvwCujj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"xb","key":"OWqVl8jHAP"},{"type":"outputs","id":"mEPBZlfZ5W9hJFdqmCb4s","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":69,"metadata":{},"data":{"text/plain":{"content":"tensor([[ 0,  0,  0,  0,  0,  0,  0, 12],\n        [ 0,  0,  0,  0,  0,  0, 18,  5],\n        [ 0,  0,  0, 11,  1, 12,  9, 14],\n        [ 0,  0,  0,  0,  0, 11,  9, 18]])","content_type":"text/plain"}}},"children":[],"key":"qWYhxTgZMF"}],"key":"wXzfSCpd7Y"}],"key":"jQfTiEEaGz"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"every two consecutive characters (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jUEUkyNAhi"},{"type":"inlineMath","value":"(0, 0), (10, 21), (12,  9), (5, 1)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmn\u003e10\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e21\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmn\u003e12\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e9\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmn\u003e5\u003c/mn\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e(0, 0), (10, 21), (12,  9), (5, 1)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e10\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e21\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e12\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e9\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord\"\u003e5\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"p3BcRr4PxL"},{"type":"text","value":") are packed in on the very last dimension (i.e. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aBi9tKw0tY"},{"type":"text","value":"20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Uk38p3t07e"},{"type":"text","value":"). So that the first dimension (i.e. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ol0YDFhmvn"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xNK6YUu2Mq"},{"type":"text","value":") is the first batch dimension and the second dimension (i.e. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t6MyIZQgKK"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jzK8WKdAHO"},{"type":"text","value":") is the second batch dimension. And this is where we want to get to:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SbmVU94Bev"}],"key":"zab9MshvYP"}],"key":"n3QnEmqu2M"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"(torch.randn(4, 4, 20) @ torch.randn(20, 200) + torch.randn(200)).shape","key":"uIJVstLTYt"},{"type":"outputs","id":"Eye6Q47xxNMduBcpGUtxZ","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":70,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 4, 200])","content_type":"text/plain"}}},"children":[],"key":"FkpQQsK50R"}],"key":"AbLGL6lfeZ"}],"key":"AZEHiAd81d"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now we have to change our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"W8D82y907G"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FMxHXzDaeQ"},{"type":"text","value":" layer (so that it doesn’t fully flatten out the examples, but creates a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"g24oShGTt4"},{"type":"inlineMath","value":"4\\times4\\times20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e20\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times4\\times20\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e20\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"a78Hjia7Y9"},{"type":"text","value":" instead of a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zdJflaqF59"},{"type":"inlineMath","value":"4\\times80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e80\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times80\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e80\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"KFVLe6ZYd1"},{"type":"text","value":") and our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FTpp7y7Aqg"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PxLQagzBkd"},{"type":"text","value":" layer (to expect ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fpqZpbzUJz"},{"type":"text","value":"20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CGgIaID9Zx"},{"type":"text","value":" instead of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eWXy15LKPY"},{"type":"text","value":"80","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UzwDpxrV8p"},{"type":"text","value":"). So let’s see how this could be implemented. Basically, right now we have an input that is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UQNtuGQorC"},{"type":"inlineMath","value":"4\\times8\\times10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e10\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times8\\times10\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e8\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e10\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"qgLeFIys02"},{"type":"text","value":" that feeds into the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sYg2QbERVW"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rfJlVpyWF3"},{"type":"text","value":" layer, and currently the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qW14uGL1h3"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HZSYuu67vF"},{"type":"text","value":" layer just stretches it out:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zk2XaKZ50A"}],"key":"FIKaGxuhgF"},{"type":"code","lang":"python","value":"class Flatten:\n    def __call__(self, x):\n        self.out = x.view(x.shape[0], -1)\n        return self.out\n...","position":{"start":{"line":3,"column":1},"end":{"line":9,"column":1}},"key":"zMVjOYVn77"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"through the ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Tb8smErz5h"},{"type":"inlineCode","value":"view","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"eoZ1NtiqWJ"},{"type":"text","value":" operation. Effectively what it does now is:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"sTkaD6mg3d"}],"key":"Fszq7eIKbc"}],"key":"atOpNlE7Tz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"e = torch.randn(\n    4, 8, 10\n)  # goal: want this to be (4, 4, 20) where consecutive 10-d vectors get concatenated\ne.view(4, -1).shape  # yields 4x80","key":"JEWR6jsI53"},{"type":"outputs","id":"mmZqwoRaRxj_2avIspzna","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":71,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 80])","content_type":"text/plain"}}},"children":[],"key":"cwTgfItXzp"}],"key":"bnkD4HpOEJ"}],"key":"RyrN9r34R9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"But we want to just view the same tensor as a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Wx3blHVROE"},{"type":"inlineMath","value":"4x4x20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmn\u003e20\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4x4x20\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mord\"\u003e20\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"xlyQ38hyLB"},{"type":"text","value":" instead, so:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PHFx3yfrJR"}],"key":"H8JYVnSDh5"}],"key":"p3iAaX2LYy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"e.view(4, 4, -1).shape  # yields 4x4x20: this is what we want!","key":"MQkmjfgSAn"},{"type":"outputs","id":"Vbh688w0OY2_9d0NfN_y3","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":72,"metadata":{},"data":{"text/plain":{"content":"torch.Size([4, 4, 20])","content_type":"text/plain"}}},"children":[],"key":"FEPvFhMRmr"}],"key":"be2zVjEyTC"}],"key":"q1Nh0efxrX"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Easy, right? Let’s now rewrite ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xwA1SEL9pd"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WILdoEV1R3"},{"type":"text","value":", but since ours will now start to depart from ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PBTfQdHqrU"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn.Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IUnc7ZgqLW"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten","key":"uzWMfXXY74"},{"type":"text","value":", we’ll rename it to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fL9AtjPwqy"},{"type":"inlineCode","value":"FlattenConsecutive","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ozc3CsNO1Z"},{"type":"text","value":" just to make sure that our APIs are somewhat similar but not the same:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KNS2ntRbAB"}],"key":"dnXiOwEuLh"}],"key":"aRDYCeDD8t"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class FlattenConsecutive:\n    def __init__(self, n):\n        self.n = n\n\n    def __call__(self, x):\n        b, t, c = x.shape\n        x = x.view(b, t // self.n, c * self.n)\n        if x.shape[1] == 1:\n            x = x.squeeze(1)\n        self.out = x\n        return self.out\n\n    def parameters(self):\n        return []","key":"CUtLCwMNTy"},{"type":"outputs","id":"-53ms26mwfJjoLp53jpfb","children":[],"key":"eDcp61zwMp"}],"key":"gP2f2FZLn3"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QNxjWyr3r8"},{"type":"inlineCode","value":"FlattenConsecutive","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"c4p20pZeaq"},{"type":"text","value":" takes in and flattens only some ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VebBa9bNLv"},{"type":"inlineCode","value":"n","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U8R9ItgT0o"},{"type":"text","value":" consecutive elements and puts them into the last dimension. In ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vHDqqu2ZJn"},{"type":"inlineCode","value":"__call__","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oA9wZe1alt"},{"type":"text","value":" we parse the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KbJ5ony9Ff"},{"type":"text","value":"3","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pZADBAmBZF"},{"type":"text","value":" dimensions of the input ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ab5ocIdZHS"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LnFX7I09Gq"},{"type":"text","value":" as ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K5VGeqHL2w"},{"type":"inlineCode","value":"b","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r40Ff1NMkr"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t7J6dJPStg"},{"type":"inlineCode","value":"c","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N7a6VVJLac"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gdJGvBr27X"},{"type":"inlineCode","value":"t","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QefpoGpe0H"},{"type":"text","value":" (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zpesIehJ2g"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gkJZuSPX3D"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a4dXVAjNbX"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Dyj2rcrbEG"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IZz0WZfMga"},{"type":"text","value":"10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BWG5tGwCn6"},{"type":"text","value":") and then we view ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MYaprSnR4r"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YgrkMrk5ir"},{"type":"text","value":" as a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pfq5hol1eQ"},{"type":"inlineCode","value":"b","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G1fgQCYLHA"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Yabd3KFbQd"},{"type":"inlineCode","value":"t // n","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CYR4MR8c4T"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oBOLpITx6H"},{"type":"inlineCode","value":"c * n","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ER8ktDXJQq"},{"type":"text","value":" tensor (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"thyDcqmJSR"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J1fozBMJ7P"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nxJTRIyzDP"},{"type":"inlineMath","value":"8/2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmi mathvariant=\"normal\"\u003e/\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e8/2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e8/2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ynPdoiFhA4"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F8LuDE8y7R"},{"type":"inlineMath","value":"10 \\cdot 2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e10\u003c/mn\u003e\u003cmo\u003e⋅\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e10 \\cdot 2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e10\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e⋅\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"SSSIYFuTk9"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WANscO0XtC"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"a.k.a.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NkZlS15dvQ"}],"key":"kMssRDc87G"},{"type":"text","value":": ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d7rBBZfMsY"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tzRPWhenGU"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zf5YNCsCJX"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SfwPUk6d4n"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iVp2TdrcJu"},{"type":"text","value":"20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VmvcpqeBgX"},{"type":"text","value":"). Last but not least, we check whether the middle dimension of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aY0C8SSBId"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F0s1TqA2MU"},{"type":"text","value":" (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LeMSwUBD6C"},{"type":"inlineCode","value":"x.shape[1]","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tKz0WbCh21"},{"type":"text","value":") is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uMQ92EtHjF"},{"type":"text","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LON5ZFCB3e"},{"type":"text","value":" and if so, then we simply squeeze out that dimension (e.g. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Uy2hhvnqGW"},{"type":"inlineMath","value":"4\\times1\\times10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e10\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times1\\times10\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e10\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"j4uPB2GYYC"},{"type":"text","value":" would become ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Bjclwhw95M"},{"type":"inlineMath","value":"4\\times10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e10\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times10\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e10\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"X4vENRrLOt"},{"type":"text","value":"). Let’s now replace ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MP1pEkZCW5"},{"type":"inlineCode","value":"Flatten","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"w6HyLzlZIm"},{"type":"text","value":" with our new ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mbysjf8cp8"},{"type":"inlineCode","value":"FlattenConsecutive","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"R9danEks6B"},{"type":"text","value":", while maintaining the same functionality:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a6eShfRUlM"}],"key":"uYx2335zId"}],"key":"xEc6aEx2G3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def define_nn(block_size, n_embd, n_hidden):\n    n_inputs = n_embd * block_size\n    n_outputs = vocab_size\n    model = Sequential(\n        [\n            Embedding(vocab_size, n_embd),\n            FlattenConsecutive(block_size),\n            Linear(n_inputs, n_hidden, bias=False),\n            BatchNorm1d(n_hidden),\n            Tanh(),\n            Linear(n_hidden, n_outputs),\n        ]\n    )\n    # parameter init\n    with torch.no_grad():\n        model.layers[-1].weight *= 0.1  # last layer make less confident\n    parameters = model.parameters()\n    print(sum(p.nelement() for p in parameters))  # number of parameters in total\n    for p in parameters:\n        p.requires_grad = True\n    return model, parameters","key":"nuXgcMNpO2"},{"type":"outputs","id":"XYC6Q63fsYj6sYf5KTafW","children":[],"key":"vzOxEUHyGc"}],"key":"fnMm97VNwS"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, let’s define the model and verify that the shapes of the layer outputs are the same after feeding one batch of data into it:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QmrKbPDibd"}],"key":"qcPnZx9M4l"}],"key":"diHJkhaqpq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, _ = define_nn(block_size, n_embd, n_hidden)\nprint(xb.shape)\nmodel(xb)\nfor l in model.layers:\n    print(l.__class__.__name__, \":\", tuple(l.out.shape))","key":"GEpiFyDx8g"},{"type":"outputs","id":"qGXsGNe0zVMvDLlmfA9ZG","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"22097\ntorch.Size([4, 8])\nEmbedding : (4, 8, 10)\nFlattenConsecutive : (4, 80)\nLinear : (4, 200)\nBatchNorm1d : (4, 200)\nTanh : (4, 200)\nLinear : (4, 27)\n"},"children":[],"key":"MuRPJDjOrx"}],"key":"RU83tHnJYo"}],"key":"jFRfOJemET"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So, we see the shapes as we expect them after every single layer in its output. Now, let’s try to restructure it and do it hierarchically:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"G2vn5im95B"}],"key":"lJL1dxQGBy"}],"key":"ZGmJ8LXzTC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def define_nn(block_size, n_embd, n_hidden):\n    n_consec = 2\n    n_inputs = n_embd * n_consec\n    n_outputs = vocab_size\n    model = Sequential(\n        [\n            Embedding(vocab_size, n_embd),\n            FlattenConsecutive(n_consec),\n            Linear(n_inputs, n_hidden, bias=False),\n            BatchNorm1d(n_hidden),\n            Tanh(),\n            FlattenConsecutive(n_consec),\n            Linear(n_hidden * n_consec, n_hidden, bias=False),\n            BatchNorm1d(n_hidden),\n            Tanh(),\n            FlattenConsecutive(n_consec),\n            Linear(n_hidden * n_consec, n_hidden, bias=False),\n            BatchNorm1d(n_hidden),\n            Tanh(),\n            Linear(n_hidden, n_outputs),\n        ]\n    )\n    # parameter init\n    with torch.no_grad():\n        model.layers[-1].weight *= 0.1  # last layer make less confident\n    parameters = model.parameters()\n    print(sum(p.nelement() for p in parameters))  # number of parameters in total\n    for p in parameters:\n        p.requires_grad = True\n    return model, parameters","key":"r4VUnx8mYc"},{"type":"outputs","id":"nbdFeRku1Z755v8aqKRV2","children":[],"key":"aEGnxNuXun"}],"key":"MxUp2kQp6H"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, let’s inspect the numbers in between after a forward pass on a new ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZzMU5Yrs0B"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oLJNFTOrzt"}],"key":"eQ51Fg2Nzv"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"x2ted6OUFj"}],"key":"tBgcthBwGu"}],"key":"kZVejTR1J9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, _ = define_nn(block_size, n_embd, n_hidden)\nprint(xb.shape)\nmodel(xb)\nfor l in model.layers:\n    print(l.__class__.__name__, \":\", tuple(l.out.shape))","key":"CHYk6iS8pb"},{"type":"outputs","id":"3pUHuPniEyYEm1a65ZC01","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"170897\ntorch.Size([4, 8])\nEmbedding : (4, 8, 10)\nFlattenConsecutive : (4, 4, 20)\nLinear : (4, 4, 200)\nBatchNorm1d : (4, 4, 200)\nTanh : (4, 4, 200)\nFlattenConsecutive : (4, 2, 400)\nLinear : (4, 2, 200)\nBatchNorm1d : (4, 2, 200)\nTanh : (4, 2, 200)\nFlattenConsecutive : (4, 400)\nLinear : (4, 200)\nBatchNorm1d : (4, 200)\nTanh : (4, 200)\nLinear : (4, 27)\n"},"children":[],"key":"dRXQCuxz39"}],"key":"STrh4hMCQ0"}],"key":"Em2Kfs60CL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"So ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sNNfmwLRLj"},{"type":"inlineMath","value":"4\\times8\\times20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e8\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e20\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times8\\times20\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e8\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e20\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"z9Jaz4wQ1I"},{"type":"text","value":" was flattened consecutively into ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zLXcSsSPXV"},{"type":"inlineMath","value":"4\\times4\\times20","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e20\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times4\\times20\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e20\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"N6c8dthN6q"},{"type":"text","value":". Through the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Y61w0A2ef4"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kPON4tvouM"},{"type":"text","value":" layer, this was projected into ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lw10uFKiQP"},{"type":"inlineMath","value":"4\\times4\\times200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times4\\times200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Ybb8lF4rOL"},{"type":"text","value":". And then ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hjeYR6hXlo"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hynTFuK307"},{"type":"text","value":" just works out of the box and so does ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RgWls1hTb9"},{"type":"inlineCode","value":"Tanh","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"flnwRGZvmo"},{"type":"text","value":", which is element-wise. Then we crushed it again. So we flattened consecutively once more and ended up with a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EvJO6JGIGM"},{"type":"inlineMath","value":"4\\times2\\times400","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e400\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times2\\times400\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e400\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"tofPl0Gbjq"},{"type":"text","value":" now. Then ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I9JX21cT3a"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GSOz47EDe6"},{"type":"text","value":" brought it back down to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Tgy5ewXnv3"},{"type":"inlineMath","value":"4\\times2\\times200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e200\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times2\\times200\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e200\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"grlE4NNTak"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BsGXKeIgBS"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MMH7dD05O4"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FkhrrzDdAm"},{"type":"inlineCode","value":"Tanh","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sLoEXCsGEL"},{"type":"text","value":" didn’t change the shape and for the last flattening,\nit squeezed out that dimension of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NR0mz1TBF3"},{"type":"text","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ddO1CGCzsa"},{"type":"text","value":", we end up with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TZfRjtOELE"},{"type":"inlineMath","value":"4\\times400","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e400\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times400\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e400\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"LwGAsXV3jR"},{"type":"text","value":". And then ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JCgzOFmziQ"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QWOwqy1JT3"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YgzMuO1ccP"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F6SUIyqyqo"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aB67DAho2g"},{"type":"inlineCode","value":"Tanh","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YXDGBGyC7i"},{"type":"text","value":" and the last ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MqzGo4T3sD"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RQj7xNGIzz"},{"type":"text","value":" yield our logits that end up in the same shape as they were before. Now, we actually have a nice three-layer ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GJE3lbUhGI"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zPbJrN12Mh"}],"key":"OsOBVgho9D"},{"type":"text","value":" that basically corresponds to this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dhpgb5uVdL"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"g2ug2be63Y"}],"key":"DYywV2ysJN"},{"type":"text","value":" network:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v2iPlbBAXX"}],"key":"wVATwjgltG"}],"key":"tTdZcRFniZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig3.png\"))","key":"pwF04jF24F"},{"type":"outputs","id":"OAxh042jRWFa_alxrpSGd","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"198c39366ff68e8b03ccb06df349f47a","path":"/build/198c39366ff68e8b03ccb06df349f47a.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"zmXn51LlnV"}],"key":"P1X0TCLpNh"}],"key":"JDZrzDk5go"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"with the only difference that we are using a blocksize of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qHkqsj2kcc"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CmeX1kjyTC"},{"type":"text","value":" instead of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"THcgLvkdt6"},{"type":"text","value":"16","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EtOjrYEOWo"},{"type":"text","value":", as depicted above. Now with a new architecture, we just have to kind of figure out some good channel numbers (numbers of hidden units) to use here. If we decrease the number to:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bbCqgestzR"}],"key":"KUkAbxVBHU"}],"key":"e3LxKSYc8O"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"n_hidden = 68","key":"eXSZXgBFwo"},{"type":"outputs","id":"HIyYRbiB0tpUOO7GYORvH","children":[],"key":"eO9oDdEg7i"}],"key":"P80SJxZqD6"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"then the total number of parameters comes out to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KYLuoAS1Ur"},{"type":"text","value":"22000","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nkey7x0gVL"},{"type":"text","value":": exactly the same that we had before (when ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jHn5qrrLU5"},{"type":"inlineCode","value":"n_hidden=200","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OeDgM3IRcl"},{"type":"text","value":"). So we have the same amount of capacity with this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OdKz7LwRsp"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ezrBlTl8Ca"}],"key":"bevimslpXm"},{"type":"text","value":" in terms of the number of parameters. But the question is whether we are utilizing those parameters in a more efficient architecture.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jicANp1GPY"}],"key":"DCXckoYnau"}],"key":"w7aCP4qGUO"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"c2oa56DpWB"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZAGwl7ZEdX"}],"key":"RjVILHevIm"},{"type":"text","value":": first pass","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IfgqFEPyNg"}],"identifier":"training-the-wavenet-first-pass","label":"Training the WaveNet: first pass","html_id":"training-the-wavenet-first-pass","implicit":true,"key":"uND4YokwV2"}],"visibility":"show","key":"sbMa5KOI3w"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s train this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dlj2iu8Yuf"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EEOthfm0Gu"}],"key":"c2Tl97V4QP"},{"type":"text","value":" and see the results:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EuJaP4BcWE"}],"key":"I7qfodLuVl"}],"key":"jYaKync9Yf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, parameters = define_nn(block_size, n_embd, n_hidden)\nlossi = train(xtrain, ytrain, model, parameters)","key":"vypfUPVeyl"},{"type":"outputs","id":"CtFSwlJFl_pr7tKhWFt3Q","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"22397\n      0/ 200000: 3.2978\n  10000/ 200000: 2.1271\n  20000/ 200000: 2.0807\n  30000/ 200000: 1.6842\n  40000/ 200000: 2.0252\n  50000/ 200000: 2.3853\n  60000/ 200000: 2.4678\n  70000/ 200000: 1.7907\n  80000/ 200000: 2.2092\n  90000/ 200000: 2.3790\n 100000/ 200000: 1.7643\n 110000/ 200000: 1.6553\n 120000/ 200000: 1.9414\n 130000/ 200000: 1.9827\n 140000/ 200000: 1.7703\n 150000/ 200000: 1.8300\n 160000/ 200000: 1.6640\n 170000/ 200000: 1.9619\n 180000/ 200000: 1.7971\n 190000/ 200000: 1.9981\n"},"children":[],"key":"RYaLvcgRBx"}],"key":"ciqjUKaJcP"}],"key":"TikuzuXF4H"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));","key":"OSXMsgzRJL"},{"type":"outputs","id":"GVGB_Y2IVu1t3YjoNGAZg","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"ebbb1fbb33064be7876271d293fca166\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"cf9b940575805b57c2be2a06f27ba028","path":"/build/cf9b940575805b57c2be2a06f27ba028.png"},"text/html":{"content_type":"text/html","hash":"ed8a713dd897205bb2b423de5d813551","path":"/build/ed8a713dd897205bb2b423de5d813551.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"ec1iiLjBGa"}],"key":"s9slGA8WgY"}],"key":"DOnvAKCMM5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"trigger_eval_mode(model)\ninfer_loss(model, xtrain, ytrain, prefix=\"train\")\ninfer_loss(model, xval, yval, prefix=\"val\");","key":"IJVDWRKIn2"},{"type":"outputs","id":"MS6aYr_-f28zvwRQeVTZt","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"train 1.9376758337020874\nval 2.026397943496704\n"},"children":[],"key":"yLmTej6b6W"}],"key":"B1FKeBDs7W"}],"key":"bRaHpalMDg"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"code","lang":"python","value":"# original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n# context: 3 -\u003e 8 (22K params): train 1.915, val 2.034\n# flat -\u003e hierachical (22K params): train 1.937, val 2.026","position":{"start":{"line":1,"column":1},"end":{"line":5,"column":1}},"key":"ztTNZmw9UI"}],"visibility":"show","key":"HV7PLt8Ar6"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"As you can see, changing from the flat to hierachical model (while keeping the same number of parameters) is not giving us any noticeable significant benefit in terms of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nuqkeymEvI"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QGt36lOtTp"}],"key":"DcCbIj7t2a"},{"type":"text","value":".  That said, there are two things to point out. Number one, we didn’t really “torture” the architecture here very much. And there’s a bunch of hyperparameter search that we could do in terms of how we allocate our budget of parameters to what layers. Number two, we still may have a bug inside the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OAtRqHNyGu"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Te1imJxmnR"},{"type":"text","value":" layer. So let’s take a look at that because it runs, but doesn’t do the right thing.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F5Z2DQ8IsJ"}],"key":"KG63kz9c5M"}],"key":"EtyYzsWgyd"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fixing the BatchNorm1d bug","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u64oZrlN6I"}],"identifier":"fixing-the-batchnorm1d-bug","label":"Fixing the BatchNorm1d bug","html_id":"fixing-the-batchnorm1d-bug","implicit":true,"key":"xyENLURnO0"}],"key":"r0XnED0R5S"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"If we train for just one step and we print the layer output shapes:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hsTMgknT2c"}],"key":"BLo16VRZo6"}],"key":"lfIVPuN7sE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"_ = train(xtrain, ytrain, model, parameters, break_at_step=1)\nmodel(xb)\nfor l in model.layers:\n    print(l.__class__.__name__, \":\", tuple(l.out.shape))","key":"TnERR8EaC0"},{"type":"outputs","id":"Es7tBtN0HEjRpOFMbxwGJ","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"      0/ 200000: 2.0969\nEmbedding : (4, 8, 10)\nFlattenConsecutive : (4, 4, 20)\nLinear : (4, 4, 68)\nBatchNorm1d : (4, 4, 68)\nTanh : (4, 4, 68)\nFlattenConsecutive : (4, 2, 136)\nLinear : (4, 2, 68)\nBatchNorm1d : (4, 2, 68)\nTanh : (4, 2, 68)\nFlattenConsecutive : (4, 136)\nLinear : (4, 68)\nBatchNorm1d : (4, 68)\nTanh : (4, 68)\nLinear : (4, 27)\n"},"children":[],"key":"cJUbdzldzY"}],"key":"nJlF6s8OIW"}],"key":"TMAPTLyGtw"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"currently, it looks like the BatchNorm is receiving an input that is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J4Tj4Ia16O"},{"type":"inlineMath","value":"32\\times4\\times68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e32\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e68\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e32\\times4\\times68\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e32\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e68\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"s6tciubIbN"},{"type":"text","value":", right? Let’s take a look at the implementation of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RA5THiISIN"},{"type":"inlineCode","value":"BatchNorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mTIbzMxjhU"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pvZTLXiOS6"}],"key":"KEUnVtemmv"},{"type":"code","lang":"python","value":"class BatchNorm1d:\n    def __init__(self, dim, eps=1e-5, momentum=0.1):\n        self.eps = eps\n        self.momentum = momentum\n        self.training = True\n        # parameters (trained with backprop)\n        self.gamma = torch.ones(dim)\n        self.beta = torch.zeros(dim)\n        # buffers (trained with a running 'momentum update')\n        self.running_mean = torch.zeros(dim)\n        self.running_var = torch.ones(dim)\n  \n    def __call__(self, x):\n        # calculate the forward pass\n        if self.training:\n            xmean = x.mean(0, keepdim=True) # batch mean\n            xvar = x.var(0, keepdim=True) # batch variance\n        else:\n            xmean = self.running_mean\n            xvar = self.running_var\n        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n        self.out = self.gamma * xhat + self.beta\n        # update the buffers\n        if self.training:\n            with torch.no_grad():\n                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n        return self.out\n  \n    def parameters(self):\n        return [self.gamma, self.beta]","position":{"start":{"line":3,"column":1},"end":{"line":35,"column":1}},"key":"qAeD7vSwMH"},{"type":"paragraph","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"It assumed, in the way we wrote it and at the time, that the input ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"VXg0sXK46I"},{"type":"inlineCode","value":"x","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"kHxKalm0kd"},{"type":"text","value":" is ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"YzVZzq1zyu"},{"type":"inlineMath","value":"2D","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"w5uFvBeiee"},{"type":"text","value":". So it was ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"v5pSyjWCCR"},{"type":"inlineMath","value":"N \\times D","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN \\times D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"M8BE7nsI7W"},{"type":"text","value":", where ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"LCr0jV9nyO"},{"type":"inlineMath","value":"N","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"QZs5Njc8he"},{"type":"text","value":" was the batch size. So that’s why we only reduced the mean and the variance over the ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"MxAXJqHmVZ"},{"type":"inlineMath","value":"0th","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"AZ5BomGnZo"},{"type":"text","value":" dimension. But now ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"wyCX9zMauq"},{"type":"inlineCode","value":"x","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"fNJD7FdRyO"},{"type":"text","value":" will basically become ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"Ji6OLjiV6E"},{"type":"inlineMath","value":"3D","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e3D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"iN5MaNJLd2"},{"type":"text","value":". So what’s happening inside the ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"SegrERipuV"},{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"aXz752iBoS"}],"key":"FrT4jB6mPI"},{"type":"text","value":" layer right now? And how come it’s working at all and not giving any errors? The reason for that is basically because everything broadcasts properly, but the ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"K5GriqDVW7"},{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"ZBSYbDn4yO"}],"key":"pps8iGgasc"},{"type":"text","value":" is not doing what we want it to do. So in particular, let’s basically think through what’s happening inside the ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"nkzmcIcDfg"},{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"Eo7JS1F0LA"}],"key":"AE8xamFsRh"},{"type":"text","value":". Let’s look at what’s happening here in a simplified example:","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"lWCwoxYusG"}],"key":"EVofoyDRPL"}],"key":"gxvAyPKNZb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"e = torch.randn(32, 4, 68)\nemean = e.mean(0, keepdim=True)  # 1, 4, 68\nevar = e.var(0, keepdim=True)  # 1, 4, 68\nehat = (e - emean) / torch.sqrt(evar + 1e-5)  # 32, 4, 68\nehat.shape","key":"xxZYzUivVV"},{"type":"outputs","id":"gjuRrPLu3PQTIC6M4r-Fo","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":84,"metadata":{},"data":{"text/plain":{"content":"torch.Size([32, 4, 68])","content_type":"text/plain"}}},"children":[],"key":"cg7tXFHZ5B"}],"key":"lwQv19qV9h"}],"key":"GsFjQDsT5x"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So we’re receiving an input of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gWEc2Qb8p6"},{"type":"inlineMath","value":"32\\times4\\times68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e32\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e68\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e32\\times4\\times68\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e32\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e68\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Cu89BWLvBk"},{"type":"text","value":". And then we are doing here ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VNvMRz0JtA"},{"type":"inlineCode","value":"x.mean()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h68cPg5MvG"},{"type":"text","value":", but we have ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"g3Zq9hVYie"},{"type":"inlineCode","value":"e","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NWmDSn68rU"},{"type":"text","value":" instead of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D8NvUj94wq"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sk5oBeenGt"},{"type":"text","value":". But we’re doing the mean over ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tL0kqLOyWW"},{"type":"text","value":"0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b2QwwVb1mB"},{"type":"text","value":" and that’s actually giving us ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wRaJSvYa15"},{"type":"inlineMath","value":"1\\times4\\times68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e68\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1\\times4\\times68\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e68\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"cGQ3jDjIU2"},{"type":"text","value":". So we’re doing the mean only over the very first dimension. And it’s giving us a mean and a variance that still maintains the middle dimension in between (i.e. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mFD56r3lOY"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tVQo0lQRvh"},{"type":"text","value":"). So these means are only taken over ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iDVNS8GgnO"},{"type":"text","value":"32","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fiZx4gaxT3"},{"type":"text","value":" numbers in the first dimension. And then, when we perform the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LAPDH9eAq4"},{"type":"inlineCode","value":"ehat","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qo07tgiyA8"},{"type":"text","value":" assignment, everything broadcasts correctly still. But basically what ends up happening is when we also look at the running mean:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NJuPeVZJLN"}],"key":"Wdx2UWJvHJ"}],"key":"J2Gi5etrpL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model.layers[3].running_mean.shape","key":"JuUImYFNwv"},{"type":"outputs","id":"HfRZRxntCppJeeM5WPsHz","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":85,"metadata":{},"data":{"text/plain":{"content":"torch.Size([1, 4, 68])","content_type":"text/plain"}}},"children":[],"key":"yJ1oLRkvrp"}],"key":"ODp0frjkUW"}],"key":"Y9uRNseVba"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"the shape of this running mean now is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bRnwxcgvae"},{"type":"inlineMath","value":"1\\times4\\times68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e68\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1\\times4\\times68\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e68\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"VXTvF7KISt"},{"type":"text","value":". Instead of it being just a size of dimension, because we have ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"v1tbtv7CHP"},{"type":"text","value":"68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RazpUineCD"},{"type":"text","value":" channels, we expect to have ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rlvp0oDpIq"},{"type":"text","value":"68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zLZfeqDEVB"},{"type":"text","value":" means and variances that we’re maintaining. But actually, we have an array of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dxUppDFOCx"},{"type":"inlineMath","value":"4\\times68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e68\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times68\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e68\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"lSPwvonubD"},{"type":"text","value":". And so basically what this is telling us is this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AE18fJiJSG"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XrcSydcMxS"}],"key":"zZYHRUm36k"},{"type":"text","value":" is currently working in parallel over ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KDfIhuKB3l"},{"type":"inlineMath","value":"4\\times68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e68\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4\\times68\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e68\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"g4txfXt29j"},{"type":"text","value":" instead of just ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Vs9xUjF9Vm"},{"type":"text","value":"68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ra8dhRqux1"},{"type":"text","value":" channels. So basically we are maintaining this. We are maintaining statistics for every one of these four positions individually and independently. And instead, what we want to do is we want to treat this middle ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dIyICDurCW"},{"type":"text","value":"4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XRWaSYt8ZH"},{"type":"text","value":" dimension as a batch dimension, just like the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JSSnTumXhV"},{"type":"inlineMath","value":"0th","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"s0kP6f3lDr"},{"type":"text","value":" dimension. So as far as the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JytWfBMy7H"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bCFEjEbNjn"}],"key":"QNu22wEvIl"},{"type":"text","value":" is concerned, it doesn’t want to average... We don’t want to average over ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"o1LzvPZfi8"},{"type":"text","value":"32","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ip5QLpYf4K"},{"type":"text","value":" numbers. But instead, we want to now average over ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CW2TxO1ecq"},{"type":"inlineMath","value":"32\\times4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e32\u003c/mn\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmn\u003e4\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e32\\times4\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e32\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"KsIJ0ik6oP"},{"type":"text","value":" numbers for every single one of these ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"askPIIooc6"},{"type":"text","value":"68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EJxpUaLSE3"},{"type":"text","value":" channels. Since ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GinSMZ26F5"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.mean.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.mean","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wWcurNJNkt"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.mean.html","key":"U1rkWBPioa"},{"type":"text","value":" allows us to reduce over multiple (and not just one) dimensions at the same time, we’ll do just that and reduce over both the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qMQDo6KE36"},{"type":"inlineMath","value":"0th","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"MhyxWA3ajY"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xnQqkyFi1E"},{"type":"inlineMath","value":"1st","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1st\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"KIx64dkZkN"},{"type":"text","value":" dimensions:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tVhcbYO9la"}],"key":"LPfMjJGjlC"}],"key":"Wd9DE0y1vT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"e = torch.randn(32, 4, 68)\nemean = e.mean((0, 1), keepdim=True)  # 1, 1, 68\nevar = e.var((0, 1), keepdim=True)  # 1, 1, 68\nehat = (e - emean) / torch.sqrt(evar + 1e-5)  # 32, 4, 68\nehat.shape","key":"oe0o5vN2Ma"},{"type":"outputs","id":"3MdRY9ZSkb_aFuDCOE_HY","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":86,"metadata":{},"data":{"text/plain":{"content":"torch.Size([32, 4, 68])","content_type":"text/plain"}}},"children":[],"key":"PQwXo3YAb2"}],"key":"InNKIRaxWz"}],"key":"hAS5Ov7ngc"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although the final shape of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mnA9rLxXjj"},{"type":"inlineCode","value":"ehat","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dMb9Ho6K6n"},{"type":"text","value":" remains the same, we see now that:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ETKzUYine5"}],"key":"iwnOjRzWyt"}],"key":"RDT8x7JSeV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"emean.shape, evar.shape","key":"km2WzjENjy"},{"type":"outputs","id":"02Y4ivqAdLvgKxTq9lHeC","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":87,"metadata":{},"data":{"text/plain":{"content":"(torch.Size([1, 1, 68]), torch.Size([1, 1, 68]))","content_type":"text/plain"}}},"children":[],"key":"kqlwG0PhBf"}],"key":"k9qFLBfO4M"}],"key":"aTZ9irHHSb"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"instead of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t80Qpi8XBQ"},{"type":"inlineCode","value":"1, 4, 68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TZ6wBZ5Wlm"},{"type":"text","value":", since we reduced over both of the batch dimensions, it yields only ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jbwLGAiErc"},{"type":"text","value":"68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J43Y3mkBOL"},{"type":"text","value":" numbers total for each tensor, with a bunch of spurious leftover ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IeYmhhrIF0"},{"type":"text","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h1gQ43uWcr"},{"type":"text","value":" dimensions remaining. Therefore, this is what should be happening with our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"imcaFvdAon"},{"type":"inlineCode","value":"running_mean","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SZR9ms46OH"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fUX2AkTre6"},{"type":"inlineCode","value":"running_var","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HYENOgB47X"},{"type":"text","value":" tensors inside our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YCLuK8Zz3i"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZSILZ7dkfI"},{"type":"text","value":" implementation. So the change is pretty straightforward:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xWuVvdypJc"}],"key":"PE9jcmJlaf"}],"key":"VWCpntnkzb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"class BatchNorm1d:\n    def __init__(self, dim, eps=1e-5, momentum=0.1):\n        self.eps = eps\n        self.momentum = momentum\n        self.training = True\n        # parameters (trained with backprop)\n        self.gamma = torch.ones(dim)\n        self.beta = torch.zeros(dim)\n        # buffers (trained with a running 'momentum update')\n        self.running_mean = torch.zeros(dim)\n        self.running_var = torch.ones(dim)\n\n    def __call__(self, x):\n        # calculate the forward pass\n        if self.training:\n            if x.ndim == 2:\n                dim = 0\n            elif x.ndim == 3:\n                dim = (0, 1)\n            xmean = x.mean(dim, keepdim=True)  # batch mean\n            xvar = x.var(dim, keepdim=True)  # batch variance\n        else:\n            xmean = self.running_mean\n            xvar = self.running_var\n        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # normalize to unit variance\n        self.out = self.gamma * xhat + self.beta\n        # update the buffers\n        if self.training:\n            with torch.no_grad():\n                self.running_mean = (\n                    1 - self.momentum\n                ) * self.running_mean + self.momentum * xmean\n                self.running_var = (\n                    1 - self.momentum\n                ) * self.running_var + self.momentum * xvar\n        return self.out\n\n    def parameters(self):\n        return [self.gamma, self.beta]","key":"GUONTxolGG"},{"type":"outputs","id":"dqBFKsbRQLk0zyS_-lBPe","children":[],"key":"eMDCDZw7R2"}],"key":"HDlb8m7wky"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Basically, now in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rfzQKKo3lN"},{"type":"inlineCode","value":"__call__","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zwMWbG0Fot"},{"type":"text","value":" we are checking the dimensionality of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PyaY5YwgP0"},{"type":"inlineCode","value":"x","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nddV6bgds6"},{"type":"text","value":" and based on it we are determining the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wA4q1QpZsS"},{"type":"inlineCode","value":"dim","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uOoHZv0KV0"},{"type":"text","value":" parameters to be passed to the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e5NQL0LRK8"},{"type":"inlineCode","value":"mean","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Z8KZlvYChw"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CMv0Py88Tq"},{"type":"inlineCode","value":"var","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cU9BX1p4Yv"},{"type":"text","value":" functions. Now, to point out one more thing. We’re actually departing from the API of PyTorch here a little bit, because when you go read the documentation of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"x7B3hLxJmB"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn.BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KduCnMgymI"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html","key":"dMaeom9QFY"},{"type":"text","value":", it says:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ceb95DCHtZ"}],"key":"vdoxHwkxSZ"},{"type":"blockquote","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Input: ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BxWEopsX6j"},{"type":"inlineMath","value":"(N,C)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e(N,C)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"kagbKdFdrY"},{"type":"text","value":" or ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ui8LbDFJYL"},{"type":"inlineMath","value":"(N,C,L)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e(N,C,L)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"H5Z9kwANBF"},{"type":"text","value":", where ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nZY9L9NJbz"},{"type":"inlineMath","value":"N","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Nrz5B6PAMO"},{"type":"text","value":" is the batch size, ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ps48WAHkKb"},{"type":"inlineMath","value":"C","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"k1x2OpDiaC"},{"type":"text","value":" is the number of features or channels, and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PBVnRKp2Ne"},{"type":"inlineMath","value":"L","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eL\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"fz6Ouy3I4H"},{"type":"text","value":" is the sequence length","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ZMrbBTCs9j"}],"key":"nF1UkoPaAF"}],"key":"lrXPbciW4P"}],"key":"WMDN8dFejS"}],"key":"txr5qc80aJ"}],"key":"KtR0EtdhVD"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Notice, the input to this layer can either be ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"luVkMTHapv"},{"type":"inlineMath","value":"N","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"pYPQigSEpR"},{"type":"text","value":" (batch size) ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"w6L7Zzhe7j"},{"type":"inlineMath","value":"\\times","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo\u003e×\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\times\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e×\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"TTbDlS7L4e"},{"type":"text","value":" ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E9jlyqoPQW"},{"type":"inlineMath","value":"C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Dd3bIbKb3k"},{"type":"text","value":" (number of features or channels) or it actually does accept three-dimensional inputs, but it expects it to be ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BxAs7T7Kn4"},{"type":"inlineMath","value":"N\\times C \\times L","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eL\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times C \\times L\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"msAmNrCVVP"},{"type":"text","value":" (sequence legth). So this is a problem because you see how ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a5MFt6wrgp"},{"type":"inlineMath","value":"C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"N2XYQ2RPY3"},{"type":"text","value":" is nested here in the middle. And so when it gets ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PzWDs4OjeX"},{"type":"inlineMath","value":"3D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e3D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"UhNYxVmoQ3"},{"type":"text","value":" inputs, this ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HRypVXGB0E"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EdwslI0x5A"}],"key":"FsN6NGEU0g"},{"type":"text","value":" layer will reduce over ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BXeuRVu8rN"},{"type":"inlineCode","value":"0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FB2z4LAtzq"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vm3VuERQYC"},{"type":"inlineCode","value":"2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"USmKgHt0dj"},{"type":"text","value":" instead of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"T38eN0RBHC"},{"type":"inlineCode","value":"0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Dz729b5dHI"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"y8spQCcKd5"},{"type":"inlineCode","value":"1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EtfhnTsFb6"},{"type":"text","value":". So basically, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DGMZ1yKMyv"},{"type":"link","url":"https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn.BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WDhHUf49Oj"}],"urlSource":"https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html","key":"zUjwhDnYF3"},{"type":"text","value":" layer assumes that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"msz0t2pHDn"},{"type":"inlineMath","value":"C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"jOA7otGOQ8"},{"type":"text","value":" will always be the first dimension, whereas we assume here that ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LwgZsauTvu"},{"type":"inlineMath","value":"C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eC\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"rxYVl9RxbD"},{"type":"text","value":" is the last dimension, and there are some number of batch dimensions beforehand. And so, it expects ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"py0uFrogOr"},{"type":"inlineMath","value":"N\\times C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times C\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"OF9IDdJ2vY"},{"type":"text","value":" or ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aYgm4cH1Gc"},{"type":"inlineMath","value":"N\\times C\\times L","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eL\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times C\\times L\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"K6EH8tQYpl"},{"type":"text","value":", whereas we expect ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"R38ttgbmGZ"},{"type":"inlineMath","value":"N\\times C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times C\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"e1tVQPK3vC"},{"type":"text","value":" or ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TA7ELNBIhQ"},{"type":"inlineMath","value":"N\\times L\\times C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times L\\times C\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"fGBl9SNSX0"},{"type":"text","value":". So just a small deviation from the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MgWTluo8yJ"},{"type":"inlineCode","value":"PyTorch","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"muzBT6ChPo"},{"type":"text","value":" API. Now, after updating our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cFTfv6Zoat"},{"type":"inlineCode","value":"BatchNorm1d","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AyZIe5mSSi"},{"type":"text","value":", if we redefine our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"liJt3MLi9z"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qim3PQma8S"}],"key":"Jkb6fjjS1t"},{"type":"text","value":" and run for one step:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TasdQmBQvn"}],"key":"HwAvU8JGgc"}],"key":"AQujZ2XIPF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, parameters = define_nn(block_size, n_embd, n_hidden)\n_ = train(xtrain, ytrain, model, parameters, break_at_step=1)\nmodel(xb)\nfor l in model.layers:\n    print(l.__class__.__name__, \":\", tuple(l.out.shape))","key":"nRtSzUaZag"},{"type":"outputs","id":"uUKrCwlmRcqmQmf1L4lbZ","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"22397\n      0/ 200000: 3.2907\nEmbedding : (4, 8, 10)\nFlattenConsecutive : (4, 4, 20)\nLinear : (4, 4, 68)\nBatchNorm1d : (4, 4, 68)\nTanh : (4, 4, 68)\nFlattenConsecutive : (4, 2, 136)\nLinear : (4, 2, 68)\nBatchNorm1d : (4, 2, 68)\nTanh : (4, 2, 68)\nFlattenConsecutive : (4, 136)\nLinear : (4, 68)\nBatchNorm1d : (4, 68)\nTanh : (4, 68)\nLinear : (4, 27)\n"},"children":[],"key":"W1H6cevIiP"}],"key":"Mqv80PbvLX"}],"key":"eQ7Uzds34u"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"the shapes are of course the same as before, but now if we inspect the shape of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"B21nfAXo13"},{"type":"inlineCode","value":"running_mean","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"H073ZThuv7"},{"type":"text","value":" inside the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CSyRQNUVlu"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"batchnorm","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KsI5ew7tcC"}],"key":"XilbsGrSh3"},{"type":"text","value":" layer:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cfcg5paLSk"}],"key":"yo4fh8YEVi"}],"key":"qEQsU7YlaA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model.layers[3].running_mean.shape","key":"Gh20lXAOHh"},{"type":"outputs","id":"YBOxMtqKwmTJ290QzlLuf","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":90,"metadata":{},"data":{"text/plain":{"content":"torch.Size([1, 1, 68])","content_type":"text/plain"}}},"children":[],"key":"v3uCz1Hwjy"}],"key":"CSfP87osMm"}],"key":"O8QhsQULnN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So correctly now we are only maintaining ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KQbEEgVPxN"},{"type":"text","value":"68","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cVXFfxRx5a"},{"type":"text","value":" means, for every one of our channels, and we are treating the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jZ18bu6TJO"},{"type":"inlineMath","value":"0th","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmi\u003eh\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0th\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eh\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"ZFpFPcR8X4"},{"type":"text","value":" and the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wlsVv6N0cz"},{"type":"inlineMath","value":"1st","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1st\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"cKSqtZKjKu"},{"type":"text","value":" dimension as batch dimensions, which is exactly what we want!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OiTJJj4UxH"}],"key":"jBJddM72Kh"}],"key":"HG8ULqce57"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Re-training the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"omEcGXUPPI"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dDYWTNc0cL"}],"key":"iF0exHkdQL"},{"type":"text","value":" after bug fix","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UY3d9OPKgV"}],"identifier":"re-training-the-wavenet-after-bug-fix","label":"Re-training the WaveNet after bug fix","html_id":"re-training-the-wavenet-after-bug-fix","implicit":true,"key":"ddmHjXSJpu"}],"key":"RH5t6KxwTT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So let’s retrain the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nNt0MPJDsf"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jMiNMimoqu"}],"key":"DQ33AxviC3"},{"type":"text","value":" now, after the bug fix:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XLdXb5vIx1"}],"key":"HlC8TICFe6"}],"key":"LCKGTIFNME"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, parameters = define_nn(block_size, n_embd, n_hidden)\nlossi = train(xtrain, ytrain, model, parameters)","key":"tVwP5GJBEp"},{"type":"outputs","id":"Ed-JmtZBHOKV7n8IFBZFq","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"22397\n      0/ 200000: 3.3054\n  10000/ 200000: 2.2512\n  20000/ 200000: 2.3514\n  30000/ 200000: 2.5115\n  40000/ 200000: 1.6012\n  50000/ 200000: 2.1728\n  60000/ 200000: 1.8859\n  70000/ 200000: 2.1417\n  80000/ 200000: 2.0348\n  90000/ 200000: 1.7458\n 100000/ 200000: 1.7257\n 110000/ 200000: 1.9065\n 120000/ 200000: 2.0347\n 130000/ 200000: 2.1898\n 140000/ 200000: 2.2163\n 150000/ 200000: 1.7984\n 160000/ 200000: 1.4846\n 170000/ 200000: 1.7952\n 180000/ 200000: 2.0809\n 190000/ 200000: 2.2824\n"},"children":[],"key":"IxJ1zzvwpp"}],"key":"Dp7Ikwqn2G"}],"key":"ApdAU1IILE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));","key":"VwMYE0OhOU"},{"type":"outputs","id":"g9EpAcwhSruZDUIdJJeI1","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"089f12aea1ff4c02959e39af0a8a4ef2\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"cdaf79a36040dbd960f88cb29bd58539","path":"/build/cdaf79a36040dbd960f88cb29bd58539.png"},"text/html":{"content_type":"text/html","hash":"a83b309522d993ec6ccf1704230ffdf5","path":"/build/a83b309522d993ec6ccf1704230ffdf5.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"cNTooB7HkG"}],"key":"hxuevJYmid"}],"key":"f0gTFNtTFL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"trigger_eval_mode(model)\ninfer_loss(model, xtrain, ytrain, prefix=\"train\")\ninfer_loss(model, xval, yval, prefix=\"val\");","key":"uZGYN2urGK"},{"type":"outputs","id":"lDDqcuIz-iZXEF-B8-h-H","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"train 1.911558985710144\nval 2.019017219543457\n"},"children":[],"key":"Ktnx5M6Qx1"}],"key":"PPOytNQOgK"}],"key":"HR8PCwhTE1"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And we can see that we are getting a tiny improvement in our training and validation losses:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"idRFymWqgk"}],"key":"VVcW4DFXru"}],"key":"X0O6Ay6Gvc"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"code","lang":"python","value":"# original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n# context: 3 -\u003e 8 (22K params): train 1.915, val 2.034\n# flat -\u003e hierachical (22K params): train 1.937, val 2.026\n# fix bug in batchnorm: train 1.911, val 2.019","position":{"start":{"line":1,"column":1},"end":{"line":6,"column":1}},"key":"D8b2jgMhBi"}],"visibility":"show","key":"RoHnIOUXhi"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The reason this improvement is to be expected is that now we have less numbers going into the estimates of the mean and variance which allows everything to be more stable and less wiggly.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"J09B48JH0r"}],"key":"Uak1psII7a"}],"key":"Tamuz4AwNL"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Scaling up our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"o8VSpt1eN1"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MhGA7kTcsB"}],"key":"qVsekgaPlG"}],"identifier":"scaling-up-our-wavenet","label":"Scaling up our WaveNet","html_id":"scaling-up-our-wavenet","implicit":true,"key":"tEKfnJIKxU"}],"key":"RxC7fE8LxJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And with this more general architecture in place, we are now set up to push the performance further by increasing the size of the network:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YzQG5Mo38m"}],"key":"jwSnEBVUQB"}],"key":"lQiBl7mYJQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"n_embd = 24  # the dimensionality of the character embedding vectors\nn_hidden = 128  # the number of neurons in the hidden layer of the MLP","key":"J5v8rVCkyd"},{"type":"outputs","id":"yN2D5VJNN9XJIAh73U4mR","children":[],"key":"LHcJLab0A0"}],"key":"i0oxV0I0oK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"And using the exact same architecture, we now have","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FJqt0r5c7x"}],"key":"SyGwLbCvmu"}],"key":"HrOxQi3Y18"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model, parameters = define_nn(block_size, n_embd, n_hidden)","key":"JaQnAAi1QM"},{"type":"outputs","id":"w8YhqTNCQ6ZgcWWMzSYP9","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"76579\n"},"children":[],"key":"vlZZqrQiju"}],"key":"xz56q58Vmg"}],"key":"ODWVpBJ8PR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"76579","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mhXUlDb4BC"},{"type":"text","value":" parameters and the training takes a lot longer:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"X0NGoCaXAO"}],"key":"sLfT0waNTo"}],"key":"uLGZfefyFO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"lossi = train(xtrain, ytrain, model, parameters)","key":"QRc1yRpCaW"},{"type":"outputs","id":"5dRqj5-qzJgBdxyKAs3_s","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"      0/ 200000: 3.3060\n  10000/ 200000: 2.1627\n  20000/ 200000: 1.8125\n  30000/ 200000: 2.1831\n  40000/ 200000: 1.9874\n  50000/ 200000: 2.3684\n  60000/ 200000: 2.1482\n  70000/ 200000: 1.7558\n  80000/ 200000: 1.8260\n  90000/ 200000: 1.8867\n 100000/ 200000: 1.9521\n 110000/ 200000: 1.9662\n 120000/ 200000: 1.9416\n 130000/ 200000: 2.0037\n 140000/ 200000: 1.9890\n 150000/ 200000: 1.7099\n 160000/ 200000: 1.8770\n 170000/ 200000: 1.5360\n 180000/ 200000: 1.4641\n 190000/ 200000: 1.8875\n"},"children":[],"key":"jgJlUjiEWn"}],"key":"wE9JYMqqRn"}],"key":"DfwlQkqsx7"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"but we do get a nice curve:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sDv3B12vEr"}],"key":"BdAnSolaQ3"}],"key":"MwtTXClL9A"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.figure()\nplt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));","key":"YQyx4tkCap"},{"type":"outputs","id":"aObYpYkyAOm7vFmLerCkV","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"338ac53bc3b84c37828d28bf9e4e8ce7\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"image/png":{"content_type":"image/png","hash":"13aaa7d5b0f0198790fa6b2332620b23","path":"/build/13aaa7d5b0f0198790fa6b2332620b23.png"},"text/html":{"content_type":"text/html","hash":"99231f3c921b2f703abfc487ea65ae31","path":"/build/99231f3c921b2f703abfc487ea65ae31.html"},"text/plain":{"content":"Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …","content_type":"text/plain"}}},"children":[],"key":"PKHywllTWW"}],"key":"IY56NsuqBi"}],"key":"QzxPwW9VcB"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"and we are now getting even better performance:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h1ASG8jBeh"}],"key":"mA3kO5lL8M"}],"key":"zmIr7OsPK0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"trigger_eval_mode(model)\ninfer_loss(model, xtrain, ytrain, prefix=\"train\")\ninfer_loss(model, xval, yval, prefix=\"val\");","key":"i3qmRvSXIs"},{"type":"outputs","id":"aH0qMGfujwM93y6YFKhVz","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"train 1.7666022777557373\nval 1.9965752363204956\n"},"children":[],"key":"NKRMbh7vp1"}],"key":"Q7Q1J2Frzn"}],"key":"OlHUG1Mkvm"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So, to compare to previous performances:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BGuFi63uxo"}],"key":"NbmjI7TXqg"}],"key":"HRjIAqtFfE"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"code","lang":"python","value":"# original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n# context: 3 -\u003e 8 (22K params): train 1.915, val 2.034\n# flat -\u003e hierachical (22K params): train 1.937, val 2.026\n# fix bug in batchnorm: train 1.911, val 2.019\n# scale up the network: n_embd 24, n_hidden 128 (76K params): train 1.768, val 1.990","position":{"start":{"line":1,"column":1},"end":{"line":7,"column":1}},"key":"sCrg2be8BM"}],"visibility":"show","key":"UROm27pay1"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"However because the experiments are starting to take longer to train, we are a little bit in the dark with respect to the correct setting of the hyperparameters here and the learning rates and so on. And so we are missing sort of like an experimental harness on which we could run a number of experiments and really tune this architecture very well.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BUjhCHCAaC"}],"key":"oYJTqP6qk8"}],"key":"YhPl7trZOy"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet but with dilated causal convolutions","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FTC7aEC5to"}],"identifier":"wavenet-but-with-dilated-causal-convolutions","label":"WaveNet but with dilated causal convolutions","html_id":"wavenet-but-with-dilated-causal-convolutions","implicit":true,"key":"C8VO5fq9QF"}],"key":"Gr6fWf2LND"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"So let’s conclude now with a few notes. We basically improved our performance noticeably from a val ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kYFN0lAud4"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kAHUdjVsBQ"}],"key":"fZfkAMyKOk"},{"type":"text","value":" of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EXPmrw8447"},{"type":"text","value":"2.10","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jl6CfSJNDw"},{"type":"text","value":" to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"T5KSgXyuDn"},{"type":"text","value":"1.99","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r9b73dOgO0"},{"type":"text","value":". But this shouldn’t be the focus as we are kind of in the dark. We have no experimental harness, we are just guessing and checking. And this whole thing is pretty terrible to be honest. We are just looking at the training ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xFdXc7lqqp"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LeUaUNY1wj"}],"key":"ERuHeuP3Z8"},{"type":"text","value":", whereas we should be looking at the training and validation ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"H1qNFlxpMa"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"loss","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ACwbMkrKwE"}],"key":"o0YFXMAI3V"},{"type":"text","value":" together. That said, we did implement the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"efisKBgWw0"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rFQfoIJbEN"}],"key":"Gpzi1Ksk7h"},{"type":"text","value":" architecture from the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KCbUwFYi8Q"},{"type":"link","url":"https://arxiv.org/abs/1609.03499","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"paper","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Yw3A2C2jl4"}],"urlSource":"https://arxiv.org/abs/1609.03499","key":"Gf8q5i6GZZ"},{"type":"text","value":":","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yYqqxXlIga"}],"key":"f2WO9ice6L"}],"key":"NMyCHtBbX0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig3.png\"))","key":"omFMVQMMfp"},{"type":"outputs","id":"9oAb_qXt1_Yj1K-lx2HBB","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"198c39366ff68e8b03ccb06df349f47a","path":"/build/198c39366ff68e8b03ccb06df349f47a.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"IuprVL2z2M"}],"key":"kfoxURjUt4"}],"key":"nw15DeDq8t"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"But we did not implement this specific forward pass of it:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YpqyHSVb1t"}],"key":"gDEinmzbTT"}],"key":"Nwx8rEqtmr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig4.png\"))","key":"T1g2TDv1W5"},{"type":"outputs","id":"kJ1YvI-_nIqkLmJVXCud3","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"54272b3d206b11fb693990a90d767eee","path":"/build/54272b3d206b11fb693990a90d767eee.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"CrReq0mYjQ"}],"key":"DCEsjI31Qt"}],"key":"GvBLmkZWzN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"where you have a more complicated kind of gated linear layer with residual connections, skip connections and so on... So we did not implement this, but only the tree-like model. All things considered, let’s briefly go over how what we’ve done here relates to convolutional neural networks as used in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GNagjOdi6i"},{"type":"link","url":"https://arxiv.org/abs/1609.03499","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"WaveNet paper","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"njd3GX6aqN"}],"urlSource":"https://arxiv.org/abs/1609.03499","key":"EXc5eXLArA"},{"type":"text","value":". Basically the use of convolutions is strictly for efficiency. It doesn’t actually change the model we’ve implemented. So, here for example:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kAk1qltqTH"}],"key":"unWuTZQRJs"}],"key":"J2xQTHS0Pd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print_next_character(xtrain[46:54], ytrain[46:54])","key":"kivLONgS0M"},{"type":"outputs","id":"YnRQGUjZr_P2NWjD6D4Nu","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"........ --\u003e a\n.......a --\u003e n\n......an --\u003e a\n.....ana --\u003e l\n....anal --\u003e i\n...anali --\u003e s\n..analis --\u003e a\n.analisa --\u003e .\n"},"children":[],"key":"LyIksBb3S1"}],"key":"eNNcNn9voy"}],"key":"OqD8dfc6IZ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"we see the name ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"p1RkQDqyJY"},{"type":"inlineCode","value":"analisa","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lryuNlASbl"},{"type":"text","value":" from our training set and it has ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tOocsZUDcM"},{"type":"text","value":"7","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NGrBLtzEsL"},{"type":"text","value":" letters, so that is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Wf8K65GIsH"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vBOEHvcULD"},{"type":"text","value":" rows which correspond to independent examples of that name. Now, we can forward any one of these rows independently:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qJ9U4JAGUp"}],"key":"sGS5wjc3Fj"}],"key":"yIVtlI6X8O"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# forward a single example\nsingle_example = xtrain[[7]]  # index by [[7]] to get an extra batch dimension\nlogits = model(single_example)\nlogits.shape","key":"xWJbdmu3SP"},{"type":"outputs","id":"yWWc0rvok2nhUwVbr7rTi","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":102,"metadata":{},"data":{"text/plain":{"content":"torch.Size([1, 27])","content_type":"text/plain"}}},"children":[],"key":"AybddDZQAx"}],"key":"aTNe7aSUY8"}],"key":"d9Z1U4jZeG"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now imagine that instead of just a single example, you would like to forward all of the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"W9DnOdp6Yd"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vu21Fagt6c"},{"type":"text","value":" examples that make up the name into the network at the same time:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"otAwNLZNX4"}],"key":"rk8rcj5JH3"}],"key":"c53siohnC3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# forward all of them\nlogits = torch.zeros(8, 27)\nfor i in range(7):\n    logits[i] = model(xtrain[[7 + i]])\nlogits.shape","key":"azmKZvVqCa"},{"type":"outputs","id":"0Z-9aFwKPWhvVuvqPJ0kc","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":103,"metadata":{},"data":{"text/plain":{"content":"torch.Size([8, 27])","content_type":"text/plain"}}},"children":[],"key":"AW32Ecljyr"}],"key":"ZzpocTIPD1"}],"key":"l9HkJ30fTz"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Of course, as we’ve implemented this right now, this is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jqfGKh0KG0"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u8OFCzKX1S"},{"type":"text","value":" independent calls to our model. But what convolutions allow you to do is they allow you to “slide” this model efficiently over the input sequence. And so this for loop we just wrote out can be done not “outside”, through iteration, in Python, but “inside” of kernels in ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rahdP60AfK"},{"type":"link","url":"https://en.wikipedia.org/wiki/CUDA","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"CUDA","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CFCSGn6EKP"}],"urlSource":"https://en.wikipedia.org/wiki/CUDA","data":{"page":"CUDA","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"wJr7sMHPed"},{"type":"text","value":". And so this for loop gets hidden into the convolution. So basically you can think of the convolution as a for loop applying a little linear filter over space of some input sequence. And in our case the space we’re interested in is one dimensional. And we are interested in sliding these filter over the input data. This diagram is quite helpful for understanding actually:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FTKuDwJr7D"}],"key":"BvqjWE8Axc"}],"key":"Y8vUDgavRU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from IPython.display import Image, display\n\ndisplay(Image(filename=\"wavenet_fig3.png\"))","key":"SsIgGZRAmf"},{"type":"outputs","id":"xhVHoebnqxiH_oGGMuIZU","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"198c39366ff68e8b03ccb06df349f47a","path":"/build/198c39366ff68e8b03ccb06df349f47a.png"},"text/plain":{"content":"\u003cIPython.core.display.Image object\u003e","content_type":"text/plain"}}},"children":[],"key":"pjqd3cdXIM"}],"key":"oG2uCPFkfv"}],"key":"BXk5qZDtJW"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Here, you can see highlighted with black arrows a single tree of the calculation we just described. So depicted here, calculating a single orange node at the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N3bcgGsybP"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Output","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h5KISVlQiE"}],"key":"BcFnZNYltI"},{"type":"text","value":" layer corresponds to us in our example forwarding a single example and getting out a single output. But what convolutions allow you to do is it allows you to take this black tree-like structure and kind of like slide it over the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"efUugKZ0Cz"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Input","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"s4USN68s9Y"}],"key":"cqQ3bK2s9d"},{"type":"text","value":" sequence (blue nodes) and calculate all of the orange outputs at the same time. In the above figure, this sliding action is represented by the dashed connections between the nodes. In our example:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hNzyGKjf6Y"}],"key":"LlUazqFfeC"}],"key":"hCUFV3FJXp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print_next_character(xtrain[46:54], ytrain[46:54])","key":"losvxBjIOq"},{"type":"outputs","id":"sbUFWhmfDsa9VxLfI5jPw","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"........ --\u003e a\n.......a --\u003e n\n......an --\u003e a\n.....ana --\u003e l\n....anal --\u003e i\n...anali --\u003e s\n..analis --\u003e a\n.analisa --\u003e .\n"},"children":[],"key":"syt22mCXPG"}],"key":"t33Y1qgCVM"}],"key":"D5JACI6KYn"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"this sliding operation would correspond to calculating all the above ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lzgfNmQE5d"},{"type":"text","value":"8","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zxBSBLLzGx"},{"type":"text","value":" outputs at all the positions of the name (like we did in an explicit loop) at the same time. And the reason this is much more efficient is because the for loop is inside the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OLOKUe8ZFZ"},{"type":"inlineCode","value":"CUDA","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m55Y39DXRG"},{"type":"text","value":" kernels. That makes it efficient. Also, notice the node re-use in the diagram were for example in the first ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IG0sbXA8Cp"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Hidden Layer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uzuq3VGLFc"}],"key":"vo20b2qDrf"},{"type":"text","value":" each white node is the right child of the white node above it (in the second ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MlOJsoc2hd"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Hidden Layer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"utolEnDFv2"}],"key":"hbk4SxHrPC"},{"type":"text","value":"), but also the left child of another white node (also in the second ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VEp84Crxw4"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Hidden Layer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jfb2qBeEut"}],"key":"ZTG40qnArQ"},{"type":"text","value":"). In the first ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Iyzue9nyV5"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Hidden Layer","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AEMpba3OYI"}],"key":"NS1aCnzSJC"},{"type":"text","value":", each node and its value is used twice. Therefore, in our above example snippet, with our naive way we would have to recalculate the value that corresponds to such a node, whereas with such a convolutional ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bArJCkzAhs"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"V03lLDREgF"}],"key":"ckIJ4qFIb7"},{"type":"text","value":" we are allowed to reuse it. So, in the convolutional ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"x40miEQOcF"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"w6g9o9K2RT"}],"key":"eoRsEoIF1R"},{"type":"text","value":" you can think of the linear layer as filters. And we take these filters and their linear filters and we slide them over the input sequence and we calculate the first layer, the second layer, the third layer and then the output layer of the sandwich and it is all done very efficiently using these convolutions.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hCZVAVUIjB"}],"key":"Rv42OgYLRv"}],"key":"MEG5Pk3g9K"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Summary","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e1zIuaJZpi"}],"identifier":"summary","label":"Summary","html_id":"summary","implicit":true,"key":"dguQTYeDgI"}],"key":"tFDFErlkuZ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Another thing to take away from this lecture is having modeled our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NbwjOPztT3"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rfvkjEsMDQ"}],"key":"gVDC1o0DWh"},{"type":"text","value":" lego blocks: the module classes (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WNzfsWUDth"},{"type":"inlineCode","value":"Linear","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tkghSgoeup"},{"type":"text","value":", etc.) after modules from ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ef7vebVoz6"},{"type":"link","url":"https://pytorch.org/docs/stable/nn.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"inlineCode","value":"torch.nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e0hxzrxSBk"}],"urlSource":"https://pytorch.org/docs/stable/nn.html","key":"Q9wq86MBQ3"},{"type":"text","value":". So it is now very easy to start using modules directly from PyTorch, from hereon. The next thing I hope you got a bit of a sense of is what the development process of building deep neural networks looks like. Which I think was relatively representative to some extent. So number one, we are spending a lot of time in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KT5ITdzXbN"},{"type":"link","url":"https://pytorch.org/docs/stable/nn.html","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"documentation page of PyTorch","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FlEEfEXeUB"}],"urlSource":"https://pytorch.org/docs/stable/nn.html","key":"jTHDu29w5U"},{"type":"text","value":". And we’re reading through all the layers, looking at documentations, what are the shapes of the inputs, what they can be, what does the layer do, and so on. Unfortunately, however, the PyTorch documentation is not very good, at least not at the time these lectures were implemented. The PyTorch developers spend a ton of time on hardcore engineering of all kinds of distributed primitives, etc. But no one is rigorously maintaining documentation. It will lie to you, it will be wrong, it will be incomplete, it will be unclear. So unfortunately, it is what it is and you just kind of have to do your best with what they give us. Also, there’s a ton of trying to make the shapes work. And there’s a lot of gymnastics around these multi-dimensional arrays. Are they ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CEm4nqzRIk"},{"type":"inlineMath","value":"2D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"HajlcXSwJ0"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dhC7Ln5Ti5"},{"type":"inlineMath","value":"3D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e3\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e3D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e3\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"h5v7t7biOQ"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YkuFSN3ngv"},{"type":"inlineMath","value":"4D","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e4\u003c/mn\u003e\u003cmi\u003eD\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e4D\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e4\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"rJPuOyg9rW"},{"type":"text","value":"? What shapes do the layers take? Is it ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZQJLYnivjh"},{"type":"inlineMath","value":"N\\times C\\times L","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eL\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times C\\times L\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"qyM3Zb0ZiX"},{"type":"text","value":" or ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lkP9CW46zd"},{"type":"inlineMath","value":"N\\times L\\times C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmo\u003e×\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\\times L\\times C\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003cspan class=\"mbin\"\u003e×\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"Ed7paioami"},{"type":"text","value":"? And you’re permuting and viewing, and it just gets pretty messy. And so that brings me to number three. It’s often helpful to first prototype these layers and implementations in jupyter notebooks and make sure that all the shapes work out, initially making sure everything is correct. And then, once you’re satisfied with the functionality, you can copy-paste the code into your actual code base or repository (e.g. in VSCode). So these are roughly only some notes on the development process of working with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kMGgLAc25V"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XAaQfvE9Aq"}],"key":"VWxneGsxHK"},{"type":"text","value":"s.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WcUNgwH6HP"}],"key":"PVNaJxcWm6"}],"key":"JXEymRMSX8"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Outro","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Hdm14l6cXr"}],"identifier":"outro","label":"Outro","html_id":"outro","implicit":true,"key":"a2657Ns1oG"}],"key":"dUbjuqQsuX"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Lastly, this lecture unlocks a lot of potential further lectures because, number one, we have to convert our ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QLw5zNthLm"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"nn","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"c58nQYway8"}],"key":"xEnU38gTEY"},{"type":"text","value":" to actually use these dilated causal convolutional layers, so implementing the convnet. Number two, we potentially start to get into what this means, where are residual connections and skip connections and why are they useful. Number three, as we already mentioned, we don’t have any experimental harness. So right now, we are just guessing and checking everything. This is not representative of typical deep learning workflows. You usually have to set up your evaluation harness. You have lots of arguments that your script can take. You’re more comfortably kicking off a lot of experiments. You’re looking at a lot of plots of training and validation losses, and you’re looking at what is working and what is not working. And you’re working on this like population level, and you’re doing all these hyperparameter searches. So we’ve done none of that so far. So how to set that up and how to make it good, I think is a whole other topic. And number four, we should probably cover RNNs, LSTMs, GRUs, and of course Transformers. So many places to go, and we’ll cover that in the future. That’s all for now. Bye! :)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HAbLQMB0Qi"}],"key":"mi32Ya0j0C"}],"key":"mzuWpT5Led"}],"key":"hfqUpQ8fln"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"5. makemore (part 4): becoming a backprop ninja","url":"/micrograduate/makemore4","group":"microgra∇uate"},"next":{"title":"7. picoGPT: implementing a tiny GPT from scratch","url":"/micrograduate/picogpt","group":"microgra∇uate"}}},"domain":"http://localhost:3000"},"project":{"title":"microgra∇uate","github":"https://github.com/ckaraneen/micrograduate","copyright":"MIT License","toc":[{"file":"index.md"},{"file":"micrograduate/micrograd.ipynb"},{"file":"micrograduate/makemore1.ipynb"},{"file":"micrograduate/makemore2.ipynb"},{"file":"micrograduate/makemore3.ipynb"},{"file":"micrograduate/makemore4.ipynb"},{"file":"micrograduate/makemore5.ipynb"},{"file":"micrograduate/picogpt.ipynb"}],"thumbnail":"/build/heading-673a2e43fc80ba15305ee790558fe91d.png","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"micrograduate.micrograd","title":"1. micrograd: implementing an autograd engine","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore1","title":"2. makemore (part 1): implementing a bigram character-level language model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore2","title":"3. makemore (part 2): mlp","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore3","title":"4. makemore (part 3): activations \u0026 gradients, batchnorm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore4","title":"5. makemore (part 4): becoming a backprop ninja","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.makemore5","title":"6. makemore (part 5): building a WaveNet","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"micrograduate.picogpt","title":"7. picoGPT: implementing a tiny GPT from scratch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-7B0967AD.js";
import * as route0 from "/build/root-EDJFWIEV.js";
import * as route1 from "/build/routes/$-AD65NCUT.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-PCJPW7TK.js");</script></body></html>